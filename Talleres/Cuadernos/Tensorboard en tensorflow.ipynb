{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Tensorborad en tensorflow</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Profesores\n",
    "\n",
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asistentes\n",
    "\n",
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co\n",
    "7. Julieth López, julalopezcas@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido\n",
    "\n",
    "* [¿Qué es Tensorborad?]()\n",
    "    * [Tablero de tensorBoard]()\n",
    "* [Requerimientos]()\n",
    "* [Instalación y carga]()\n",
    "* [Ejemplo]()\n",
    "    * [Modelo]()\n",
    "    * [Graficando imaganes con TensorBoard]()\n",
    "    * [Tensorboard callback]()\n",
    "    * [Ejecución de Tensorboard]()\n",
    "    * [Matriz de confusión en TensorBoard]()\n",
    "    * [Ajuste de hiperparámetros con TensorBoard]()\n",
    "* [TensorFlow Profiler]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es Tensorborad?\n",
    "\n",
    "Tutorial tomado de [Neptune blog, Deep Dive Into TensorBoard: Tutorial With Examples](https://neptune.ai/blog/tensorboard-tutorial)\n",
    "\n",
    "Es una herramienta que permite rastrear varias métricas como la precisión (accuracy) y los registros de los grupos de pérdida de entrenamiento o de validación. TensorBoard provee distintas aplicaciones para utilizar en experimentos de aprendizaje de maquina. Algunas de las aplicaciones que se pueden ver en las distintas pestañas del tablero de Tensorboard son:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablero de tensorBoard\n",
    "\n",
    "- **Scalars**: Muestra los cambios en la perdida y métricas cobre las epocas. Tambien puede usarse para rastrear otros valores escalares como la taza de aprendizaje y la velocidad de entrenamiento.\n",
    "- **Images**: Tiene imagenes que muestran los pesos. Parandose con sobre una epoca especifica se pueden ver los pesos del modelo en esa epoca.\n",
    "- **Graphs**: Muestra las capas del modelo. Se puede utilizar para revisar si la arquitectura del modelo es la que se pretende.\n",
    "- **Distributions**: Muestra la distribución de los tensores. Por ejemplo, se puede ver la distribucion de los pesos y sesgos sobre cada epoca en una capa específica.\n",
    "- **Histograms**: Muestra la distribución de los tensores sobre el tiempo, sobre cada epoca.\n",
    "- **Proyector**: Se puede utilizar para visualizar la representación de cada vector, por ejemplo, word embeddings (la representación numérica de las palabras que captura su relación semantica) y imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requerimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalación y carga\n",
    "\n",
    "Se puede utlizar ´pip´ o ´conda´ para la **instalación**, observe los siguientes comandos:\n",
    "\n",
    "`pip install tensorboard`\n",
    "\n",
    "`conda install -c conda-forge tensorboard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(143): Could not remove or rename C:\\Users\\LENOVO\\anaconda3\\pkgs\\numpy-base-1.17.0-py37hc3f5095_0.tar.bz2.  Please remove this file manually (you may need to reboot to free file handles)\n",
      "WARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(143): Could not remove or rename C:\\Users\\LENOVO\\anaconda3\\pkgs\\numpy-base-1.17.0-py37hc3f5095_0\\Lib\\site-packages\\numpy\\ma\\tests\\test_regression.py.  Please remove this file manually (you may need to reboot to free file handles)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  environment location: C:\\Users\\LENOVO\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorboard\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    absl-py-1.0.0              |     pyhd8ed1ab_0          95 KB  conda-forge\n",
      "    ca-certificates-2021.10.8  |       h5b45459_0         176 KB  conda-forge\n",
      "    certifi-2021.10.8          |   py38haa244fe_1         145 KB  conda-forge\n",
      "    conda-4.11.0               |   py38haa244fe_0        16.9 MB  conda-forge\n",
      "    grpcio-1.42.0              |   py38hc60d5dd_0         1.9 MB\n",
      "    libprotobuf-3.17.2         |       h23ce68f_1         1.9 MB\n",
      "    markdown-3.3.4             |   py38haa95532_0         144 KB\n",
      "    openssl-1.1.1l             |       h8ffe710_0         5.7 MB  conda-forge\n",
      "    protobuf-3.17.2            |   py38hd77b12b_0         257 KB\n",
      "    python_abi-3.8             |           2_cp38           4 KB  conda-forge\n",
      "    tensorboard-1.15.0         |           py38_0         3.8 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        30.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  absl-py            conda-forge/noarch::absl-py-1.0.0-pyhd8ed1ab_0\n",
      "  grpcio             pkgs/main/win-64::grpcio-1.42.0-py38hc60d5dd_0\n",
      "  libprotobuf        pkgs/main/win-64::libprotobuf-3.17.2-h23ce68f_1\n",
      "  markdown           pkgs/main/win-64::markdown-3.3.4-py38haa95532_0\n",
      "  protobuf           pkgs/main/win-64::protobuf-3.17.2-py38hd77b12b_0\n",
      "  python_abi         conda-forge/win-64::python_abi-3.8-2_cp38\n",
      "  tensorboard        conda-forge/win-64::tensorboard-1.15.0-py38_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.9.30-~ --> conda-forge::ca-certificates-2021.10.8-h5b45459_0\n",
      "  certifi            pkgs/main::certifi-2021.10.8-py38haa9~ --> conda-forge::certifi-2021.10.8-py38haa244fe_1\n",
      "  conda              pkgs/main::conda-4.10.3-py38haa95532_0 --> conda-forge::conda-4.11.0-py38haa244fe_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  openssl              pkgs/main::openssl-1.1.1l-h2bbff1b_0 --> conda-forge::openssl-1.1.1l-h8ffe710_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "tensorboard-1.15.0   | 3.8 MB    |            |   0% \n",
      "tensorboard-1.15.0   | 3.8 MB    |            |   0% \n",
      "tensorboard-1.15.0   | 3.8 MB    | 6          |   6% \n",
      "tensorboard-1.15.0   | 3.8 MB    | #4         |  14% \n",
      "tensorboard-1.15.0   | 3.8 MB    | #8         |  19% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ##4        |  24% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ##9        |  29% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ###4       |  35% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ####1      |  42% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ####9      |  49% \n",
      "tensorboard-1.15.0   | 3.8 MB    | #####9     |  59% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ######6    |  66% \n",
      "tensorboard-1.15.0   | 3.8 MB    | #######3   |  74% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ########3  |  83% \n",
      "tensorboard-1.15.0   | 3.8 MB    | #########1 |  91% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ########## | 100% \n",
      "tensorboard-1.15.0   | 3.8 MB    | ########## | 100% \n",
      "\n",
      "markdown-3.3.4       | 144 KB    |            |   0% \n",
      "markdown-3.3.4       | 144 KB    | #1         |  11% \n",
      "markdown-3.3.4       | 144 KB    | ########## | 100% \n",
      "markdown-3.3.4       | 144 KB    | ########## | 100% \n",
      "\n",
      "libprotobuf-3.17.2   | 1.9 MB    |            |   0% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | 8          |   8% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | #5         |  16% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | ##2        |  23% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | ####3      |  44% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | #####3     |  54% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | ######4    |  65% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | ########2  |  82% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | ########## | 100% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1l       | 5.7 MB    |            |   0% \n",
      "openssl-1.1.1l       | 5.7 MB    |            |   1% \n",
      "openssl-1.1.1l       | 5.7 MB    | 6          |   7% \n",
      "openssl-1.1.1l       | 5.7 MB    | #4         |  14% \n",
      "openssl-1.1.1l       | 5.7 MB    | #9         |  20% \n",
      "openssl-1.1.1l       | 5.7 MB    | ##7        |  27% \n",
      "openssl-1.1.1l       | 5.7 MB    | ###3       |  33% \n",
      "openssl-1.1.1l       | 5.7 MB    | ###9       |  40% \n",
      "openssl-1.1.1l       | 5.7 MB    | ####6      |  47% \n",
      "openssl-1.1.1l       | 5.7 MB    | #####3     |  53% \n",
      "openssl-1.1.1l       | 5.7 MB    | #####9     |  60% \n",
      "openssl-1.1.1l       | 5.7 MB    | ######6    |  66% \n",
      "openssl-1.1.1l       | 5.7 MB    | #######2   |  73% \n",
      "openssl-1.1.1l       | 5.7 MB    | #######8   |  79% \n",
      "openssl-1.1.1l       | 5.7 MB    | ########4  |  85% \n",
      "openssl-1.1.1l       | 5.7 MB    | #########  |  90% \n",
      "openssl-1.1.1l       | 5.7 MB    | #########6 |  97% \n",
      "openssl-1.1.1l       | 5.7 MB    | ########## | 100% \n",
      "\n",
      "grpcio-1.42.0        | 1.9 MB    |            |   0% \n",
      "grpcio-1.42.0        | 1.9 MB    | 2          |   3% \n",
      "grpcio-1.42.0        | 1.9 MB    | #          |  10% \n",
      "grpcio-1.42.0        | 1.9 MB    | #6         |  17% \n",
      "grpcio-1.42.0        | 1.9 MB    | ##4        |  24% \n",
      "grpcio-1.42.0        | 1.9 MB    | ###2       |  32% \n",
      "grpcio-1.42.0        | 1.9 MB    | ####7      |  47% \n",
      "grpcio-1.42.0        | 1.9 MB    | #####7     |  57% \n",
      "grpcio-1.42.0        | 1.9 MB    | ######5    |  66% \n",
      "grpcio-1.42.0        | 1.9 MB    | #######5   |  75% \n",
      "grpcio-1.42.0        | 1.9 MB    | ########6  |  87% \n",
      "grpcio-1.42.0        | 1.9 MB    | #########6 |  96% \n",
      "grpcio-1.42.0        | 1.9 MB    | ########## | 100% \n",
      "\n",
      "conda-4.11.0         | 16.9 MB   |            |   0% \n",
      "conda-4.11.0         | 16.9 MB   | 1          |   1% \n",
      "conda-4.11.0         | 16.9 MB   | 2          |   2% \n",
      "conda-4.11.0         | 16.9 MB   | 3          |   3% \n",
      "conda-4.11.0         | 16.9 MB   | 4          |   4% \n",
      "conda-4.11.0         | 16.9 MB   | 5          |   5% \n",
      "conda-4.11.0         | 16.9 MB   | 6          |   7% \n",
      "conda-4.11.0         | 16.9 MB   | 7          |   7% \n",
      "conda-4.11.0         | 16.9 MB   | 8          |   9% \n",
      "conda-4.11.0         | 16.9 MB   | 9          |  10% \n",
      "conda-4.11.0         | 16.9 MB   | #          |  11% \n",
      "conda-4.11.0         | 16.9 MB   | #2         |  12% \n",
      "conda-4.11.0         | 16.9 MB   | #3         |  13% \n",
      "conda-4.11.0         | 16.9 MB   | #3         |  14% \n",
      "conda-4.11.0         | 16.9 MB   | #5         |  16% \n",
      "conda-4.11.0         | 16.9 MB   | #7         |  17% \n",
      "conda-4.11.0         | 16.9 MB   | #8         |  18% \n",
      "conda-4.11.0         | 16.9 MB   | #9         |  20% \n",
      "conda-4.11.0         | 16.9 MB   | ##         |  21% \n",
      "conda-4.11.0         | 16.9 MB   | ##1        |  22% \n",
      "conda-4.11.0         | 16.9 MB   | ##3        |  23% \n",
      "conda-4.11.0         | 16.9 MB   | ##4        |  24% \n",
      "conda-4.11.0         | 16.9 MB   | ##5        |  25% \n",
      "conda-4.11.0         | 16.9 MB   | ##6        |  26% \n",
      "conda-4.11.0         | 16.9 MB   | ##8        |  28% \n",
      "conda-4.11.0         | 16.9 MB   | ##9        |  30% \n",
      "conda-4.11.0         | 16.9 MB   | ###1       |  31% \n",
      "conda-4.11.0         | 16.9 MB   | ###2       |  32% \n",
      "conda-4.11.0         | 16.9 MB   | ###3       |  34% \n",
      "conda-4.11.0         | 16.9 MB   | ###4       |  35% \n",
      "conda-4.11.0         | 16.9 MB   | ###5       |  36% \n",
      "conda-4.11.0         | 16.9 MB   | ###6       |  36% \n",
      "conda-4.11.0         | 16.9 MB   | ###7       |  37% \n",
      "conda-4.11.0         | 16.9 MB   | ###7       |  37% \n",
      "conda-4.11.0         | 16.9 MB   | ###7       |  38% \n",
      "conda-4.11.0         | 16.9 MB   | ###8       |  38% \n",
      "conda-4.11.0         | 16.9 MB   | ###8       |  38% \n",
      "conda-4.11.0         | 16.9 MB   | ###8       |  39% \n",
      "conda-4.11.0         | 16.9 MB   | ###8       |  39% \n",
      "conda-4.11.0         | 16.9 MB   | ###9       |  39% \n",
      "conda-4.11.0         | 16.9 MB   | ###9       |  39% \n",
      "conda-4.11.0         | 16.9 MB   | ###9       |  40% \n",
      "conda-4.11.0         | 16.9 MB   | ###9       |  40% \n",
      "conda-4.11.0         | 16.9 MB   | ###9       |  40% \n",
      "conda-4.11.0         | 16.9 MB   | ####       |  40% \n",
      "conda-4.11.0         | 16.9 MB   | ####       |  40% \n",
      "conda-4.11.0         | 16.9 MB   | ####       |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####       |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####       |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####       |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  41% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####1      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####2      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####2      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####2      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####2      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####2      |  42% \n",
      "conda-4.11.0         | 16.9 MB   | ####2      |  43% \n",
      "conda-4.11.0         | 16.9 MB   | ####2      |  43% \n",
      "conda-4.11.0         | 16.9 MB   | ####3      |  43% \n",
      "conda-4.11.0         | 16.9 MB   | ####3      |  43% \n",
      "conda-4.11.0         | 16.9 MB   | ####3      |  44% \n",
      "conda-4.11.0         | 16.9 MB   | ####4      |  44% \n",
      "conda-4.11.0         | 16.9 MB   | ####4      |  45% \n",
      "conda-4.11.0         | 16.9 MB   | ####5      |  45% \n",
      "conda-4.11.0         | 16.9 MB   | ####6      |  47% \n",
      "conda-4.11.0         | 16.9 MB   | ####8      |  48% \n",
      "conda-4.11.0         | 16.9 MB   | ####9      |  49% \n",
      "conda-4.11.0         | 16.9 MB   | #####      |  50% \n",
      "conda-4.11.0         | 16.9 MB   | #####1     |  52% \n",
      "conda-4.11.0         | 16.9 MB   | #####3     |  53% \n",
      "conda-4.11.0         | 16.9 MB   | #####4     |  54% \n",
      "conda-4.11.0         | 16.9 MB   | #####6     |  56% \n",
      "conda-4.11.0         | 16.9 MB   | #####7     |  58% \n",
      "conda-4.11.0         | 16.9 MB   | #####9     |  59% \n",
      "conda-4.11.0         | 16.9 MB   | ######1    |  61% \n",
      "conda-4.11.0         | 16.9 MB   | ######2    |  63% \n",
      "conda-4.11.0         | 16.9 MB   | ######4    |  65% \n",
      "conda-4.11.0         | 16.9 MB   | ######6    |  67% \n",
      "conda-4.11.0         | 16.9 MB   | ######8    |  69% \n",
      "conda-4.11.0         | 16.9 MB   | #######    |  71% \n",
      "conda-4.11.0         | 16.9 MB   | #######2   |  73% \n",
      "conda-4.11.0         | 16.9 MB   | #######5   |  75% \n",
      "conda-4.11.0         | 16.9 MB   | #######7   |  78% \n",
      "conda-4.11.0         | 16.9 MB   | #######9   |  80% \n",
      "conda-4.11.0         | 16.9 MB   | ########1  |  82% \n",
      "conda-4.11.0         | 16.9 MB   | ########3  |  84% \n",
      "conda-4.11.0         | 16.9 MB   | ########5  |  86% \n",
      "conda-4.11.0         | 16.9 MB   | ########7  |  88% \n",
      "conda-4.11.0         | 16.9 MB   | ########9  |  90% \n",
      "conda-4.11.0         | 16.9 MB   | #########1 |  91% \n",
      "conda-4.11.0         | 16.9 MB   | #########2 |  93% \n",
      "conda-4.11.0         | 16.9 MB   | #########4 |  94% \n",
      "conda-4.11.0         | 16.9 MB   | #########6 |  96% \n",
      "conda-4.11.0         | 16.9 MB   | #########8 |  98% \n",
      "conda-4.11.0         | 16.9 MB   | #########9 | 100% \n",
      "conda-4.11.0         | 16.9 MB   | ########## | 100% \n",
      "\n",
      "ca-certificates-2021 | 176 KB    |            |   0% \n",
      "ca-certificates-2021 | 176 KB    | 9          |   9% \n",
      "ca-certificates-2021 | 176 KB    | #8         |  18% \n",
      "ca-certificates-2021 | 176 KB    | #####4     |  55% \n",
      "ca-certificates-2021 | 176 KB    | ######3    |  64% \n",
      "ca-certificates-2021 | 176 KB    | ########## | 100% \n",
      "ca-certificates-2021 | 176 KB    | ########## | 100% \n",
      "\n",
      "protobuf-3.17.2      | 257 KB    |            |   0% \n",
      "protobuf-3.17.2      | 257 KB    | 6          |   6% \n",
      "protobuf-3.17.2      | 257 KB    | ####9      |  50% \n",
      "protobuf-3.17.2      | 257 KB    | #######4   |  75% \n",
      "protobuf-3.17.2      | 257 KB    | ########## | 100% \n",
      "protobuf-3.17.2      | 257 KB    | ########## | 100% \n",
      "\n",
      "certifi-2021.10.8    | 145 KB    |            |   0% \n",
      "certifi-2021.10.8    | 145 KB    | #1         |  11% \n",
      "certifi-2021.10.8    | 145 KB    | ########## | 100% \n",
      "\n",
      "python_abi-3.8       | 4 KB      |            |   0% \n",
      "python_abi-3.8       | 4 KB      | ########## | 100% \n",
      "python_abi-3.8       | 4 KB      | ########## | 100% \n",
      "\n",
      "absl-py-1.0.0        | 95 KB     |            |   0% \n",
      "absl-py-1.0.0        | 95 KB     | ######7    |  67% \n",
      "absl-py-1.0.0        | 95 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede **cargar** Tensorboard utilizando Jupyter notebook, Jupyter lab o Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Tensorboard genera unos archivos \"logs\" o \"registros\" del codigo que se ejecuta y que deben ser guaradados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = 'logs1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de querer recargar la extensión se puede utilizar el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para limpiar los `logs` y dejar libre el folder se pueden correr los siguientes comandos:\n",
    "\n",
    "- Para linux: `rm -rf logs`\n",
    "- Para colab: `!rm -rf /logs/`\n",
    "- Para windows utilizar ambos:\n",
    "    - `!taskkill /f /t /im tensorboard.exe`\n",
    "    - `!del /a /s /q /f logs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se estan corriendo distintos experimentos, todos ellos se pueden guardar para luego compararlos creando logs guardados con una marca de tiempo utilizando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTO: el proceso con PID 6184 (proceso secundario de PID 8852)\n",
      "ha sido terminado.\n",
      "CORRECTO: el proceso con PID 8852 (proceso secundario de PID 5372)\n",
      "ha sido terminado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No se pudo encontrar C:\\Users\\LENOVO\\Downloads\\logs\n"
     ]
    }
   ],
   "source": [
    "# Clear out any prior log data.\n",
    "!taskkill /f /t /im tensorboard.exe\n",
    "!del /a /s /q /f logs\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "log_folder = f\"{log_folder}/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(log_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo\n",
    "\n",
    "Usaremos TensorBoard para visualizar las metricas de un modelo. Construiremos para ello un modelo simple de clasificación de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0 #normalización\n",
    "class_names = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine']\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficando imagenes de entrenamiento con TensorBoard\n",
    "\n",
    "Este tablero (dashboard) tiene imágenes que muestran los pesos. Ajustando con los botones deslizantes los pesos para las distintas epocas.\n",
    "\n",
    "Se puede usar la API de resumen de imagenes de TensorFlow para visualizar las imagenes de entrenamiento. Esto es especialmente util cuando se trabaja con datos de imágenes como en este caso. Anteriormente se habían especificado las imagenes con un tamaño de 28x28, por eso, es importante reajustar el tamaño de las imagenes antes de escribirlas en TensorFlow. Tambien se necesita especificar el canal a 1 porque las imagenes estan en escala de grises. Después, se utuliza la función **file_write** para escribir las imagenes en TensorBoard. \n",
    "\n",
    "En este caso las imágenes indexadas de 10 a 30 seran mostradas en TensorBoar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar imagenes para mostrar en Tensorboard.\n",
    "with file_writer.as_default():\n",
    "    images = np.reshape(X_train[10:30], (-1, 28, 28, 1))\n",
    "    tf.summary.image(\"20 Digits\", images, max_outputs=25, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para especificar la retrollamada (call back) durante el ajuste del modelo se debe importar Tensorboard. Esta retrollamada es responsable de registrar los eventos como los histogramas de activación, gráficas de resumen de las métricas o gráficos de visualización de perfilado (profiling: duración de ejecución de un código) y entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la retrollamada (callback) y especificamos el directorio de los registros (logs) utilizando el código `log_dir`. Otros de los parámetros que se utilizan son:\n",
    "\n",
    "- `histogram_freq`: Es la frecuencia con la que se computa la activación y pesos de los histogramas por capas del modelo. Cuando se deja en cerp significa que los histogramas no seran computados. Para esto se debe trabajar con un conjunto de validación.\n",
    "- `write_graph`:  Dicta si el gráfico sera visualizaso en TensorBoard.\n",
    "- `write_images`: Cuando es verdadero (True), los pesos del modelo son visualizados como una imagen en TensorBoard\n",
    "- `update_freq_`: Determina como las perdidas y metricas son escritas en TensorBoard. Cuando se establece como un entero, por ejemplo 100, las perdidas y metricas son registradas cada 100 lotes. Cuando se define por lotes, las metricas son establecidas despues de cada lote y cuando se define por epoca, se establecen despues de cada epoca.\n",
    "- `profile_batch`: Determina que lotes (batches) seran medidos (profiled). Por defecto, el segundo lote es medido.\n",
    "- `embeddings_freq`: Frecuencia con que las capas de embedding del modelo son visualizadas, con cero no son visualizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el modelo llamando la retrollamada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 2.1230 - accuracy: 0.2919 - val_loss: 1.4197 - val_accuracy: 0.7575\n",
      "Epoch 2/8\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 1.2958 - accuracy: 0.7487 - val_loss: 0.9102 - val_accuracy: 0.8383\n",
      "Epoch 3/8\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.8777 - accuracy: 0.8176 - val_loss: 0.6683 - val_accuracy: 0.8685\n",
      "Epoch 4/8\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.6725 - accuracy: 0.8509 - val_loss: 0.5430 - val_accuracy: 0.8830\n",
      "Epoch 5/8\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.5657 - accuracy: 0.8653 - val_loss: 0.4709 - val_accuracy: 0.8932\n",
      "Epoch 6/8\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4985 - accuracy: 0.8771 - val_loss: 0.4255 - val_accuracy: 0.8991\n",
      "Epoch 7/8\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4517 - accuracy: 0.8849 - val_loss: 0.3937 - val_accuracy: 0.9055\n",
      "Epoch 8/8\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4280 - accuracy: 0.8879 - val_loss: 0.3703 - val_accuracy: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28cd184d8e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=0.000004)\n",
    "\n",
    "model.compile(optimizer=optim,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_folder, histogram_freq=1)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "        y=y_train, \n",
    "        epochs=8, \n",
    "        validation_data=(X_test, y_test), \n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución de Tensorboard\n",
    "\n",
    "Se puede ejecutar con alguno de los siguientes códigos:\n",
    "\n",
    "- Si se instaló con pip y se quiere correr en la terminal: `tensorboard --logdir=log`\n",
    "- Si se va a correr en el cuaderno: `%tensorboard --logdir={log_folder}`\n",
    "- Si se desea ver en el navegador: http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={log_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se desea compartir los resultados obtenidos en Tensorboard basta con oprimir el botón **upload** que pedira correr un comando similar al mostrado a continuación. Resulta mejor correrlo desde la consola o en colab.\n",
    "\n",
    "`tensorboard dev upload --logdir 'logs2/fit/20211121-184313'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión en TensorBoard\n",
    "\n",
    "Usando el mismo ejemplo, puede registrar la matriz de confusión para todas las épocas. Primero, se define una función que devolverá una figura Matplotlib que mantiene la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):    \n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "\n",
    "    digit = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    digit = tf.expand_dims(digit, 0)\n",
    "\n",
    "    return digit\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names): \n",
    "    figure = plt.figure(figsize=(8, 8)) \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent) \n",
    "    plt.title(\"Confusion matrix\") \n",
    "    plt.colorbar() \n",
    "    tick_marks = np.arange(len(class_names)) \n",
    "    plt.xticks(tick_marks, class_names, rotation=45) \n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)  \n",
    "    threshold = cm.max() / 2. \n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):   \n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"   \n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)  \n",
    "    \n",
    "    plt.tight_layout() \n",
    "    plt.ylabel('True label') \n",
    "    plt.xlabel('Predicted label') \n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, borramos los registros anteriores, definimos el directorio de registro para la matriz de confusión, y creamos una variable de escritor para escribir en la carpeta de registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTO: el proceso con PID 6884 (proceso secundario de PID 13552)\n",
      "ha sido terminado.\n",
      "CORRECTO: el proceso con PID 13552 (proceso secundario de PID 16304)\n",
      "ha sido terminado.\n"
     ]
    }
   ],
   "source": [
    "# Clear out any prior log data.\n",
    "!taskkill /f /t /im tensorboard.exe\n",
    "!del /a /s /q /f logs\n",
    "\n",
    "log_folder2 = 'logs2'\n",
    "# Sets up a timestamped log directory.\n",
    "log_folder2 = f\"{log_folder2}/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(log_folder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso que sigue es crear una función que hará predicciones del modelo y registrara la matriz de confusión como una imagen. Después de eso, se utiliza `File_Writer` para escribir la matriz de confusión al directorio de registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_test, predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "    \n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto será seguido por la definición de la retrollamada de Tensorboard y el Lambdacallback. El Lambdacallback registrará la matriz de confusión en cada época. Finalmente, se corre el modelo utilizando estos dos callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3986 - accuracy: 0.8940 - val_loss: 0.3423 - val_accuracy: 0.9121\n",
      "Epoch 2/8\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3833 - accuracy: 0.8975 - val_loss: 0.3308 - val_accuracy: 0.9132\n",
      "Epoch 3/8\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3693 - accuracy: 0.9008 - val_loss: 0.3209 - val_accuracy: 0.9158\n",
      "Epoch 4/8\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3588 - accuracy: 0.9028 - val_loss: 0.3123 - val_accuracy: 0.9173\n",
      "Epoch 5/8\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3487 - accuracy: 0.9049 - val_loss: 0.3048 - val_accuracy: 0.9188\n",
      "Epoch 6/8\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3408 - accuracy: 0.9082 - val_loss: 0.2980 - val_accuracy: 0.9197\n",
      "Epoch 7/8\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3314 - accuracy: 0.9103 - val_loss: 0.2915 - val_accuracy: 0.9213\n",
      "Epoch 8/8\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3254 - accuracy: 0.9112 - val_loss: 0.2858 - val_accuracy: 0.9223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x210ca2d0b20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "   TensorBoard(log_dir=log_folder2, \n",
    "               histogram_freq=1, \n",
    "               write_graph=True,\n",
    "               write_images=True,\n",
    "               update_freq='epoch',\n",
    "               profile_batch=2,\n",
    "               embeddings_freq=1),\n",
    "   keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "]\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=8,\n",
    "          validation_split=0.2,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run TensorBoard and check the confusion matrix on the Images tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bfd464028af64e28\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bfd464028af64e28\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={log_folder2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ajuste de hiperparámetros con TensorBoard\n",
    "\n",
    "Tensorborad tambien se puede utilizar para visualizar la optimización de los hiperparámetros, por ejemplo, el número de lotes o la tasa de aprendizaje. Se puede revisar los hiperparámetros del modelo manualmente o usando una optimización automatizada y visualizandolos en TensorBoard. El tablero está disponible bajo la pestaña HPARAMS. Para esto se debe lipiar los registros previos e importar el paquete hparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: no se encontr¢ el proceso \"tensorboard.exe\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\events.out.tfevents.1637626001.LAPTOP-QV7ELDEM.16304.6.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\events.out.tfevents.1637627118.LAPTOP-QV7ELDEM.16304.25.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 0\\events.out.tfevents.1637626005.LAPTOP-QV7ELDEM.16304.7.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 1\\events.out.tfevents.1637626035.LAPTOP-QV7ELDEM.16304.8.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 10\\events.out.tfevents.1637626501.LAPTOP-QV7ELDEM.16304.17.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 11\\events.out.tfevents.1637626561.LAPTOP-QV7ELDEM.16304.18.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 12\\events.out.tfevents.1637626612.LAPTOP-QV7ELDEM.16304.19.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 13\\events.out.tfevents.1637626674.LAPTOP-QV7ELDEM.16304.20.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 14\\events.out.tfevents.1637626753.LAPTOP-QV7ELDEM.16304.21.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 15\\events.out.tfevents.1637626806.LAPTOP-QV7ELDEM.16304.22.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 16\\events.out.tfevents.1637626857.LAPTOP-QV7ELDEM.16304.23.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 17\\events.out.tfevents.1637626924.LAPTOP-QV7ELDEM.16304.24.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 2\\events.out.tfevents.1637626088.LAPTOP-QV7ELDEM.16304.9.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 3\\events.out.tfevents.1637626133.LAPTOP-QV7ELDEM.16304.10.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 4\\events.out.tfevents.1637626186.LAPTOP-QV7ELDEM.16304.11.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 5\\events.out.tfevents.1637626239.LAPTOP-QV7ELDEM.16304.12.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 6\\events.out.tfevents.1637626283.LAPTOP-QV7ELDEM.16304.13.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 7\\events.out.tfevents.1637626338.LAPTOP-QV7ELDEM.16304.14.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 8\\events.out.tfevents.1637626401.LAPTOP-QV7ELDEM.16304.15.v2\n",
      "Archivo eliminado: C:\\Users\\JULIETH LOPEZ\\Documents\\Diplomado_IA_AP\\logs\\hparam_tuning\\Experiment 9\\events.out.tfevents.1637626451.LAPTOP-QV7ELDEM.16304.16.v2\n"
     ]
    }
   ],
   "source": [
    "# Clear out any prior log data.\n",
    "!taskkill /f /t /im tensorboard.exe\n",
    "!del /a /s /q /f logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs3\"\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es definir los parámetros a sintonizar. En este caso, las unidades en la capa densa, la tasa de deserción (dropout rate) y la función del optimizador se sintonizarán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([300, 200,512]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1,0.5))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se usa `tf.summary.create_file_writer` para definir la carpeta donde los registros serán guardados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(f'{logdir}/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con eso, se debe definir el modelo como se hizo anteriormente sin embargo, la diferencia está en el número de neuronas en la primera capa densa, la tasa de abandono (drop out rate) y la función del optimizador, ya que estas no se codificarán.\n",
    "\n",
    "Esto se hará en una función que se utilizará más adelante, mientras ejecute los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hparams):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS],  activation='relu'),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=5)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función que se debe crear ejecutará la función anterior utilizando los parámetros definidos anteriormente. Luego se registrará la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(experiment_dir, hparams):\n",
    "\n",
    "    with tf.summary.create_file_writer(experiment_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy = create_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esto, debe ejecutar esta función para todas las combinaciones de los parámetros definidos anteriormente. Cada uno de los experimentos se almacenará en su propia carpeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Experiment: Experiment 0\n",
      "{'num_units': 200, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2514 - accuracy: 0.9271\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1104 - accuracy: 0.9668\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0773 - accuracy: 0.9762\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0590 - accuracy: 0.9812\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0493 - accuracy: 0.9841\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9789\n",
      "Starting Experiment: Experiment 1\n",
      "{'num_units': 200, 'dropout': 0.1, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2497 - accuracy: 0.9276\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1204 - accuracy: 0.9649\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0910 - accuracy: 0.9743\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0778 - accuracy: 0.9784\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0676 - accuracy: 0.9812\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9777\n",
      "Starting Experiment: Experiment 2\n",
      "{'num_units': 200, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6484 - accuracy: 0.8289\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3488 - accuracy: 0.9011\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2950 - accuracy: 0.9164\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2614 - accuracy: 0.9259\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2354 - accuracy: 0.9342\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2065 - accuracy: 0.9429\n",
      "Starting Experiment: Experiment 3\n",
      "{'num_units': 200, 'dropout': 0.5, 'optimizer': 'adam'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3479 - accuracy: 0.8975\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1853 - accuracy: 0.9453\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1502 - accuracy: 0.9546\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1317 - accuracy: 0.9603\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1168 - accuracy: 0.9634\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.9757\n",
      "Starting Experiment: Experiment 4\n",
      "{'num_units': 200, 'dropout': 0.5, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3485 - accuracy: 0.8988\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2059 - accuracy: 0.9428\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1814 - accuracy: 0.9508\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1675 - accuracy: 0.9556\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1643 - accuracy: 0.9583\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1132 - accuracy: 0.9734\n",
      "Starting Experiment: Experiment 5\n",
      "{'num_units': 200, 'dropout': 0.5, 'optimizer': 'sgd'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.7875 - accuracy: 0.7713\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4250 - accuracy: 0.8771\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3603 - accuracy: 0.8974\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3184 - accuracy: 0.9081\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2903 - accuracy: 0.9179\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2087 - accuracy: 0.9385\n",
      "Starting Experiment: Experiment 6\n",
      "{'num_units': 300, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2326 - accuracy: 0.9321\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0978 - accuracy: 0.9702\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0681 - accuracy: 0.9786\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0518 - accuracy: 0.9834\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0398 - accuracy: 0.9874\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9774\n",
      "Starting Experiment: Experiment 7\n",
      "{'num_units': 300, 'dropout': 0.1, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2277 - accuracy: 0.9337\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1079 - accuracy: 0.9685\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0837 - accuracy: 0.9766\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0689 - accuracy: 0.9809\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0587 - accuracy: 0.9839\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.0878 - accuracy: 0.9786\n",
      "Starting Experiment: Experiment 8\n",
      "{'num_units': 300, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.6341 - accuracy: 0.8385\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3438 - accuracy: 0.9038\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2918 - accuracy: 0.9174\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2595 - accuracy: 0.9258\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2348 - accuracy: 0.9338\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2060 - accuracy: 0.9419\n",
      "Starting Experiment: Experiment 9\n",
      "{'num_units': 300, 'dropout': 0.5, 'optimizer': 'adam'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3013 - accuracy: 0.9093\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1546 - accuracy: 0.9533\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1277 - accuracy: 0.9609\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1059 - accuracy: 0.9668\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0966 - accuracy: 0.9698\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9793\n",
      "Starting Experiment: Experiment 10\n",
      "{'num_units': 300, 'dropout': 0.5, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3070 - accuracy: 0.9100\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1810 - accuracy: 0.9496\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1575 - accuracy: 0.9587\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1473 - accuracy: 0.9620\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1397 - accuracy: 0.9650\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1105 - accuracy: 0.9744\n",
      "Starting Experiment: Experiment 11\n",
      "{'num_units': 300, 'dropout': 0.5, 'optimizer': 'sgd'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7510 - accuracy: 0.7843\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4060 - accuracy: 0.8834\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3393 - accuracy: 0.9039\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2995 - accuracy: 0.9148\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2696 - accuracy: 0.9224\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2015 - accuracy: 0.9426\n",
      "Starting Experiment: Experiment 12\n",
      "{'num_units': 512, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2100 - accuracy: 0.9388\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0887 - accuracy: 0.9727\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0593 - accuracy: 0.9813\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0438 - accuracy: 0.9859\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0351 - accuracy: 0.9888\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9784\n",
      "Starting Experiment: Experiment 13\n",
      "{'num_units': 512, 'dropout': 0.1, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 17s 8ms/step - loss: 0.2099 - accuracy: 0.9387\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0988 - accuracy: 0.9713\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0740 - accuracy: 0.9786\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0594 - accuracy: 0.9840\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0518 - accuracy: 0.9863\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0834 - accuracy: 0.9798\n",
      "Starting Experiment: Experiment 14\n",
      "{'num_units': 512, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6318 - accuracy: 0.8396\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3336 - accuracy: 0.9071\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2836 - accuracy: 0.9195\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2503 - accuracy: 0.9295\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2274 - accuracy: 0.9365\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9421\n",
      "Starting Experiment: Experiment 15\n",
      "{'num_units': 512, 'dropout': 0.5, 'optimizer': 'adam'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2706 - accuracy: 0.9186\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1366 - accuracy: 0.9582\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1079 - accuracy: 0.9668\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0927 - accuracy: 0.9707\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0812 - accuracy: 0.9739\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9769\n",
      "Starting Experiment: Experiment 16\n",
      "{'num_units': 512, 'dropout': 0.5, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2725 - accuracy: 0.9190\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.1586 - accuracy: 0.9559\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1360 - accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1246 - accuracy: 0.9690\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1181 - accuracy: 0.9713\n",
      "313/313 [==============================] - 3s 5ms/step - loss: 0.0976 - accuracy: 0.9777: \n",
      "Starting Experiment: Experiment 17\n",
      "{'num_units': 512, 'dropout': 0.5, 'optimizer': 'sgd'}\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.6856 - accuracy: 0.8090\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3792 - accuracy: 0.8910\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3170 - accuracy: 0.9095\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2793 - accuracy: 0.9204\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2519 - accuracy: 0.9281\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1986 - accuracy: 0.9449\n"
     ]
    }
   ],
   "source": [
    "experiment_no = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,}\n",
    "\n",
    "            experiment_name = f'Experiment {experiment_no}'\n",
    "            print(f'Starting Experiment: {experiment_name}')\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            experiment(f'{logdir}/hparam_tuning/' + experiment_name, hparams)\n",
    "            experiment_no += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se ejecuta Tensorboard para ver la visualización que se vio al comienzo de estenotebook. En la pestaña *Hparams*, se muestran todos los modelos corridos y su precisión (accuracy), dropout rate y capas densas. *Parallel Coordinates View* muestra cada corrida como una línea que se mueve a través de un eje para cada uno de los hiperparamétricos y la métrica de precisión. Al hacer clic en uno de ellos, mostrará los ensayos de los hiperparametros y *Scatter Plot View* visualiza la comparación entre los hiperparaméteres y las métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ad8e843ce670581\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ad8e843ce670581\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={logdir}/hparam_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Profiler\n",
    "\n",
    "También puede realizar un seguimiento del rendimiento de los modelos de TensorFlow utilizando la herramienta `Profiler` que resulta crucial para comprender el consumo de recursos de recursos de hardware de las operaciones de TensorFlow. Esta herramienta solo está disponible para quienes cuenten con equipos con GPU. Quienes deseen pueden hacer uso especial de la siguiente aplicación de la herramienta:\n",
    "\n",
    "- Input pipeline analyzer: Se puede utilizar para analizar las ineficiencias en la tubería de entrada (input pipeline) del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
