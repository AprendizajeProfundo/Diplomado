{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center> Introducción a Stanza para NLP</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Repo oficial de [stanza](https://github.com/stanfordnlp/stanza)\n",
    "2. [Stanza](https://stanfordnlp.github.io/stanza/index.html) in Stanford \n",
    "3. [Speech and Language Processing (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Fuente</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este cuaderno es una adaptación y traducción libre de los cuadernos disponibles en el repo oficial de [stanza](https://github.com/stanfordnlp/stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Instalación de Stanza](#Instalación-de-Stanza)\n",
    "* [Descarga de modelos](#Descarga-de-modelos)\n",
    "* [Descarga de modelos](#Descarga-de-modelos)\n",
    "* [Procesamiento de texto](#Procesamiento-de-texto)\n",
    "* [Acceso a las anotaciones](#Acceso-a-las-anotaciones)\n",
    "* [Recursos](#Recursos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56LiYCkPM7V_"
   },
   "source": [
    "Stanza es una colección de herramientas precisas y eficientes para el análisis lingüístico de muchos idiomas humanos. Desde el texto en bruto hasta el análisis sintáctico y el reconocimiento de entidades, Stanza ofrece modelos de procesamiento del lenguaje natural de vanguardia para los idiomas que elijas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56LiYCkPM7V_"
   },
   "source": [
    "Stanza es un paquete de análisis de lenguaje natural en Python. Contiene herramientas que se pueden utilizar en una secuencia de procesamiento para convertir una cadena de texto en lenguaje humano en listas de oraciones y palabras, generar las formas base de esas palabras, sus partes del discurso y características morfológicas, proporcionar un análisis de dependencia estructural sintáctica y reconocer entidades nombradas. Esta herramienta está diseñada para ser utilizada en paralelo en más de 70 idiomas, utilizando el formalismo de Universal Dependencies.\n",
    "\n",
    "Stanza se construye con componentes de redes neuronales altamente precisos que también permiten un entrenamiento y evaluación eficientes con tus propios datos anotados. Los módulos se basan en la biblioteca **PyTorch**. Obtendrás un rendimiento mucho más rápido si ejecutas el software en una máquina con capacidad para GPU.\n",
    "\n",
    "Además, Stanza incluye una interfaz de Python para el paquete Java CoreNLP y hereda funcionalidades adicionales de allí, como el análisis de constituyentes, la resolución de correferencias y la coincidencia de patrones lingüísticos.\n",
    "\n",
    "En resumen, las características de Stanza son:\n",
    "\n",
    "* Implementación nativa en Python que requiere un esfuerzo mínimo para configurar.\n",
    "* Canalización completa de redes neuronales para análisis de texto robusto, que incluye tokenización, expansión de tokens de varias palabras (MWT), lematización, etiquetado de partes del discurso (POS) y características morfológicas, análisis de dependencia y reconocimiento de entidades nombradas.\n",
    "* Modelos neuronales preentrenados que admiten 70 idiomas humanos.\n",
    "* Una interfaz de Python estable y oficialmente mantenida para CoreNLP.\n",
    "\n",
    "A continuación, se muestra un resumen de la canalización de procesamiento de lenguaje natural basada en redes neuronales de Stanza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"https://stanfordnlp.github.io/stanza/assets/images/pipeline.png\" width=\"70%\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56LiYCkPM7V_"
   },
   "source": [
    "En este tutorial, demostraremos cómo configurar Stanza y anotar texto con sus modelos nativos de PNL de red neuronal. Para el uso de la interfaz Python CoreNLP, consulte otros tutoriales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQff4Di5Nnq0"
   },
   "source": [
    "## <span style=\"color:blue\">Instalación de Stanza</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQff4Di5Nnq0"
   },
   "source": [
    "Ten en cuenta que Stanza solo es compatible con Python 3.6 y versiones superiores. La instalación e importación de Stanza son tan sencillas como ejecutar los siguientes comandos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owSj1UtdEvSU"
   },
   "outputs": [],
   "source": [
    "# Install; note that the prefix \"!\" is not needed if you are running in a terminal\n",
    "#!pip install --quiet stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owSj1UtdEvSU"
   },
   "outputs": [],
   "source": [
    "# Importamos el paquete\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ixllwEKeCJg"
   },
   "source": [
    "Si tiene problemas consulte esta \n",
    " [página de ayuda](https://stanfordnlp.github.io/stanfordnlp/installation_usage.html#troubleshooting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeyPs5ARO79d"
   },
   "source": [
    "## <span style=\"color:blue\">Descarga de modelos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeyPs5ARO79d"
   },
   "source": [
    "Puedes descargar modelos con el comando `stanza.download`. El idioma se puede especificar con un nombre de idioma completo (por ejemplo, \"english\") o un código corto (por ejemplo, \"en\"). Aqui instalaremos español \"spanish\": \"es\".\n",
    "\n",
    "Por defecto, los modelos se guardarán en su directorio `~/stanza_resources`. Si desea especificar su propia ruta para guardar los archivos del modelo, puede pasar un argumento `dir=your_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDwRm-KXGcYo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando modelo Español...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8044859a53b44dfe979bbd9ffa41dc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 17:27:15 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2023-06-09 17:27:16 INFO: File exists: /home/cjtorresj/stanza_resources/es/default.zip\n",
      "2023-06-09 17:27:22 INFO: Finished downloading models and saved to /home/cjtorresj/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "# Descarga un modelo en español en el directorio predeterminado.\n",
    "print(\"Descargando modelo Español...\")\n",
    "stanza.download('es')\n",
    "\n",
    "# Download an English model into the default directory\n",
    "#print(\"Downloading English model...\")\n",
    "#stanza.download('en')\n",
    "\n",
    "# Similarly, download a (simplified) Chinese model\n",
    "# Note that you can use verbose=False to turn off all printed messages\n",
    "#print(\"Downloading Chinese model...\")\n",
    "#stanza.download('zh', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HCfQ0SfdmsU"
   },
   "source": [
    "### Más información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HCfQ0SfdmsU"
   },
   "source": [
    "Se proporcionan modelos previamente entrenados para más de 60 idiomas diferentes. Para todos los idiomas, modelos disponibles y los códigos breves de idioma correspondientes, consulte la [página de modelos](https://stanfordnlp.github.io/stanza/models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3-WZJrzWD2o"
   },
   "source": [
    "## <span style=\"color:blue\">Procesamiento de texto</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrnKl2m3fq2f"
   },
   "source": [
    "### Construcción de canalizaciones (tuberías)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrnKl2m3fq2f"
   },
   "source": [
    "\n",
    "Para procesar un fragmento de texto, primero deberá construir una tubería  o canalización `Pipeline` con diferentes unidades de procesamiento `Processor`. La canalización es específica del idioma, por lo que nuevamente deberá especificar el idioma (ver ejemplos).\n",
    "\n",
    "- De forma predeterminada, la canalización incluirá todos los procesadores, incluida la tokenización, la expansión de token de varias palabras, el etiquetado de parte de la voz, la lematización, el análisis de dependencias y el reconocimiento de entidades con nombre (para idiomas admitidos). Sin embargo, siempre puede especificar qué procesadores desea incluir con el argumento `processors`.\n",
    "\n",
    "- La canalización de Stanza es compatible con CUDA, lo que significa que se usará un dispositivo CUDA siempre que esté disponible; de lo contrario, se usarán CPU cuando no se encuentre una GPU. Puede obligar a la canalización a utilizar la CPU independientemente de si establece `use_gpu = False`.\n",
    "\n",
    "- Puede suprimir todos los mensajes impresos configurando `verbose=False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbiTSBDPG53o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 17:27:22 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construyendo una canalización de Español...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5ad6ff12364ea6b674e5467ac6867c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 17:27:23 INFO: Loading these models for language: es (Spanish):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | ancora   |\n",
      "| mwt          | ancora   |\n",
      "| pos          | ancora   |\n",
      "| lemma        | ancora   |\n",
      "| constituency | combined |\n",
      "| depparse     | ancora   |\n",
      "| sentiment    | tass2020 |\n",
      "| ner          | conll02  |\n",
      "===========================\n",
      "\n",
      "2023-06-09 17:27:23 INFO: Using device: cuda\n",
      "2023-06-09 17:27:23 INFO: Loading: tokenize\n",
      "2023-06-09 17:27:25 INFO: Loading: mwt\n",
      "2023-06-09 17:27:25 INFO: Loading: pos\n",
      "2023-06-09 17:27:25 INFO: Loading: lemma\n",
      "2023-06-09 17:27:25 INFO: Loading: constituency\n",
      "2023-06-09 17:27:26 INFO: Loading: depparse\n",
      "2023-06-09 17:27:26 INFO: Loading: sentiment\n",
      "2023-06-09 17:27:26 INFO: Loading: ner\n",
      "2023-06-09 17:27:27 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Cree una canalización en Español, con todos los procesadores de forma predeterminada\n",
    "print(\"Construyendo una canalización de Español...\")\n",
    "es_nlp = stanza.Pipeline('es')\n",
    "\n",
    "# Build an English pipeline, with all processors by default\n",
    "#print(\"Building an English pipeline...\")\n",
    "#en_nlp = stanza.Pipeline('en')\n",
    "\n",
    "# Build a Chinese pipeline, with customized processor list and no logging, and force it to use CPU\n",
    "#print(\"Building a Chinese pipeline...\")\n",
    "#zh_nlp = stanza.Pipeline('zh', processors='tokenize,lemma,pos,depparse', verbose=False, use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Go123Bx8e1wt"
   },
   "source": [
    "### Marcación o Anotación  de texto (Annotating text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Go123Bx8e1wt"
   },
   "source": [
    "Una vez que se ha construido correctamente una canalización, puede obtener anotaciones de un fragmento de texto simplemente pasando la cadena al objeto de canalización. La canalización devolverá un objeto `Document`, que se puede utilizar para acceder a anotaciones detalladas. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_p0h1UTHDMm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stanza.models.common.doc.Document'>\n"
     ]
    }
   ],
   "source": [
    "# Processing texto en Español\n",
    "es_doc = es_nlp(\"Alvaro Montenegro nació en Bogotá. Su carrera profesoral en la Universidad Nacional de Colombia inicio en 1990.\")\n",
    "print(type(es_doc))\n",
    "\n",
    "# Processing English text\n",
    "#en_doc = en_nlp(\"Barack Obama was born in Hawaii. He was elected president in 2008.\")\n",
    "#print(type(en_doc))\n",
    "\n",
    "# Processing Chinese text\n",
    "#zh_doc = zh_nlp(\"达沃斯世界经济论坛是每年全球政商界领袖聚在一起的年度盛事。\")\n",
    "#print(type(zh_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DavwCP9egzNZ"
   },
   "source": [
    "### Más información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DavwCP9egzNZ"
   },
   "source": [
    "Para obtener más información sobre cómo construir una canalización e información sobre diferentes procesos, visite [pipeline page](https://stanfordnlp.github.io/stanfordnlp/pipeline.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_PYLEGziQWR"
   },
   "source": [
    "## <span style=\"color:blue\">Acceso a las anotaciones</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_PYLEGziQWR"
   },
   "source": [
    "Se puede acceder a las anotaciones desde el objeto Documento devuelto.\n",
    "\n",
    "Un `Document` contiene una lista de `Sentence`s y una oración contiene una lista de tokens (`Token`s) y palabras (`Word`s). En su mayor parte, los tokens y las palabras se superponen, pero algunos tokens se pueden dividir en varias palabras, por ejemplo, el token francés `aux` se divide en las palabras `à` y `les`, mientras que en inglés una palabra y un token son equivalentes. Tenga en cuenta que los análisis de dependencia se derivan de `Word`s.\n",
    "\n",
    "Además, un objeto `Span` se usa para representar anotaciones que son parte de un documento, como menciones de entidades nombradas.\n",
    "\n",
    "El siguiente ejemplo itera sobre todas las oraciones y palabras en español e imprime la información de la palabra una por una: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Oración 1]\n",
      "Alvaro      \tAlvaro      \tPROPN \t3\tnsubj       \n",
      "Montenegro  \tMontenegro  \tPROPN \t1\tflat        \n",
      "nació       \tnacer       \tVERB  \t0\troot        \n",
      "en          \ten          \tADP   \t5\tcase        \n",
      "Bogotá      \tBogotá      \tPROPN \t3\tobl         \n",
      ".           \t.           \tPUNCT \t3\tpunct       \n",
      "\n",
      "[Oración 2]\n",
      "Su          \tsu          \tDET   \t2\tdet         \n",
      "carrera     \tcarrera     \tNOUN  \t0\troot        \n",
      "profesoral  \tprofesoral  \tADJ   \t2\tamod        \n",
      "en          \ten          \tADP   \t6\tcase        \n",
      "la          \tel          \tDET   \t6\tdet         \n",
      "Universidad \tUniversidad \tPROPN \t2\tnmod        \n",
      "Nacional    \tNacional    \tPROPN \t6\tflat        \n",
      "de          \tde          \tADP   \t9\tcase        \n",
      "Colombia    \tColombia    \tPROPN \t6\tflat        \n",
      "inicio      \tinicio      \tADJ   \t2\tamod        \n",
      "en          \ten          \tADP   \t12\tcase        \n",
      "1990        \t1990        \tNOUN  \t10\tnmod        \n",
      ".           \t.           \tPUNCT \t2\tpunct       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(es_doc.sentences):\n",
    "    print(\"[Oración {}]\".format(i+1))\n",
    "    for word in sent.words:\n",
    "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
    "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUhWAs8pnnHT"
   },
   "source": [
    "Alternativamente, puede imprimir directamente un objeto `Word` para ver todas sus anotaciones como un diccionario de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 1,\n",
      "  \"text\": \"Alvaro\",\n",
      "  \"lemma\": \"Alvaro\",\n",
      "  \"upos\": \"PROPN\",\n",
      "  \"xpos\": \"np00000\",\n",
      "  \"head\": 3,\n",
      "  \"deprel\": \"nsubj\",\n",
      "  \"start_char\": 0,\n",
      "  \"end_char\": 6\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "word = es_doc.sentences[0].words[0]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AUkCkNIrusq"
   },
   "source": [
    "El siguiente ejemplo itera sobre todas las menciones de entidades nombradas extraídas e imprime sus intervalos y tipos de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mention text                       \tType \tStart\tEnd\n",
      "Alvaro Montenegro                  \tPER  \t    0\t 17\n",
      "Bogotá                             \tLOC  \t   27\t 33\n",
      "Universidad Nacional de Colombia   \tORG  \t   63\t 95\n"
     ]
    }
   ],
   "source": [
    "print(\"{:35s}\\t{:5s}\\t{:5s}\\t{:3s}\".format(\"Mention text\", \"Type\", \"Start\", \"End\"))\n",
    "for ent in es_doc.ents:\n",
    "    print(\"{:35s}\\t{:5s}\\t{:5d}\\t{:3d}\".format(ent.text, ent.type, ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TAQlOsuRoq2V"
   },
   "source": [
    "### Más información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TAQlOsuRoq2V"
   },
   "source": [
    "Para toda la información acerca de los diferentes objetos de datos, visite [data objects page](https://stanfordnlp.github.io/stanza/data_objects.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiiWHxYPpmhd"
   },
   "source": [
    "## <span style=\"color:blue\">Recursos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiiWHxYPpmhd"
   },
   "source": [
    "Para más tutoriales, visite [Tutorials page](https://stanfordnlp.github.io/stanza/tutorials.html).\n",
    "\n",
    "Otros recursos que pueden resultar útiles incluyen:\n",
    "\n",
    "- [Stanza Homepage](https://stanfordnlp.github.io/stanza/index.html)\n",
    "- [FAQs](https://stanfordnlp.github.io/stanza/faq.html)\n",
    "- [GitHub Repo](https://github.com/stanfordnlp/stanza)\n",
    "- [Reporting Issues](https://github.com/stanfordnlp/stanza/issues)\n",
    "- [Stanza System Description Paper](http://arxiv.org/abs/2003.07082)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
