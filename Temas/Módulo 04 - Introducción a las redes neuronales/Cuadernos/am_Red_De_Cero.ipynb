{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Red Neuronal desde Cero</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Descargando Datos de Ejemplo](#Descargando-Datos-de-Ejemplo)\n",
    "* [Leyendo Datos con Pickle](#Leyendo-Datos-con-Pickle)\n",
    "* [Visualizando los Datos](#Visualizando-los-Datos)\n",
    "* [Transformar Datos a Forma Tensorial](#Transformar-Datos-a-Forma-Tensorial)\n",
    "* [Objetivo de la Red Neuronal](#Objetivo-de-la-Red-Neuronal)\n",
    "* [Red Neuronal Artificial From Scratch!](#Red-Neuronal-Artificial-From-Scratch!)\n",
    "    * [Racional](#Racional)\n",
    "    * [Diferenciación Automática](#Diferenciación-Automática)\n",
    "* [Enfoque Matemático de una RNP](#Enfoque-Matemático-de-una-RNP)\n",
    "    * [Modelamiento matemático de una RNP con una capa oculta](#Modelamiento-matemático-de-una-RNP-con-una-capa-oculta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta lección y en el resto del diplomado se requiere tenr instalado Tensorflow. Por favor crre una nuevo ambiente en con Conda es instale una versión fresca de Tensorflow.\n",
    "\n",
    "Desde la versión 2.0 Tensorflow incluye por defecto la API Keras para crear las redes neuronales de manera bastante simple y natural.\n",
    "\n",
    " \n",
    "Siga las siguientes instrucciones en la terminal o haga las instalación desde la interface gráfica de Anaconda. En el ejemplo llamaremos tf al  nuevo ambiente. Conda le instala lo necesario, incluido la versión de Python mas reciente que maneja Tensorflow. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "shell> conda create -n tf tensorflow\n",
    "shell> conda activate tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien la API de tensorflow Keras es bastante útil para resumir una cantidad considerable de líneas de código cuando se construye una red neuronal y se logra flexibilidad en la forma de diseño de la red, es muy importante primero entender cómo construir una red desde cero, en caso que sea necesario volver a cambiar detalles que no son claros o modificables desde la API.\n",
    "\n",
    "Además de esto, ganamos entendimiento profundo sobre cómo es que realmente funciona una red por dentro.\n",
    "\n",
    "Ese es el propósito de éste cuaderno.\n",
    "\n",
    "Construiremos una red neuronal desde cero usando nada más que tensorflow, para luego refactorizar el código hasta llegar a la abstracción visible cuando usamos Keras en una próxima lección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver al Inicio]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Descargando datos de ejemplo </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ésta ocasión haremos un ejercicio de clasificación.\n",
    "\n",
    "Para este fin, usaremos el conjunto de datos de juguete más utilizado para probar modelos de redes neuronales, llamado **MNIST**.\n",
    "\n",
    "**MNIST = Modified National Institute of Standards and Technology database**\n",
    "\n",
    "Esta es una base de datos de dígitos entre cero y nueve digitalizados en escala de grises. \n",
    "\n",
    "Esto siginifica que cada punto de la imagen digitalizada es representada  mediante un byte. Es decir, es posible representar 256 tonos de grises, con valores enteros entre 0 (negro) hasta 255 (blanco). \n",
    "\n",
    "Además, la base de datos contiene una etiqueta (label) para cada  imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcional request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar request para bajar los datos desde la fuente.\n",
    "\n",
    "Use el siguiente código si desea familiarizarse con request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importar librería necesaria para crear archivos localmente\n",
    "from pathlib import Path\n",
    "# Importar libreria necesaria para descargar archivos de la web\n",
    "import requests\n",
    "\n",
    "# Generar Camino Para archivo\n",
    "carpeta_datos= Path(\"../Datos\")\n",
    "\n",
    "# Especificar el nombre del dataset\n",
    "camino = carpeta_datos / \"MNIST\"\n",
    "\n",
    "# Crear directorio en el lugar indicado\n",
    "camino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Posición actual en el equipo\n",
    "donde_estoy=!pwd\n",
    "#Note que la variable se guarda como una lista, no como un string\n",
    "print(\"\\nActualmente estoy en:\\n\\n\",donde_estoy[0],\"\\n\")\n",
    "\n",
    "# Colocar la URL donde se encuentran los datos\n",
    "url = \"http://deeplearning.net/data/mnist/\"\n",
    "# Separar el nombre del archivo (Note que ha sido comprimido)\n",
    "nombre_archivo = \"mnist.pkl.gz\"\n",
    "\n",
    "# Comprobar si existe el archivo a descargar\n",
    "if not (camino / nombre_archivo).exists():\n",
    "    \n",
    "        #Mensaje para el usuario\n",
    "        print(\"\\nBajando Archivo Desde la URL \"+url+nombre_archivo+\"\\n\")\n",
    "        \n",
    "        # Haciendo un request a la url correspondiente y obtener contenido\n",
    "        contenido = requests.get(url + nombre_archivo).content\n",
    "        \n",
    "        # Escribir el contenido binario del request\n",
    "        (camino / nombre_archivo).open(\"wb\").write(contenido)\n",
    "\n",
    "        # Exito, mostrar camino donde se encuentra el archivo descargado\n",
    "print(\"Bajado con éxito en:\\n\\n\"+donde_estoy[0]+\"/\"+camino.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**¿Confundido?**, ¡chequea un [Quickstart](https://es.python-requests.org/es/latest/user/quickstart.html) en la libreria request para comenzar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver al Inicio]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcional  Leyendo Datos con Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo descargado se encuentra en contenido binario.\n",
    "\n",
    "Una librería eficiente para leer archivos binarios, se llama **pickle**.\n",
    "\n",
    "Además, como el archivo esta comprimido (extensión .gzip) necesitaremos la librería **gzip**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Operador lógico with para abrir el archivo descargado y leer bytes (readbytes)\n",
    "with gzip.open((camino / nombre_archivo).as_posix(), \"rb\") as f:\n",
    "        \n",
    "        # desempaqueta la información en diferentes variables (entrenamiento+validación)\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizá, en este punto, sea buena idea leer aquí: [What do the gzip.open() modes mean?](https://www.reddit.com/r/learnpython/comments/88h4yz/what_do_the_gzipopen_modes_mean/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver al Inicio]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos desde Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar rápidamente recomendamos bajr los datos desde la API Keras, ya instalada con Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de Tensorflow:  2.4.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Versión de Tensorflow: \",tf.__version__,\"\\n\")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    " ((x_train, y_train), (x_valid, y_valid)) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplana los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lee los datoa directamente desde la URL, probablemente ya están aplanados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape= (60000, 784)\n",
      "x_valid.shape= (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((-1,784))\n",
    "x_valid = x_valid.reshape((-1,784))\n",
    "print('x_train.shape=',x_train.shape)\n",
    "print('x_valid.shape=',x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Una vez leídos los datos**, podemos por ejemplo, mirar qué forma tienen los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de los Datos de entrenamiento: (60000, 784)\n",
      "Forma de los Datos de validación   : (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de los Datos de entrenamiento:\",x_train.shape)\n",
    "print(\"Forma de los Datos de validación   :\",x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen del dataset clásico tiene un tamaño de 28 x 28 pixeles, con lo cual cada una es representada por 784 números entre cero y 255. \n",
    "\n",
    "Vamos a **visualizar** los datos con **matplotlib**, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imagen de ejemplo:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANb0lEQVR4nO3df6hc9ZnH8c9HrSi2QvRe9RKjt1v8Y4NYW0dZ/BGyFGMURatUkj+KK9JUUGmx4IqLNP8osq4tFRYlXbXpUi3FNhowWEUCWoSQUWJ+bFh1Y7a9SfReEWyqkG7Ms3/cY7nGO2cmc87MGfO8XzDMzHnmzHk43M89M/M9M19HhAAc/Y5pugEAw0HYgSQIO5AEYQeSIOxAEscNc2NjY2MxOTk5zE0CqezevVvvv/++56tVCrvt5ZJ+JulYSf8REQ+UPX5yclLtdrvKJgGUaLVaHWt9v4y3faykf5d0paTFklbaXtzv8wEYrCrv2S+S9HZE7IqIv0r6taRr62kLQN2qhH2hpD/NuT9VLPsM26tst223Z2ZmKmwOQBVVwj7fhwCfO/c2ItZERCsiWuPj4xU2B6CKKmGfkrRozv0zJe2t1g6AQakS9s2SzrH9VdvHS1ohaX09bQGoW99DbxFx0Pbtkn6v2aG3xyNiR22dAahVpXH2iNggaUNNvQAYIE6XBZIg7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRRacpm27sl7Zf0iaSDEdGqoykA9asU9sI/RsT7NTwPgAHiZTyQRNWwh6QXbL9me9V8D7C9ynbbdntmZqbi5gD0q2rYL4mIb0q6UtJttpcc/oCIWBMRrYhojY+PV9wcgH5VCntE7C2upyWtk3RRHU0BqF/fYbd9ku2vfHpb0jJJ2+tqDEC9qnwaf7qkdbY/fZ4nI+L5WroCULu+wx4RuyR9vcZeAAwQQ29AEoQdSIKwA0kQdiAJwg4kUccXYVDRtm3bSuv3339/af2dd97pWHv33XdL173hhhsq1S+++OLSOkYHR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSMIRMbSNtVqtaLfbQ9veqHjjjTdK68uXLy+tdxsrH6Tjjis/FeOaa64prT/55JMdayeccEJfPaGzVquldrvt+Woc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCb7PXoOPPvqotH7XXXeV1gc5jn7uueeW1rudZ7Fjx47S+rp160rrS5Z8bpKgv3n66adL1z3rrLNK6zgyHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2WtQ9rvtkvTCCy9Uev5FixaV1h9++OGOtW7fle9mwYIFpfXjjz++tL5169aOtauvvrp03U2bNpXWTzzxxNI6Pqvrkd3247anbW+fs+wU2y/afqu4Lv+LANC4Xl7G/0LS4YeHuyW9FBHnSHqpuA9ghHUNe0S8LOmDwxZfK2ltcXutpOvqbQtA3fr9gO70iNgnScX1aZ0eaHuV7bbt9szMTJ+bA1DVwD+Nj4g1EdGKiNb4+PigNwegg37D/p7tCUkqrqfrawnAIPQb9vWSbipu3yTp2XraATAoXcfZbT8laamkMdtTkn4s6QFJv7F9i6Q/SvrOIJscdWVjyb247LLLSuuPPvpoaX3x4sV9b7vbd8oPHDhQWl+2bFlp/fLLL+9Yu+OOO0rXXbt2bWn91ltvLa3js7qGPSJWdih9q+ZeAAwQp8sCSRB2IAnCDiRB2IEkCDuQBFM292jv3r0da5deemnpuocOHSqtb9iwobReZWit29dEr7jiitL6wYMHS+vPP/98aX1ycrJj7bzzzitdd2xsrLT+5ptvltYzYspmAIQdyIKwA0kQdiAJwg4kQdiBJAg7kAQ/Jd2jV199tWOt209J33nnnaX1blMT79mzp7T+xBNPdKw99NBDpet++OGHpfW77y7/LdFu5xiUWbFiRWm929dvu011fcYZZxxxT0czjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7D268MILO9ZOO63j7FeSpEceeaS0/swzz5TWd+3aVVovc/LJJ5fW77vvvtJ6t3H2Kk499dTSerfpwqampkrrjLN/Fkd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYenX322R1r3cbRH3zwwdJ6t2mRb7755tL60qVLO9aWL19eum63cwQGacmSJZXW73b+QavVqvT8R5uuR3bbj9uetr19zrLVtvfY3lJcrhpsmwCq6uVl/C8kzXd4+GlEnF9cyqc0AdC4rmGPiJclfTCEXgAMUJUP6G63vbV4mb+g04Nsr7Ldtt3udq4zgMHpN+yPSPqapPMl7ZPU8VcNI2JNRLQiojU+Pt7n5gBU1VfYI+K9iPgkIg5J+rmki+ptC0Dd+gq77Yk5d78taXunxwIYDV3H2W0/JWmppDHbU5J+LGmp7fMlhaTdkr4/uBZH3/XXX1+pntXExET3B5XYvHlzaf3GG2+s9PxHm65hj4iV8yx+bAC9ABggTpcFkiDsQBKEHUiCsANJEHYgCb7iisZERKX1Dx06VFMnOXBkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdHY2xXWv+YYzhWHQn2FpAEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTg7GjM9Pd10C6lwZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR2M2btxYaf0FCxbU1EkOXY/sthfZ3mh7p+0dtn9QLD/F9ou23yqu2fPACOvlZfxBST+KiL+X9A+SbrO9WNLdkl6KiHMkvVTcBzCiuoY9IvZFxOvF7f2SdkpaKOlaSWuLh62VdN2AegRQgyP6gM72pKRvSNok6fSI2CfN/kOQdFqHdVbZbttuz8zMVGwXQL96DrvtL0v6raQfRsSfe10vItZERCsiWuPj4/30CKAGPYXd9pc0G/RfRcTvisXv2Z4o6hOS+AoTMMK6Dr159vd+H5O0MyJ+Mqe0XtJNkh4orp8dSIdAB8uWLWu6hS+UXsbZL5H0XUnbbG8plt2j2ZD/xvYtkv4o6TsD6RBALbqGPSL+IKnTr/l/q952AAwKp8sCSRB2IAnCDiRB2IEkCDuQBF9xRWP2799fWu/2FdaJiYk62znqcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ0djnnvuudL62NhYaX3hwoV1tnPU48gOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo6B2rlzZ8fanj17Stc988wz624nNY7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEL/OzL5L0S0lnSDokaU1E/Mz2aknfkzRTPPSeiNgwqEbxxfTxxx93rB04cGCInaCXk2oOSvpRRLxu+yuSXrP9YlH7aUT82+DaA1CXXuZn3ydpX3F7v+2dkviJEOAL5ojes9uelPQNSZuKRbfb3mr7cdvzztVje5Xttu32zMzMfA8BMAQ9h932lyX9VtIPI+LPkh6R9DVJ52v2yP/QfOtFxJqIaEVEa3x8vHrHAPrSU9htf0mzQf9VRPxOkiLivYj4JCIOSfq5pIsG1yaAqrqG3bYlPSZpZ0T8ZM7yuVNoflvS9vrbA1CXXj6Nv0TSdyVts72lWHaPpJW2z5cUknZL+v4A+sMX3AUXXNCxdu+995au+8orr9TdTmq9fBr/B0mep8SYOvAFwhl0QBKEHUiCsANJEHYgCcIOJEHYgST4KWk0ZvXq1U23kApHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhExvI3ZM5L+d86iMUnvD62BIzOqvY1qXxK99avO3s6OiHl//22oYf/cxu12RLQaa6DEqPY2qn1J9NavYfXGy3ggCcIOJNF02Nc0vP0yo9rbqPYl0Vu/htJbo+/ZAQxP00d2AENC2IEkGgm77eW2/9v227bvbqKHTmzvtr3N9hbb7YZ7edz2tO3tc5adYvtF228V1/POsddQb6tt7yn23RbbVzXU2yLbG23vtL3D9g+K5Y3uu5K+hrLfhv6e3faxkt6UdLmkKUmbJa2MiP8aaiMd2N4tqRURjZ+AYXuJpL9I+mVEnFss+1dJH0TEA8U/ygUR8c8j0ttqSX9pehrvYraiibnTjEu6TtI/qcF9V9LXjRrCfmviyH6RpLcjYldE/FXSryVd20AfIy8iXpb0wWGLr5W0tri9VrN/LEPXobeREBH7IuL14vZ+SZ9OM97ovivpayiaCPtCSX+ac39KozXfe0h6wfZrtlc13cw8To+IfdLsH4+k0xru53Bdp/EepsOmGR+ZfdfP9OdVNRH2+aaSGqXxv0si4puSrpR0W/FyFb3paRrvYZlnmvGR0O/051U1EfYpSYvm3D9T0t4G+phXROwtrqclrdPoTUX93qcz6BbX0w338zejNI33fNOMawT2XZPTnzcR9s2SzrH9VdvHS1ohaX0DfXyO7ZOKD05k+yRJyzR6U1Gvl3RTcfsmSc822MtnjMo03p2mGVfD+67x6c8jYugXSVdp9hP5/5H0L0300KGvv5P0RnHZ0XRvkp7S7Mu6/9PsK6JbJJ0q6SVJbxXXp4xQb/8paZukrZoN1kRDvV2q2beGWyVtKS5XNb3vSvoayn7jdFkgCc6gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/h/1ShYzb+SvAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta (label) Asignada por Humano: 9\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nImagen de ejemplo:\\n\")\n",
    "\n",
    "# Elegir una observación al azar usando randint\n",
    "azar=np.random.randint(x_train.shape[0])\n",
    "\n",
    "#Visualizar la imagen usando imshow en escala de grises\n",
    "plt.imshow(x_train[azar].reshape((28,28)), cmap=\"binary\")\n",
    "#plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(\"Etiqueta (label) Asignada por Humano:\",y_train[azar])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora, un regalito útil para el futuro (para ver varios ejemplos al mismo tiempo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indices Elegidos:  [18130 53097 23195 48655 40085  4958 25519 40485 22172 56032 52463 44372] \n",
      "\n",
      "\n",
      "Elementos Elegidos:  [8 7 6 8 6 1 2 9 3 5 7 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cuántas filas\n",
    "filas=3\n",
    "#Cuantas columnas\n",
    "colus=4\n",
    "#Elementos totales\n",
    "n=filas*colus\n",
    "#Elegir una muestra del dataset via índices\n",
    "vector_azar=np.random.randint(x_train.shape[0],size=(n,))\n",
    "# contador para dibujar en la grilla\n",
    "w=1\n",
    "#iniciar espacio de dibujo\n",
    "plt.figure(figsize=(15,10))\n",
    "#titulo\n",
    "plt.suptitle(\"Ejemplos del dataset MNIST\",fontsize=18)\n",
    "\n",
    "# Loop anidado para recorrer la matriz completa\n",
    "for i in range(filas):\n",
    "    for j in range(colus):\n",
    "        \n",
    "        # subplots se peden contar incrementalmente\n",
    "        plt.subplot(filas,colus,w)\n",
    "        # dibujar el ejemplo de la muestra convertida a una matrix 28X28\n",
    "        plt.imshow(x_train[vector_azar[i+j]].reshape((28, 28)), cmap=\"binary\")\n",
    "        #mostrar la etiqueta dada por el humano a dicho ejemplo (Aprendizaje supervisado)\n",
    "        plt.title(\"label: \"+str(y_train[vector_azar[i+j]]))\n",
    "        #No mostrar ejes corrdenados\n",
    "        plt.axis(\"off\")\n",
    "        # Incrementar contador\n",
    "        w+=1\n",
    "\n",
    "plt.show()\n",
    "#mostrar índices de los ejemplos elegidos\n",
    "print(\"\\nIndices Elegidos: \",vector_azar,\"\\n\")\n",
    "# mostrar etiquetas correspondientes\n",
    "print(\"\\nElementos Elegidos: \",y_train[vector_azar],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos algunos datos en bruto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[226,  80,   8,   8, 247],\n",
       "       [ 42,   0,   0,  84, 253],\n",
       "       [  0,   0,  55, 240, 244],\n",
       "       [ 27, 124, 238, 255, 135],\n",
       "       [254, 254, 241, 122,   2]], dtype=uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extraer pixeles 10->15 en x y 10->15 en y\n",
    "x_train[azar].reshape((28,28))[10:15,10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, estos ejemplo ya han sido tratados, pues se muestran número entre cero y uno.\n",
    "\n",
    "Usamos la forma alternativa de subir los datos, haciendo uso de los **datasets** internos que vienen por defecto en la instalación de **tensorflow.keras**:\n",
    "\n",
    "```(x_train, y_train), (x_valid, y_valid) = tf.keras.datasets.mnist.load_data()```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver al Inicio]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar Datos a Forma Tensorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Tensorflow puro se trabaja con tensores mas que con arreglos de numpy, así que deberemos transformar nuestros datos.\n",
    "\n",
    "Para este fin, usaremos la función ```tf.constant```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de Tensorflow:  2.4.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chequear la versión de tensorflow disponible\n",
    "print(\"Versión de Tensorflow: \",tf.__version__,\"\\n\")\n",
    "\n",
    "\n",
    "# transforma los features a la escala [0,1]\n",
    "x_train, x_valid = np.array(x_train/255.0,dtype=np.float32), np.array(x_valid/255.0,dtype=np.float32)\n",
    "y_train, y_valid = np.array(y_train,dtype=np.int32), np.array(y_valid,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=int32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de Entrenamiento:\n",
      "\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(60000, 784), dtype=float32) \n",
      "\n",
      "Etiquetas de Entrenamiento:\n",
      "\n",
      "[5 0 4 ... 5 6 8] \n",
      "\n",
      "Label mínimo: 0\n",
      "Label máximo: 9\n",
      "Label únicos: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Usando función map para convertir TODOS los datos a tensor\n",
    "x_train, y_train, x_valid, y_valid = map(tf.constant, \n",
    "                                    (x_train, y_train, x_valid, y_valid))\n",
    "#Mostrar datos\n",
    "print(\"Datos de Entrenamiento:\\n\")\n",
    "print(x_train,\"\\n\")\n",
    "print(\"Etiquetas de Entrenamiento:\\n\")\n",
    "print(y_train.numpy(),\"\\n\")\n",
    "\n",
    "#Chequear límites de las etiquetas\n",
    "print(f'Label mínimo: {tf.reduce_min(y_train).numpy()}')\n",
    "print(f'Label máximo: {tf.reduce_max(y_train).numpy()}')\n",
    "print(\"Label únicos:\",np.sort(tf.unique(y_train)[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 784), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver al Inicio]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Objetivo de la Red Neuronal</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelo Logístico Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El propósito de la red es clasificar cada una de las imágenes en una de 10 clases. Cada clase representa a un dígito entre 0 y 9.\n",
    "\n",
    "En este experimento cada imagen será presentada a la entrada de la red como una tensor de una dimensión (1D) y de tamaño (shape) $28\\times 28 = 784$. Por lo tanto, la capa entrada se tendran 784 neuronas. La red no tendrá capas ocultas. La capa de salida tendrá 10 neuronas, debido a que hay 10 clases.\n",
    "\n",
    "El tipo de red será densa o completamente conectada, es  decir cada neurona de entrada está conectada con cada neurona de salida. \n",
    "\n",
    "Así, la matriz de pesos $\\mathbf{W}$ tendrá tamaño $784 \\times 10$ y el vector $\\mathbf{b}$ de interceptos (bias) será de un vector tamaño 10.\n",
    "\n",
    "\n",
    "En nuestro primer modelo, la función de activación de la capa de entrada será la identidad y en la capa de salida la función de activación será la función *softmax* que definimos abajo.\n",
    "\n",
    "La siguiente imagen ilustra el diseño (topología) de la primera red que constriomos desde cero. Esta red, es realmente un modelo logístico multinomial clásico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multinomial](../Imagenes/am_ANN_mnist_748_10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Volver al Inicio]](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Red Neuronal Artificial desde cero!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un modelo simple, para lo cual solamente usaremos las operaciones de Tensorflow.\n",
    "\n",
    "Los pesos son inicializados siguiendo la propuesta de <a href='http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf'>Glorot_Bengio </a>. Se generaran números aleatorios uniformemente distribuidos entre -1 y 1 divididos por $\\sqrt{n}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "n=x_train.shape[1]\n",
    "output=10\n",
    "\n",
    "weights = tf.Variable(tf.random.uniform((n,output))/math.sqrt(n), dtype= tf.float32)\n",
    "bias = tf.Variable(tf.zeros(output),tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(weights.numpy().shape)\n",
    "print(bias.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos  *tf.Variable* para declarar tensores de tipo variable, es decir, cuyo contenido cambia a los largo de nuestro algortimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Racional\n",
    "\n",
    "Por  otro lado, observe que *weights* es una matriz de tamaño $784 \\times 10$ y *bias* es un vector de tamaño 10. Vamos a construir una red neuronal que tiene solamente dos capas: entrada con 784 neuronas y salida con 10 neuronas. Note que nuestros patrones de entrada son vectores de tamaño 784.\n",
    "\n",
    "La razón de tener 10 neuronas de salida es porque tenemos un problema de clasificación en 10 clases. Podemos imaginar intuitivamente que construimos un modelo de regresión logística para cada una de las clases. \n",
    "\n",
    "Entonces a la salida esperamos tener es la probabilidad de que el patron de entrada pertenezca a esa clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferenciación Automática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde Tensorflow 2.X se incluye **diferenciación automática** para calcular gradientes automáticamente. Esto permite usar funciones estándar de Python como modelos para la redes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de Activación softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un modelo lineal simple. Necesitaremos una función de activación, por lo que vamos a escribir la función *log_softmax*. La variable $\\eta$ en la función, que corresponde al máximo de los valores, se introduce para tener una función muy robusta, desde el punto de vista computacional.\n",
    "\n",
    "Para un conjunto de valores $x_1,\\ldots,x_n$, la función softwax transforma estos valores en la escala (0,1), que pueden interpretarse como probabilidades. Cada componente de softmax es interpretada como la probabilidad que la imagen pertenezca a la clase representada por dicha componente.\n",
    "\n",
    "Matemáticamente se escribe\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Prob[y=j|x] = \\frac{\\exp(x_j)}{\\sum_{k=1}^{n}\\exp(x_j)}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Un cálculo muy estable computacionalmente de estos valores se obtiene de la siguente manera. Sea $\\eta = \\underset{i}{\\text{max}} \\hspace{2mm} \\{x_i\\}$. Es fácil verificar que\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Prob[y=j|x] = \\frac{\\exp(x_j-\\eta)}{\\sum_{k=1}^{n}\\exp(x_k-\\eta)} = \\text{softmax}_j(x)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Observe que $\\log \\text{softmax}_j(x)  = x_j - \\eta - \\log(\\sum_{k=1}^n \\exp(x_k-\\eta))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def log_softmax(x):\n",
    "    η = tf.math.reduce_max(x)\n",
    "    return x - η - tf.math.log(tf.math.reduce_sum(tf.math.exp(x-η), -1, keepdims=True))\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb@weights + bias) # z = x'W +b\n",
    "    #return log_softmax(tf.linalg.matmul(xb,weights) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior, el símbolo @ representa la operación del producto punto (en este caso corresponde a el producto de un vector con una matriz).\n",
    "\n",
    "Llamaremos a nuestra función con un lote de datos (en este caso, 64 imágenes). Este es un paso hacia adelante (forward pass). Tenga en cuenta que nuestras predicciones no serán mejores que aleatorias en esta etapa, ya que comenzamos con pesos aleatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso Hacia Adelante (Forward Pass) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones para la primera imagen:\n",
      "\n",
      " tf.Tensor(\n",
      "[-2.3090463 -2.2887955 -2.2076452 -2.2677054 -2.3034987 -2.2903447\n",
      " -2.3672752 -2.3688927 -2.2506318 -2.386469 ], shape=(10,), dtype=float32) \n",
      "\n",
      "Tamaño de la matriz de predicciones de este lote:  (64, 10)\n"
     ]
    }
   ],
   "source": [
    "bs = 64# batch size\n",
    "\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb) # predictions\n",
    "print('Predicciones para la primera imagen:\\n\\n',preds[0],\"\\n\")\n",
    "print('Tamaño de la matriz de predicciones de este lote: ', preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de pérdida\n",
    "\n",
    "Vamos a implementar la función menos log-verosimilitud, la cual usaremos como **función de pérdida** (loss function). Esta es la misma **entropía cruzada**(cross entropy, usando la codificación One-hot).\n",
    "\n",
    "\n",
    "Matemáticamente, la función de pérdida en esta caso es definida como sigue:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  El Modelo\n",
    "\n",
    "Aqui $\\mathbf{x}_i$ denota la observación $i$. \n",
    "\n",
    "$$\n",
    "\\pi_{ik} = Prob[\\mathbf{x} \\in \\mathcal{C}_k] = sofmax_k(\\mathbf{x}_i) = \\frac{\\exp(\\mathbf{x}_i'\\mathbf{w}_k + \\mathbf{b}_k)}{\\sum_{s=1}^K  \\exp (\\mathbf{x}_i'\\mathbf{w}_s+  \\mathbf{b}_s)} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Función de pérdida \n",
    "\n",
    "En esta sección $\\mathbf{W}$ es la martriz completa de pesos. Cada fila $\\mathbf{w}_k$ está asociada a la respectiva categoría $\\mathcal{C}_k$.\n",
    "\n",
    "Entropía cruzada: **-log verosimilitud** .  Aqui $\\mathbf{x}_i$ denota la observación $i$ y $y_i$ la respectiva etiqueta. Sea $\\chi_{ik}$ definda por\n",
    "\n",
    "$$\n",
    "\\chi_{ik} = \\begin{cases} 1, & \\text{ si } y_i = k\\\\\n",
    "0, & \\text{ en otro caso. }\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "loss(\\mathbf{W},\\mathbf{b}) = -\\frac{1}{N}  \\sum_i \\sum_k \\chi_{ik} \\log \\pi_{ik}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción\n",
    "\n",
    "$$\n",
    "\\tilde{y} = \\text{índice}(\\max_{k}{\\pi_k(x)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Precisión\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{accuracy} = \\frac{1}{N} \\sum_{i=1}^{N} 1_{y_i =\\tilde{y}_i}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    indices = tf.stack([tf.range(input.shape[0]),target], axis=1)\n",
    "    return tf.math.reduce_mean(-tf.gather_nd(input, indices))\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre el código anterior. \n",
    "1. *tf.range(input.shape[0])*  genera un tensor con números en el rango entre 0 y 63, porque la forma (shape) es 64, el tamaño del batch.\n",
    "2. *tf.stack([tf.range(input.shape[0], dtype=tf.int32),target], axis=1)* crea un tensor bidimensional, en donde cada fila corresponde al índice del elemento que debe tomarse de cada fila de input para calcular la funcion de pérdida. Por ejemplo, si la fila 3 de índice es [3,4], significará que y_train[3] es 4, y ṕor tanto se requiere tomar el contenido de la cuarta posición de la entrada 3.\n",
    "3. tf.gather_nd(input, indices). Para cada fila de input toma el valor de input en la posición indicada en el índice, como se explica en el numeral 2.\n",
    "4. tf.math.reduce_mean(-tf.gather_nd(input, indices)), calcula el resumen. La media, que corresponde exáctamete a - log likelihood\n",
    "\n",
    "Veámos una ilustración de índices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pattern  target\n",
       "0        0       3\n",
       "1        1       0\n",
       "2        2       5\n",
       "3        3       7\n",
       "4        4       1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo del tensor indices\n",
    "import pandas as pd\n",
    "pattern = {'0': 0, '1': 1, '2':2, '3':3, '4':4}\n",
    "target = {'0': 3, '1': 0, '2':5, '3':7, '4':1}\n",
    "indices = pd.DataFrame({'pattern': pattern, 'target':target})\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la columna pattern en esta ilustración contiene el índice del respectivo patrón de entrada. La columna target es el target asociado al respectivo patrón de entrada. Indices es esta matriz con las dos columnas.\n",
    "\n",
    "La última línea del código calcula la función de pérdida definida arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos ahora la **función de pérdida** para el modelo con datos aleatorios. Esto permitirá comparar las mejoras después del paso de propagacion hacia atrás  (backpropagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.2912655, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds,yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También implementamos la función precisión (accuracy) de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = tf.math.argmax(out, axis=1,output_type=tf.int32)\n",
    "    return tf.math.reduce_mean(tf.dtypes.cast(preds == yb, tf.float16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chequamos la precisión actual del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.1094, shape=(), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds,yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la Red\n",
    " \n",
    " Estamos listos para correr el ciclo de entranamiento. Para calcular los gradientes usaremos diferenciación automática, con la clase tf.GradientTape.\n",
    " \n",
    "- Seleccionamos un mini-batch de datos de tamaño *bs*\n",
    "- Bajo un contexto tf.GradientTape \n",
    " - Usamos el modelo para hacer predicciones\n",
    " - Calculamos la pérdida\n",
    "- Calculamos el gradientes de las operaciones registradas en el contexto de esta cinta (tape).\n",
    "\n",
    "Ahora usamos estos gradientes para actualizar los pesos (weights) y los desplazamientos (bias).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.2 # learning rate\n",
    "epochs = 2 # how many epochs to train for\n",
    "n = x_train.shape[0]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs +1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        with tf.GradientTape() as t:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred,yb)\n",
    "        dW, dB = t.gradient(loss,[weights,bias])\n",
    "        weights.assign_sub(lr*dW)\n",
    "        bias.assign_sub(lr*dB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos creado y entrenado una red neuronal minimal( en este caso una regression logística multinomial, dado que no tiene capas ocultas) totalmente desde cero (from scratch).\n",
    "\n",
    "Revisemos la pérdida y precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  tf.Tensor(0.30652905, shape=(), dtype=float32)\n",
      "train accuracy:  tf.Tensor(0.911, shape=(), dtype=float16)\n",
      "test loss:  tf.Tensor(0.30012172, shape=(), dtype=float32)\n",
      "test accuracy:  tf.Tensor(0.9136, shape=(), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# pérdida y precisión datos de entrenamiento\n",
    "print(\"train loss: \",loss_func(model(x_train),y_train))\n",
    "print(\"train accuracy: \",accuracy(model(x_train),y_train))\n",
    "\n",
    "# pérdida y precisión datos de validación\n",
    "print(\"test loss: \",loss_func(model(x_valid),y_valid))\n",
    "print(\"test accuracy: \",accuracy(model(x_valid),y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperando estimaciones (Weights & Bias) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(784, 10) dtype=float32, numpy=\n",
       "array([[0.01936717, 0.01670487, 0.01259941, ..., 0.0354806 , 0.02773505,\n",
       "        0.024815  ],\n",
       "       [0.01509231, 0.0284929 , 0.00563908, ..., 0.01314457, 0.02220905,\n",
       "        0.00493607],\n",
       "       [0.0047584 , 0.02688436, 0.03469312, ..., 0.03535743, 0.02096629,\n",
       "        0.0103931 ],\n",
       "       ...,\n",
       "       [0.00444492, 0.03566462, 0.02684227, ..., 0.03182695, 0.01084574,\n",
       "        0.00429973],\n",
       "       [0.01353151, 0.01630927, 0.01565207, ..., 0.0348251 , 0.0053246 ,\n",
       "        0.00656663],\n",
       "       [0.0292965 , 0.02399355, 0.03454986, ..., 0.01452523, 0.01184466,\n",
       "        0.009656  ]], dtype=float32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=\n",
       "array([-0.3216015 ,  0.33821732,  0.06465681, -0.23871014,  0.05610637,\n",
       "        1.0925262 , -0.07184623,  0.5204884 , -1.2441906 , -0.19565555],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
