{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b851f7-c675-4a2a-8932-59bf23db8edb",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F72585\">Funciones de pérdida</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182c2d6-3db5-4cd4-b665-4d160a8e1b22",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Libro_Fundamentos_Programacion/main/Pytorch/Imagenes/perdida_vgg56.png\" width=300 height= 400 align=\"left\" />      \n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Libro_Fundamentos_Programacion/main/Pytorch/Imagenes/perdida_Res.png\" width=300 height= 400 align=\"right\" />      \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed8cd5-2d41-4e5e-b077-dfc17116b53c",
   "metadata": {},
   "source": [
    "Visualización funciones de pérdida modelos neuronales VGG56 y resnet56. Fuente: [University of Maryland](https://www.cs.umd.edu/~tomg/projects/landscapes/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab698e08-33bf-45c2-8b16-306084b6bf78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0386d0e-d3ef-45ca-8548-aa11ce06319c",
   "metadata": {},
   "source": [
    "Basado en [Ravindra Parmar en towardsdatascience](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23), [Vishal Yathish en towardsdatascience](https://towardsdatascience.com/loss-functions-and-their-use-in-neural-networks-a470e703f1e9#:~:text=A%20loss%20function%20is%20a,the%20predicted%20and%20target%20outputs.)\n",
    "\n",
    "Las máquinas aprenden por medio de una función de pérdida. Es un método para evaluar qué tan bien un algoritmo específico modela los datos dados. Si las predicciones se desvían demasiado de los resultados reales, la función de pérdida arrojaría un número muy grande. \n",
    "\n",
    "Un método de optimización es utilizado para encontrar los pesos y sesgos de una red neuronal que minimizan una función de pérdida. En esta lección, analizaremos varias funciones de pérdida y utilizadas en el dominio del aprendizaje de redes neuronales.\n",
    "\n",
    "No existe una función de pérdida única para todos los algoritmos de entrenamiento de redes neuronales. En términos generales, las funciones de pérdida se pueden clasificar en dos categorías principales según el tipo de tarea de aprendizaje con la que nos enfrentemos: pérdidas de regresión y pérdidas de clasificación \n",
    "\n",
    "* En la clasificación, estamos tratando de predecir la salida de un conjunto de valores categóricos finitos, por ejemplo, dado un gran conjunto de datos de imágenes de dígitos escritos a mano (MNIST), clasificándolos en uno de los dígitos 0–9. \n",
    "* La regresión, por otro lado, se ocupa de predecir un valor continuo, por ejemplo, dado el área de una casa, el número de habitaciones, el tamaño de las habitaciones, predecir el precio de la habitación.\n",
    "\n",
    "La imagen muestra los elementos necesarios para construir una función de pérdida:\n",
    "\n",
    "* La entrada a la red $X$.\n",
    "* La salida de la red $\\hat{Y} = net(X)$\n",
    "* La etiqueta $Y$.\n",
    "\n",
    "Usamos la siguiente notación: \n",
    "* $X =(X_1, X_2, X_3)$; \n",
    "* $\\hat{Y}=(\\hat{Y}_1, \\hat{Y}_2)$; \n",
    "* $Y=(Y_1, Y_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70831d6-6711-44d4-95c9-83df567db640",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Libro_Fundamentos_Programacion/main/Pytorch/Imagenes/nn.jpg\" width=600 height=600 align=\"left\" />      \n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Libro_Fundamentos_Programacion/main/Pytorch/Imagenes/target.png\" width=180 height=200 align=\"right\" />      \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943eccb-e545-4f6e-af92-3755e3d7652d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large X   \\hspace{9cm} \\hat{Y} = net(X) \\hspace{4cm} Y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d42ec-040e-4d93-a011-146d82882232",
   "metadata": {},
   "source": [
    "Basada en una imagen de [Wiki-commons](https://commons.wikimedia.org/wiki/Main_Page)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c1644-14ed-4b2d-8592-1874afb533ce",
   "metadata": {},
   "source": [
    "Una  función de pérdida mide que tan cerca esta la salida de la red con respecto a la respectiva etiqueta.\n",
    "\n",
    "Si por ejemplo, en el problema la salida y la etiqueta son  tensores de forma (2,) y la función de pérdida es el error cuadrático medio, se tiene que\n",
    "\n",
    "$$\n",
    "\\mathfrak{L} = \\left[(\\hat{y}_1 - y_1)^2 + (\\hat{y}_2 - y_2)^2 \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba799a3-870e-45f6-92cc-6594ee9df03f",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Funciones de pérdida para regresión</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692dedf6-1ac0-4056-b58e-42e2063cf869",
   "metadata": {},
   "source": [
    "En los problemas de regresión se supone que tanto la salida como la etiqueta con tensores de tipo *float*. En este caso algunas de las funciones de pérdida más utilizadas son:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827dde42-548d-4ee5-9582-4e65ed455897",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Error cuadrático medio (ECM): Mean squared error (MSE)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00df4e5-7989-443e-8d03-ce32e3e3c2d5",
   "metadata": {},
   "source": [
    "</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a0b2a-2680-47b4-951a-70a2bb5f92ec",
   "metadata": {},
   "source": [
    "En este caso, si se tiene $N$ datos para en un bloque de datos de entrenamiento, digamos $(x_i, y_i)$, en donde las $y_i$ son números, entonces la función de pérdida es \n",
    "\n",
    "$$\n",
    "\\text{ECM} = \\frac{1}{N} \\sum_{i=1}^N (y_i-\\hat{y}_i)^2\n",
    "$$ \n",
    "\n",
    "Si la salida y la etiqueta son vectores, digamos de tamaño $J$, cada componente de los vectores escribe $\\hat{y}_{ij}$ y ${y}_{ij}$ respectivamente. En este caso la función ECM toma la forma\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{ECM} = \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^J (y_{ij}-\\hat{y}_{ij})^2\n",
    "$$ \n",
    "\n",
    "La desventaja de esta función de pérdida es que es muy sensible a valores extremos. Una valor extremo puede hacer crecer mucha la función de pérdida debido al cuadrado en la fórmula. Una opción para resolver esta situación es es la siguiente función de pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29358e5f-0919-4b2a-bdfc-50b28d03b6d3",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Error absoluto medio (EAM): Mean absolute Value (MAE) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e670e627-7e0b-40b7-a688-e99074a03f15",
   "metadata": {},
   "source": [
    "</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c93be7-2b08-4cbc-94ba-1e614d13c538",
   "metadata": {},
   "source": [
    "En este caso, en lugar de calcular las diferencias al cuadrado de entre los $\\hat{y}_i$ y los $y_i$ se toman las diferencias absolutas, es decir\n",
    "\n",
    "$$\n",
    "\\text{EAM} = \\frac{1}{N} \\sum_{i=1}^N |y_i-\\hat{y}_i|\n",
    "$$ \n",
    "\n",
    "o,\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{EAM} = \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^J|y_{ij}-\\hat{y}_{ij}|\n",
    "$$ \n",
    "\n",
    "La función de pérdida EAM no resuelve del todo los problemas, debido a que si su valor es cercano a cero, los valores absolutos son cercanos a cero y esto impacta el cálculo del gradiente, debido a que la función valor absoluto no es derivable en cero. Una alternativa viable a estas dos funciones de pérdida es la siguiente.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5e21c-2a80-4a0e-8a60-2dd48457ea65",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Función de perdida de Hubber: Hubber loss</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681671e-0977-4c2f-bc08-445b678d96b4",
   "metadata": {},
   "source": [
    "Para el caso de salida y etiqueta de forma (1,) la función de pérdida de Hubber se define como: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c0371-bdef-4172-9c3a-c6b9728aeafa",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\text{Hubber loss} &= \\tfrac{1}{n}\\sum_{i=1}^n (Y_i- \\hat{Y}_i)^2 \\hspace{2cm} |\\hat{Y}_i-Y_i|\\le \\delta\\\\\n",
    "&=  \\tfrac{1}{n}\\sum_{i=1}^n |Y_i- \\hat{Y}_i)| \\hspace{2cm} |\\hat{Y}_i-Y_i|> \\delta\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad434b-7dcf-466b-9690-7b1d46942033",
   "metadata": {},
   "source": [
    "y en el caso de tensores de salida y etiqueta de forma $(J,)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c63ae-bc90-4d35-b14b-f4066c336945",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\text{Hubber loss} &= \\tfrac{1}{N}\\sum_{i=1}^N \\sum_{j=1}^J(Y_{ij}- \\hat{Y}_{ij})^2 \\hspace{2cm} \\sum_{j=1}^J|\\hat{Y}_{ij}-Y_{ij}|\\le \\delta\\\\\n",
    "&=  \\tfrac{1}{N}\\sum_{i=1}^N \\sum_{j=1}^J |Y_{ij}- \\hat{Y}_{ij})| \\hspace{2cm} \\sum_{j=1}^J|\\hat{Y}_{ij}-Y_{ij}|> \\delta\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a23fe1-7f3a-49df-971a-24ef070adde5",
   "metadata": {},
   "source": [
    "Si la diferencia absoluta entre el valor real y el predicho es menor o igual que un valor de umbral, $\\delta$, entonces se aplica ECM. De lo contrario, si el error es suficientemente grande, se aplica EAM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc6431-db8b-4b25-b942-19fd56635b87",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Funciones de pérdida para clasificación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9f579-a3b3-4125-bba8-338e52aeb3f4",
   "metadata": {},
   "source": [
    "En los problemas de clasificación, las etiquetas son discreta. Cada ejemplo de entrenamiento tiene una categoría asociada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b75d84e-0a2c-4eb9-ba97-ecdf0e7f6c55",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Funciones sigmoide y softmax</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60501c72-7b48-458c-9bf8-b0f01b74d0b2",
   "metadata": {},
   "source": [
    "En los problemas de clasificación, lo usual es que las salida de la red sea un tensor de tipo float de forma $(1,)$ si se tienen dos clases y en general un tensor de tipo float de de forma $(J,)$ si se tiene $J$ clases. Este tensor se conoce como un tensor de pre-probabilidad.\n",
    "\n",
    "\n",
    "En el caso binario (dos clases), es usual transformar la salida de la red con la función de activación `sigmoide`, la cual es la función de distribución acumulada estándar de la distribución logística. El sigmoide puede usarse en este caso con la activación en la capa de salida de la red. Esta función de activación es definida por\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{e^x}{1 + e^x}.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "La función *softmax* está diseñada para convertir un tensor de tipo float de forma $(J,)$ en un tensor de la misma forma que representa una distribución de probabilidad. Si $(Y_1, \\ldots,Y_j, \\ldots, Y_J)$ es un tensor de números reales, entonces $\\text{softmax(Y)}$ es un tensor $p=(p_1, \\ldots, p_j, \\ldots, p_J)$, en donde\n",
    "\n",
    "$$\n",
    "p_j = \\frac{e^{y_j}}{\\sum_{k=1}^J e^{y_k}}.\n",
    "$$\n",
    "\n",
    "Como podemos observar, la función softmax es una generalización natural del sigmoide cuando se tiene más de dos categorías."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137d7cb-10c5-42c1-adfb-94dbfb411a18",
   "metadata": {},
   "source": [
    "En la práctica $p_j$ se interpreta como la probabilidad que la entrada $X$ pertenezca a la clase $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397c16f-1d17-4ca5-9f42-efcfc39ac2b1",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Entropía cruzada binaria: Binary cross entropy</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eaa2b4-981c-44b9-9934-74b7b26c397a",
   "metadata": {},
   "source": [
    "Esta función de pérdida es la más utilizada en los casos de clasificación en dos clases. En este caso se espera que la salida de la red neuronal y la etiqueta sean  tensores de forma $(1,)$.\n",
    "\n",
    "Puede revisar el origen de la entropía cruzada en el capítulo introductorio de teoría de la información. Técnicamente, la entropía cruzada para una entrada $X$ con salida $\\hat{Y}$ y etiqueta $Y$ se define en este caso de la siguiente manera. En este caso las etiquetas solamente serán 0 o 1. Tenemos que $\\hat{Y}= net(X)$,  $\\hat{p} = \\sigma(\\hat{Y})$, y\n",
    "\n",
    "$$\n",
    "\\mathfrak{L} = -\\left[(\\log (\\hat{p}) Y) + \\log (1-\\hat{p})(1-Y) \\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd32eb-5556-495b-83f9-1727cae860a8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Entropía cruzada: Cross entropy</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57243469-63b4-430c-b06e-1d82d97226f0",
   "metadata": {},
   "source": [
    "Para el caso de $J$ clases, definimos el tensor $Z = (Z_1, \\ldots, Z_j, \\ldots Z_J)$, en donde\n",
    "\n",
    "$$\n",
    "Z_j = \\begin{cases} &1, \\quad \\text{si } Y=j\\\\\n",
    "& 0, \\quad \\text{en otro caso} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Es decir, $Z$ es el vector que representa la codificación `one-hot` de la etiqueta $Y$. Observe que $Z$ solamente tiene 1 en la posición $j$, si la categoría de la etiqueta es $j$, y cero en el resto de posiciones.\n",
    "\n",
    "Finalmente, para este caso la entropía cruzada es definida para el caso general de $N$ muestras en un lote de datos como\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathfrak{L} = -\\frac{1}{N} \\sum_{i=1}^N\\left[ \\sum_{j=1}^J  Z_{ij}log (\\hat{p}_{ij}) \\right],\n",
    "$$\n",
    "\n",
    "en donde $\\hat{Y}_i= (\\hat{Y}_{i1}, \\ldots, \\hat{Y}_{iJ})$ es la salida del la red para la entrada $X_i$, $\\hat{p}_i = \\text{softmax}(Y_i)$, y $Z_i$ la codificación *one-hot* de la etiqueta $Y_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e123bb-41ee-4527-a013-75054a458530",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Funciones de Pérdida en Keras</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a546be6-cc75-42b3-8497-9267ec080a84",
   "metadata": {},
   "source": [
    "Para revisar la descripción y forma de uso de las funciones de pérdida en Keras vaya [aquí](https://keras.io/api/losses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3e947-a324-4dd0-b1f3-d8ad01888e0b",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Perdidas para clasificación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53795f3-4c24-491c-a60c-e4f34cce838e",
   "metadata": {},
   "source": [
    "* `tf.keras.losses.BinaryCrossentropy`: entropía cruzada binaria\n",
    "* `tf.keras.losses.CategoricalCrossentropy`: entropía cruzada. Las etiquetas se espera en formato *one-hot*.\n",
    "* `SparseCategoricalCrossentropy`: entropía cruzada dispersa. Las etiquetas esperadas son enteros \n",
    "* `tf.keras.losses.Poisson`:  pérdida = $\\hat{Y} - Y \\log (\\hat{Y})$.\n",
    "* `tf.keras.losses.KLDivergence`: divergencia Kullback-Leiber.  $loss = Y * log(Y / \\hat{Y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa5312-7f60-449b-bd83-fc3852216980",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Perdidas para regresión</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed9fa8e-d110-49b3-a4bc-5b54ee4388b5",
   "metadata": {},
   "source": [
    "* `tf.keras.losses.MeanSquaredError`: error cuadrático medio\n",
    "* `tf.keras.losses.MeanAbsoluteError`: error aboluto medio\n",
    "* `tf.keras.losses.MeanAbsolutePercentageError`: procentaje de error absoluto entre $Y$ y $\\hat{y}$.\n",
    "* `tf.keras.losses.MeanSquaredLogarithmicError`: $loss = (log(Y + 1.) - log(\\hat{Y} + 1.))^2$\n",
    "* `tf.keras.losses.CosineSimilarity`: similaridad coseno entre $Y$ y $\\hat{y}$.\n",
    "* `tf.keras.losses.Huber`: pérdida de Hubber\n",
    "* `tf.keras.losses.LogCosh`: $logcosh = log((exp(x) + exp(-x))/2)$, en donde $x$ es el error  $\\hat{Y}-Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78841d2-ea3f-4b5b-b377-7c5e31e10d5f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Perdidas de tipo bisagra para clasificación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2423e24-a7e4-4107-acd1-fa74c6a850d6",
   "metadata": {},
   "source": [
    "* `tf.keras.losses.Hinge`: $loss = maximum(1 - Y * \\hat{Y}, 0)$\n",
    "* `tf.keras.losses.SquaredHinge`: loss = (maximum(1 - y_true * y_pred, 0))^2\n",
    "* `tf.keras.losses.CategoricalHinge`: $loss = maximum(neg - pos + 1, 0)$ en donde $neg=maximum((1-Y)*\\hat{Y})$ y $pos=sum(Y*\\hat{Y})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698374c-c7f1-40f1-9abd-0e84a654fc35",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Funciones de Pérdida en Pytorch</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e00812-f5d5-4e70-ad48-f503fb24d97a",
   "metadata": {},
   "source": [
    "El detalle de las funciones de pérdida en Pytorch revise [aquí](https://pytorch.org/docs/stable/nn.html#loss-functions).\n",
    "\n",
    "* `nn.L1Loss`: Error absoluto medio.\n",
    "* `nn.nn.MSELoss`: Error cuadrático medio.\n",
    "* `nn.BCELoss`: pérdida entropía cruzada binaria.\n",
    "* `nn.CrossEntropyLoss`: pérdida entropía cruzada. Puede incluir pesos para las clases.\n",
    "* `nn.NLLLoss`: Perdida Log-verosimilitud negativa. Puede incluir pesos para las clases.\n",
    "* `nn.CTCLoss`:Pérdida para Clasificación Temporal Conexionista. Para series de tiempo.\n",
    "* `nn.PoissonNLLLoss`: Pérdida negativa de log verosimilitud con distribución de Poisson del objetivo.\n",
    "* `nn.GaussianNLLLoss`: Pérdida log-verosimiltud negativa.\n",
    "* `nn.KLDivLoss`: divergencia Kullback-Leibler.\n",
    "* `nn.BCEWithLogitsLoss`: combina sigmoide con entropía binaria cruzada binaria.\n",
    "* `nn.HingeEmbeddingLoss`: pérdida entre el tensor de entrada y las etiquetas marcadas como -1 o 1.\n",
    "*  `nn.MultiLabelMarginLoss`: Crea un criterio que optimiza una pérdida de  multiclasificación en multiclase tipo bisagra (hinge).\n",
    "* `nn.HingeEmbeddingLoss`:  pérdida de incrustación de tipo bisagra.\n",
    "* `nn.HuberLoss`: Crea un criterio que usa un término cuadrático si el error absoluto del elemento cae por debajo del delta y un término L1 con escala delta en caso contrario.\n",
    "* `nn.SmoothL1Loss`: Crea un criterio que usa un término cuadrático si el error absoluto del elemento cae por debajo de beta y un término L1 en caso contrario.\n",
    "* `nn.nn.SoftMarginLoss`:Crea un criterio que optimiza una  clasificación de dos clases.\n",
    "* `nn.MultiLabelSoftMarginLoss`: Crea un criterio que optimiza una pérdida uno contra todos de varias etiquetas en función de la entropía máxima, entre la entrada $X$ y la etiqueta $Y$ de tamaño (N, C).\n",
    "* `nn.CosineEmbeddingLoss`: Usa un criterio basado en la similaridad coseno.\n",
    "* `nn.MultiMarginLoss`:Crea un criterio que optimiza una pérdida de tipo hinge de clasificación multiclase\n",
    "* `nn.MultiMarginLoss`: Crea un criterio que mide la pérdida de una tripleta de datos, dados los tensores de entrada $X_1$,$X_2$, $X_3$ y un margen con un valor mayor que 0.\n",
    "* `nn.TripletMarginWithDistanceLoss`: Crea un criterio que mide la pérdida de  una tripleta de dados los tensores de entrada $a$, $p$ y $n$ (que representan ejemplos de ancla, positivo y negativo, respectivamente), y una función de valor real no negativa (\"función de distancia\") utilizada para calcular la relación entre el ancla y ejemplo positivo (“distancia positiva”) y el ancla y ejemplo negativo (“distancia negativa”).\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
