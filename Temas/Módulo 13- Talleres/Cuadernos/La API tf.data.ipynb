{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a4da1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d3ab6",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Canalización  de datos. La API tf.data</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c25e9d-16e9-4b0a-86f5-070df5f59c59",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Escritor</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed11a50-22d8-47ba-a949-c06a9e2d04fc",
   "metadata": {},
   "source": [
    "1. Oleg Jarma, ojarmam@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef8e79",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3110c21",
   "metadata": {},
   "source": [
    "2. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "3. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "4. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88f287",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31059b",
   "metadata": {},
   "source": [
    "5. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b807f69",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951543d5",
   "metadata": {},
   "source": [
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co \n",
    "7. Julieth Lopez, julalopezcas@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac3cf5",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cb5f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d59fa41",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7a4a6",
   "metadata": {},
   "source": [
    "Basado en [tf.data](https://www.tensorflow.org/guide/data).\n",
    "\n",
    "La API `tf.data` permite crear tuberías de entrada complejas a partir de piezas simples y reutilizables. Por ejemplo, la canalización de un modelo de imagen podría agregar datos de archivos en un sistema de archivos distribuido, aplicar perturbaciones aleatorias a cada imagen y fusionar imágenes seleccionadas al azar en un lote para entrenamiento. La canalización de un modelo de texto puede implicar extraer símbolos de datos de texto sin procesar, convertirlos en identificadores incrustados con una tabla de búsqueda y agrupar secuencias de diferentes longitudes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e8e52",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Importa librerías</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91817879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 20:24:54.231435: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbe623",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Esenciales</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0fb187",
   "metadata": {},
   "source": [
    "Para crear una canalización de entrada, debe comenzar con una fuente de datos. Por ejemplo, para construir un `Dataset` de datos a partir de datos en la memoria, puede usar *tf.data.Dataset.from_tensors()* o *tf.data.Dataset.from_tensor_slices()*. Alternativamente, si sus datos de entrada están almacenados en un archivo en el formato *TFRecord* de TensorFlow puede usar *tf.data.TFRecordDataset()*.\n",
    "\n",
    "El objeto Dataset es un iterable de Python. Esto hace posible consumir sus elementos usando un bucle for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de65f4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 20:24:55.367167: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-22 20:24:55.367861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-22 20:24:55.385686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:55.386574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.2GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2021-10-22 20:24:55.386599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-10-22 20:24:55.470300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-10-22 20:24:55.470524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-10-22 20:24:55.518951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-22 20:24:55.530561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-22 20:24:55.610845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-22 20:24:55.621892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-10-22 20:24:55.757277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-10-22 20:24:55.757679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:55.759036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:55.760126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-10-22 20:24:55.762801: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-22 20:24:55.766616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:55.767801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.2GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2021-10-22 20:24:55.767867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-10-22 20:24:55.767932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-10-22 20:24:55.767985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-10-22 20:24:55.768035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-22 20:24:55.768085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-22 20:24:55.768134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-22 20:24:55.768184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-10-22 20:24:55.768245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-10-22 20:24:55.768433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:55.769678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:55.770922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-10-22 20:24:55.772383: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-10-22 20:24:57.382221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-22 20:24:57.382294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-10-22 20:24:57.382312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-10-22 20:24:57.384330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:57.385299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:57.386110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 20:24:57.386712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4584 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-10-22 20:24:57.390453: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9534256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b7da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n",
      "0\n",
      "8\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset:\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bcf17d",
   "metadata": {},
   "source": [
    "o se pueden crear explícitamente un iterador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99db79c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "it = iter(dataset)\n",
    "print(next(it).numpy())\n",
    "print(next(it).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59719072",
   "metadata": {},
   "source": [
    "### Consumo de datos usando reducción: reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e4225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 20:24:57.501054: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-22 20:24:57.509488: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2601325000 Hz\n"
     ]
    }
   ],
   "source": [
    "print(dataset.reduce(0, lambda state, value: state+value).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b6fef",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Estructura del conjunto de datos</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774636ec",
   "metadata": {},
   "source": [
    "Un conjunto de datos produce una secuencia de elementos , donde cada elemento tiene la misma estructura (anidada) de componentes . \n",
    "\n",
    "Los componentes individuales de la estructura pueden ser de cualquier tipo representable por *tf.TypeSpec*, incluidos *tf.Tensor* , *tf.sparse.SparseTensor* ,*tf.RaggedTensor* , *tf.TensorArray* o *tf.data.Dataset*.\n",
    "\n",
    "Las construcciones de Python que se pueden usar para expresar la estructura (anidada) de elementos incluyen *tuple , dict , NamedTuple y OrderedDict*. \n",
    "\n",
    "En particular, *list* no es una construcción válida para expresar la estructura de los elementos del conjunto de datos. \n",
    "\n",
    "Si desea que una entrada de *list* se trate como una estructura, debe convertirla en tuple y si desea que una lista de salida, entonces debe empaquetarla explícitamente usando *tf.stack*.\n",
    "\n",
    "\n",
    "La propiedad *Dataset.element_spec* permite inspeccionar el tipo de cada componente del elemento. La propiedad devuelve una estructura anidada de objetos *tf.TypeSpec*, que coincide con la estructura del elemento, que puede ser un solo componente, una tupla de componentes o una tupla anidada de componentes. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c151db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (10,), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))\n",
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "071bbaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6204 0.968  0.7465 0.7744 0.0607 0.6962 0.9613 0.2486 0.2937 0.2226]\n",
      "[0.0055 0.8556 0.8988 0.7702 0.1104 0.528  0.9498 0.9686 0.6508 0.7378]\n",
      "[0.666  0.9003 0.1938 0.4402 0.2969 0.8741 0.9344 0.2061 0.6413 0.2789]\n",
      "[0.6481 0.0825 0.2581 0.863  0.6081 0.891  0.0352 0.647  0.4875 0.5228]\n"
     ]
    }
   ],
   "source": [
    "for i in dataset1:\n",
    "    print(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "085014f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1cc36c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(100,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random.uniform([4]), #y\n",
    "     tf.random.uniform([4,100], maxval=100, dtype=tf.int32))) #x\n",
    "\n",
    "dataset2.element_spec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be7574f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "228ced99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(10,), dtype=tf.float32, name=None),\n",
       " (TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(100,), dtype=tf.int32, name=None)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "dataset3.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2efecf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3117a8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.ZipDataset"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cafd3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b243467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([0.6204, 0.968 , 0.7465, 0.7744, 0.0607, 0.6962, 0.9613, 0.2486,\n",
      "       0.2937, 0.2226], dtype=float32)>, (<tf.Tensor: shape=(), dtype=float32, numpy=0.8985994>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([97, 50, 15, 40, 46, 86, 62, 13, 41, 58, 54, 65,  7, 94, 22, 78, 93,\n",
      "       43, 69,  4, 73, 22, 65, 62, 86, 52, 16, 87, 95, 66, 49,  0, 76, 45,\n",
      "       33, 42, 92, 56, 51, 77, 88, 90,  7, 52, 81, 26, 13, 13, 15, 51, 58,\n",
      "       59, 11, 47, 32, 73, 88,  6, 87, 47, 61, 22, 22, 90, 47, 92, 21, 85,\n",
      "       76, 73, 71, 35, 18, 52, 39, 52, 18, 10,  3, 85, 20, 19, 16, 21, 80,\n",
      "       56, 25, 95, 13, 75, 23,  0, 77, 81, 44, 49,  3, 55, 64, 17],\n",
      "      dtype=int32)>)) \n",
      "\n",
      "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([0.0055, 0.8556, 0.8988, 0.7702, 0.1104, 0.528 , 0.9498, 0.9686,\n",
      "       0.6508, 0.7378], dtype=float32)>, (<tf.Tensor: shape=(), dtype=float32, numpy=0.32415867>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([16, 62, 65, 29, 42, 95, 47, 82, 19, 10, 48, 49, 35, 34, 43, 30, 18,\n",
      "       21, 64,  4, 14, 24, 31, 48, 81, 11, 61, 78, 40, 15, 18, 73, 40, 86,\n",
      "       50, 21, 69, 81, 55, 94, 70,  1, 97, 47, 70, 97, 43, 26, 57, 69, 64,\n",
      "       54, 24, 15, 42, 84, 12, 24, 80, 22, 40, 60, 30, 78, 85, 84, 95, 22,\n",
      "        6, 34, 67, 34, 73, 30,  5, 89, 38, 27, 23, 27, 42, 76, 24, 34, 70,\n",
      "       16,  7, 87, 61,  1, 74, 37, 90, 99, 68, 46,  4, 45,  0, 76],\n",
      "      dtype=int32)>)) \n",
      "\n",
      "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([0.666 , 0.9003, 0.1938, 0.4402, 0.2969, 0.8741, 0.9344, 0.2061,\n",
      "       0.6413, 0.2789], dtype=float32)>, (<tf.Tensor: shape=(), dtype=float32, numpy=0.10261607>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([16, 73, 55, 16, 37, 13, 33, 35, 15, 13,  5, 46, 22,  0, 67, 65, 28,\n",
      "       10, 79, 33, 54, 52, 59, 37, 67,  1, 22, 55, 29, 32, 77, 61, 97, 12,\n",
      "       11,  1,  8, 13, 26, 93, 79, 56, 50, 47,  2, 53, 13, 69,  6, 36, 49,\n",
      "       72, 32, 29, 43, 33, 87, 59, 35,  0, 79, 85, 87,  5, 35, 88, 22, 60,\n",
      "       88, 33, 12, 91, 67, 75, 50, 64, 80, 70, 57, 41, 52, 37, 32,  4, 15,\n",
      "       35, 58, 61,  5, 20, 12, 37, 99, 40, 18, 10, 83,  3, 80, 88],\n",
      "      dtype=int32)>)) \n",
      "\n",
      "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([0.6481, 0.0825, 0.2581, 0.863 , 0.6081, 0.891 , 0.0352, 0.647 ,\n",
      "       0.4875, 0.5228], dtype=float32)>, (<tf.Tensor: shape=(), dtype=float32, numpy=0.7428007>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([56, 63, 17, 25, 68, 39, 61,  4, 29, 13, 16,  7, 53, 56, 64, 61, 94,\n",
      "       59, 78, 24, 79, 44, 48, 98, 67, 69, 55, 92, 31, 24, 27, 86, 54, 67,\n",
      "       28, 81, 40, 55, 60, 20,  9, 96, 39, 10, 42, 83, 52, 24, 44, 90, 14,\n",
      "       41, 90, 72, 63, 12, 72, 60, 61, 85, 49, 77, 73, 10, 53, 94, 21, 14,\n",
      "       60, 85, 78, 31, 40, 82, 14, 17, 35, 79, 58, 98, 91, 23, 90, 97,  9,\n",
      "       71, 58, 69, 95, 39, 31, 30, 13, 89, 94, 39, 23, 47, 90, 69],\n",
      "      dtype=int32)>)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(i.next(), \"\\n\")\n",
    "print(i.next(), \"\\n\")\n",
    "print(i.next(), \"\\n\")\n",
    "print(i.next(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1949018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (10,), (), (100,)\n",
      "shapes: (10,), (), (100,)\n",
      "shapes: (10,), (), (100,)\n",
      "shapes: (10,), (), (100,)\n"
     ]
    }
   ],
   "source": [
    "for a, (b,c) in dataset3:\n",
    "    print('shapes: {a.shape}, {b.shape}, {c.shape}'.format(a=a, b=b, c=c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9fda2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensorSpec(TensorShape([3, 4]), tf.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset con tensores dispersos\n",
    "dataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0, 0],[1, 2]], values=[1, 2], dense_shape=[3, 4]))\n",
    "dataset4.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be872e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.sparse_tensor.SparseTensor"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4.element_spec.value_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1377cf5",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Leer datos de entrada</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18cc06",
   "metadata": {},
   "source": [
    "### Consumir matrices Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ecff01",
   "metadata": {},
   "source": [
    "Si todos sus datos de entrada caben en la memoria, la forma más sencilla de crear un Dataset a partir de ellos es convertirlos en objetos tf.Tensor y usar Dataset.from_tensor_slices() ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "491e7447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8614e9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 20:25:02.463024: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 376320000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenes, labels  = train\n",
    "imagenes = imagenes /255.\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((imagenes, labels))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0c67e",
   "metadata": {},
   "source": [
    "### Consumir generadores de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07bdf63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def count(stop):\n",
    "    i=0\n",
    "    while i<stop:\n",
    "        yield i\n",
    "        i+= 1\n",
    "        \n",
    "for n in count(5):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fefeef9",
   "metadata": {},
   "source": [
    "El constructor `Dataset.from_generator` convierte el generador de Python en un `tf.data.Dataset` completamente funcional.\n",
    "\n",
    "El constructor toma un invocable como entrada, no un iterador. Esto le permite reiniciar el generador cuando llega al final. Toma un argumento args opcional, que se pasa como argumentos del invocable.\n",
    "\n",
    "El argumento *output_types* es necesario porque *tf.data* crea un *tf.Graph* internamente y los bordes del gráfico requieren un tf.dtype .\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2dba736",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_counter = tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes=(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b62f481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24  0  1  2  3  4]\n",
      "[ 5  6  7  8  9 10 11 12 13 14]\n",
      "[15 16 17 18 19 20 21 22 23 24]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24  0  1  2  3  4]\n",
      "[ 5  6  7  8  9 10 11 12 13 14]\n",
      "[15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "for count_batch in ds_counter.repeat().batch(10).take(10):\n",
    "    print(count_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a20b1a6",
   "metadata": {},
   "source": [
    "El argumento `output_shapes` no es necesario, pero se recomienda, ya que muchas operaciones de flujo tensorial no admiten tensores con rango desconocido. Si la longitud de un eje en particular es desconocida o variable, output_shapes puede colcarse como None.\n",
    "\n",
    "También es importante tener en cuenta que `output_shapes` y `output_types` siguen las mismas reglas de anidamiento que otros métodos de conjuntos de datos.\n",
    "\n",
    "Aquí hay un generador de ejemplo que demuestra ambos aspectos, devuelve tuplas de matrices, donde la segunda matriz es un vector con longitud desconocida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b54dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_series():\n",
    "    i = 0\n",
    "    while True:\n",
    "        size = np.random.randint(0,10)\n",
    "        yield i, np.random.normal(size = (size,))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0146dfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [-0.4878 -1.0768  0.1019 -2.1496 -0.1024 -0.3561 -0.5842]\n",
      "1 : [-1.6571  1.7648]\n",
      "2 : [ 0.2236 -0.9558 -1.0754]\n",
      "3 : [ 1.2209 -0.2764 -0.4315  1.0234  1.57    0.6807 -0.1986 -0.6546]\n",
      "4 : [-0.7463  1.6724  0.5388 -0.1088 -0.2901 -0.6404 -0.1316  0.31  ]\n",
      "5 : [ 0.5233  0.0156 -0.4458  0.2986  0.2649 -0.009  -0.6764  0.9104  0.7872]\n",
      "6 : [ 0.1752 -0.7187  0.0144]\n"
     ]
    }
   ],
   "source": [
    "for i, series in gen_series():\n",
    "    print(i, \":\", str(series))\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158acb7f",
   "metadata": {},
   "source": [
    "La primera salida es un *int32* la segunda es un *float32*.\n",
    "\n",
    "El primer elemento es un escalar, forma () , y el segundo es un vector de longitud desconocida, forma (None,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "261aba25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: ((), (None,)), types: (tf.int32, tf.float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_series = tf.data.Dataset.from_generator(\n",
    "    gen_series,\n",
    "    output_types=(tf.int32, tf.float32),\n",
    "    output_shapes=((), (None, )))\n",
    "\n",
    "ds_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d896b",
   "metadata": {},
   "source": [
    "Ahora se puede utilizar como un *tf.data.Dataset* normal. Tenga en cuenta que al procesar por lotes un conjunto de datos con una forma variable, debe usar *Dataset.padded_batch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d5341d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 17 20 21 23 15 16 25  4 24]\n",
      "\n",
      "[[ 0.999   0.0996 -2.2703 -0.8717  0.0303 -1.5378 -2.2933 -2.2715  0.8909]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.1955  0.095   1.036   0.4378  0.694  -1.1221 -0.43    0.      0.    ]\n",
      " [-0.7131  1.4196  0.2035 -1.4516  0.2716  0.7313  0.395   0.      0.    ]\n",
      " [-1.2149  1.0299 -2.3611 -0.1821  0.3814  0.2352 -0.6536 -2.4488  0.1501]\n",
      " [-1.0646  2.0647  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.107   0.8555 -0.8319  0.5519 -2.8758 -0.4358 -0.3965  0.      0.    ]\n",
      " [ 0.2342  0.1476  0.2805  0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.2992  0.1146  0.355   0.      0.      0.      0.      0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "ds_series_batch = ds_series.shuffle(20).padded_batch(10)\n",
    "\n",
    "ids, sequence_batch = next(iter(ds_series_batch))\n",
    "\n",
    "print (ids.numpy())\n",
    "print()\n",
    "print(sequence_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9616254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20  1  9 14 16 15 19 18 28]\n",
      "\n",
      "[[-2.9010e+00 -2.0369e+00  9.9899e-01  5.8083e-01 -4.7284e-01  1.2962e-01\n",
      "  -1.2801e+00 -8.1442e-01  5.3743e-02]\n",
      " [-1.0548e+00  1.1036e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [ 1.1315e+00  3.8801e-02  2.1285e+00  1.5725e-03  6.1771e-01 -1.3438e+00\n",
      "  -7.0964e-02  6.5054e-01 -1.1254e+00]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [-8.7647e-01 -4.6213e-01  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [ 1.2491e+00  2.8543e-01  1.7239e+00 -1.7181e-01 -5.0816e-01 -1.3537e+00\n",
      "   1.1628e-01  2.3577e-01 -1.6698e-01]\n",
      " [ 2.1827e-01 -3.0780e-01  3.9623e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [ 4.6858e-01  4.4233e-01 -1.0819e-01 -1.4063e+00  1.6744e-01 -5.5851e-01\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [-3.8315e-01 -4.8301e-01 -1.0096e+00 -9.2611e-01  1.0052e+00  3.8201e-01\n",
      "   3.8185e-01  0.0000e+00  0.0000e+00]\n",
      " [ 6.5574e-01 -8.0525e-01 -1.1524e+00  1.0724e+00 -3.0175e-01 -4.2876e-01\n",
      "  -1.1739e+00 -1.0440e+00  4.0443e-01]]\n",
      "\n",
      "[ 5 12 21 32 11 33 17 27 37  7]\n",
      "\n",
      "[[-0.2664 -1.7646 -0.3971  0.      0.      0.    ]\n",
      " [ 0.4635  0.7865  0.      0.      0.      0.    ]\n",
      " [-0.7567  0.2172  0.4399 -1.0234  0.      0.    ]\n",
      " [-0.0758  0.      0.      0.      0.      0.    ]\n",
      " [-0.9244  0.      0.      0.      0.      0.    ]\n",
      " [-2.809  -0.3637  0.1409  1.6983 -1.6063  0.    ]\n",
      " [ 0.6532 -0.7355 -0.8039 -0.5373 -0.7216  0.6891]\n",
      " [-0.7265  1.1366  0.6765 -0.8099  0.      0.    ]\n",
      " [ 1.6042  0.3532 -0.0331  0.2405  0.      0.    ]\n",
      " [-0.6163  0.3439  1.3413  0.3243  0.      0.    ]]\n",
      "\n",
      "[13  4 22 25 38 44 35 30  8 43]\n",
      "\n",
      "[[ 0.1346 -0.7314 -0.5448  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.469   1.2531 -0.6024  0.6273  0.      0.      0.      0.      0.    ]\n",
      " [-1.0974  1.3811 -2.3938 -0.9955  0.      0.      0.      0.      0.    ]\n",
      " [-0.5906 -0.9619 -0.2972 -1.0228  2.536   0.7906 -1.0828  0.6686  0.    ]\n",
      " [-0.2728 -0.6002  0.2212  0.3084 -0.2805 -1.1227  0.6326  0.      0.    ]\n",
      " [-0.6807  0.3321 -0.179  -0.3213 -1.2429 -1.1093  0.      0.      0.    ]\n",
      " [-0.6434  0.4091  1.7854 -0.1369  1.7157 -0.3163 -1.2235 -2.3911  0.1787]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.81   -0.0225 -0.3584  0.4108 -0.7085 -0.5728  0.2634 -0.01    0.    ]]\n",
      "\n",
      "[26 24 49 46 47 41 53 23 29 36]\n",
      "\n",
      "[[ 0.0276 -0.9498  1.8266  1.1518 -0.6555 -0.848   0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.0853 -0.4294 -0.3433  1.6517  0.7794  0.      0.      0.    ]\n",
      " [ 0.8172 -0.7116  0.1059  0.13    0.      0.      0.      0.    ]\n",
      " [ 1.1333  1.1668  0.1581  0.5612 -0.9966 -0.6267  0.      0.    ]\n",
      " [ 1.2693  0.682   0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.9421  1.8953  1.8982 -0.2468 -0.1475 -1.4822 -0.8024  0.6769]\n",
      " [-0.4673  0.3945  0.3508 -0.7815  0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.2897 -0.9003  0.2244 -1.7139 -1.4517  0.4683  0.      0.    ]]\n",
      "\n",
      "[ 0 45 61 59 55  6 50  3 40 60]\n",
      "\n",
      "[[ 0.1946 -0.1437 -0.1669  0.035   0.506  -0.4668  0.0257  0.523 ]\n",
      " [-0.2412 -1.1378  2.6508  0.1223 -1.1927  0.7346  0.2567 -0.5271]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.906  -1.4921  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.1571  1.7453  0.363  -0.0118 -0.9979 -0.0043 -0.7113  0.    ]\n",
      " [ 0.3046  1.9106 -0.1733  0.      0.      0.      0.      0.    ]\n",
      " [ 1.1194  0.4165 -1.9181 -0.6298  0.2696  0.619   1.5631 -0.3058]\n",
      " [ 1.075  -0.6586 -0.1404 -1.3941  0.      0.      0.      0.    ]\n",
      " [ 0.2056 -0.6283  1.6799  0.      0.      0.      0.      0.    ]]\n",
      "\n",
      "[52 51 42 48 67 66 34 74 76 58]\n",
      "\n",
      "[[-1.3423e-03  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [ 4.4434e-01 -2.8140e-01  5.7476e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [ 1.6100e+00 -1.2631e+00 -1.4291e-01  3.7178e-01  1.1160e+00  2.2852e+00\n",
      "  -5.9311e-02 -1.1738e+00  5.1194e-02]\n",
      " [-1.8737e+00  1.0291e-01 -1.7773e-01 -1.3422e-01  2.8400e-01  4.1071e-01\n",
      "   1.5888e-01  0.0000e+00  0.0000e+00]\n",
      " [ 6.6524e-01 -5.9674e-01 -2.7076e-01  9.3441e-01 -1.8010e+00  1.2632e-01\n",
      "   1.5578e+00  1.3205e-01 -2.9775e-01]\n",
      " [-3.7664e-02  2.4073e-01  1.3012e+00  1.3347e+00 -7.0411e-01  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [ 9.1678e-01 -7.4655e-01  4.9216e-01  1.2796e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [-1.8249e+00 -4.4558e-01  2.8786e-01  5.0001e-01 -5.9083e-01 -3.9602e-01\n",
      "  -2.0261e+00 -8.2654e-01  0.0000e+00]\n",
      " [ 1.1041e+00  1.2723e+00  4.9756e-01  2.7818e-02  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00  0.0000e+00]\n",
      " [-1.3690e+00  7.7644e-01  1.3097e+00 -6.4432e-01 -1.4156e+00 -7.0613e-01\n",
      "   3.9360e-02 -4.3522e-01  0.0000e+00]]\n",
      "\n",
      "[68 70 54  2 65 83 39 62 64 85]\n",
      "\n",
      "[[ 5.9084e-01  5.9306e-01  1.5567e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [ 2.0955e-01 -1.5892e+00  1.9027e+00 -4.2325e-01  3.0433e-01 -7.7556e-01\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [ 1.2295e+00 -3.4240e-01 -1.0856e+00  9.6131e-01 -1.5829e+00 -8.0795e-01\n",
      "   8.8585e-01  7.8264e-04]\n",
      " [ 3.2539e-01 -4.0977e-01 -2.5075e-01 -4.5619e-01  1.9973e-01  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [-5.6565e-01 -1.3797e+00 -1.9819e-01  1.3084e+00 -1.3668e+00 -1.4853e+00\n",
      "  -1.1403e+00  0.0000e+00]\n",
      " [ 4.1327e-01 -5.5875e-01  2.6779e-01  2.6972e-01 -4.2432e-01  1.0683e+00\n",
      "  -7.8892e-01  0.0000e+00]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [ 7.5621e-01  7.0688e-01  9.7664e-02 -8.8528e-01  7.3933e-01  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [ 1.4057e+00 -3.6241e-01  3.0940e-01 -1.0074e+00  6.1427e-01 -2.6099e+00\n",
      "   1.3146e+00  0.0000e+00]\n",
      " [ 1.1003e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]]\n",
      "\n",
      "[82 86 77 81 87 92 31 93 69 88]\n",
      "\n",
      "[[ 0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.1333 -1.0256  0.8036 -1.4901 -0.331  -0.9413]\n",
      " [ 0.2572  0.6939 -0.8447 -0.6384 -2.0591  0.7166]\n",
      " [ 0.6348  1.2743 -1.0512 -0.9674  0.      0.    ]\n",
      " [ 0.1002  0.      0.      0.      0.      0.    ]\n",
      " [-1.529  -0.7592  0.4331  0.1403 -0.5438  0.    ]\n",
      " [-0.1501  1.6688 -0.5254  1.61   -0.8961  0.    ]\n",
      " [ 0.2126  0.      0.      0.      0.      0.    ]\n",
      " [ 0.4478  0.      0.      0.      0.      0.    ]\n",
      " [-0.1926  0.      0.      0.      0.      0.    ]]\n",
      "\n",
      "[ 57  84  75  56 102  97  89  96 107 100]\n",
      "\n",
      "[[-0.0251  0.5382  0.4915 -0.5678 -1.9199  0.0267  1.3887  0.7877]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.4832 -0.8295  0.7404  0.      0.      0.      0.      0.    ]\n",
      " [-0.3294  1.4816  0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.9259  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.0646  0.7366  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.155  -0.2213  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.7455 -0.7518  1.5741  0.      0.      0.      0.      0.    ]\n",
      " [-0.5576  0.1778 -0.1274  0.      0.      0.      0.      0.    ]]\n",
      "\n",
      "[ 90  79 109 112  78 113 101  91  98 105]\n",
      "\n",
      "[[-0.7482  0.7373  1.3825 -0.8701  0.6113  2.1941  0.      0.      0.    ]\n",
      " [ 0.6818  0.1104  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.2564  0.7162  0.5119 -0.0865 -1.321  -1.3729 -0.9764 -0.9151  0.1187]\n",
      " [ 0.7011  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.791   1.4558  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.5692  1.3048  0.1395  0.0146 -1.9348 -0.8491 -0.5096  1.2571  0.    ]\n",
      " [ 1.1135 -1.7239  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.1777  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 2.5331  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.2653  0.2312  0.2806  0.4061  0.7182 -0.5725  0.7865 -0.718   0.    ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "it = iter(ds_series_batch)\n",
    "for i in range(10):\n",
    "    ids, sequence_batch = next(it)\n",
    "    print (ids.numpy())\n",
    "    print()\n",
    "    print(sequence_batch.numpy())\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f132a33",
   "metadata": {},
   "source": [
    "### Ejemplo realista con imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dda2a8",
   "metadata": {},
   "source": [
    "Para obtener un ejemplo más realista, intente `tf.data.Dataset` `preprocessing.image.ImageDataGenerator` como un `tf.data.Dataset` .\n",
    "\n",
    "Primero descargue los datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70ae9c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228818944/228813984 [==============================] - 21s 0us/step\n"
     ]
    }
   ],
   "source": [
    "flowers = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    cache_dir='/media/storage', #dirección de extracción\n",
    "    cache_subdir='Datasets', #carpeta que se crea para la extracción\n",
    "    untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f200b4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/storage/Datasets/flower_photos\n"
     ]
    }
   ],
   "source": [
    "print(flowers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a483f8",
   "metadata": {},
   "source": [
    "Cree la `image.ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afeeabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6764cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(image_gen.flow_from_directory(flowers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027026a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.dtype, images.shape)\n",
    "print(labels.dtype, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35881913",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_generator(\n",
    "    lambda: image_gen.flow_from_directory(flowers),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([32,256,256,3],[32,5]))\n",
    "\n",
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14badd50",
   "metadata": {},
   "source": [
    "### Consumir datos de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404be34c",
   "metadata": {},
   "source": [
    "Muchos conjuntos de datos se distribuyen como uno o más archivos de texto. `tf.data.TextLineDataset` proporciona una manera fácil de extraer líneas de uno o más archivos de texto. \n",
    "\n",
    "Dados uno o más nombres de archivo, un `TextLineDataset` producirá un elemento con valor de cadena por línea de esos archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
    "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
    "\n",
    "file_paths = [\n",
    "    tf.keras.utils.get_file(file_name, directory_url +file_name)\n",
    "    for file_name in file_names\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd826494",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b2f64",
   "metadata": {},
   "source": [
    "Estas son las primeras líneas del primer archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3715dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in dataset.take(5):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682533fa",
   "metadata": {},
   "source": [
    "Para alternar líneas entre archivos, use `Dataset.interleave` . Esto facilita la reproducción aleatoria de archivos. Aquí están la primera, segunda y tercera líneas de cada traducción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e38c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds = tf.data.Dataset.from_tensor_slices(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca4b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in file_ds: print(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_ds = file_ds.interleave(tf.data.TextLineDataset, cycle_length=3)\n",
    "\n",
    "for i, line in enumerate(line_ds.take(9)):\n",
    "    if i%3 ==0:\n",
    "        print()\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c6a93",
   "metadata": {},
   "source": [
    "De manera predeterminada, `TextLineDataset` produce todas las lineas de cada archivo, lo cual tal vez no sea lo que se quiera. Tal vez el archivo empieza con el encabezado, o contiene comentarios. Para remover o pasarse estas lineas se usan las transformaciones `Dataset.skip()` o `Dataset.filter()`\n",
    "\n",
    "\n",
    "A continuación, trabajamos con el archivo de la tragedia del Titanic. Se salta la primera linea, y filtramos para tener solo a los sobrevivientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic_lines = tf.data.TextLineDataset(titanic_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in titanic_lines.take(10):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b829c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def survived(line):\n",
    "    return tf.not_equal(tf.strings.substr(line,0,1), '0')\n",
    "\n",
    "survivors=titanic_lines.skip(1).filter(survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in survivors.take(10):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0516c",
   "metadata": {},
   "source": [
    "### Consumir Datos CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597be64c",
   "metadata": {},
   "source": [
    "El formato CSV es muy popular para guardar datos tabulares en forma de texto.\n",
    "\n",
    "Ya subimos el archivo del titanic, el cual es csv. Podemos subirlo en este mismo formato usando pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27937af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(titanic_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61252899",
   "metadata": {},
   "source": [
    "Si se tiene suficiente memoria, pueden transformar a diccionario el Dataframe e importar los datos con facilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_slices = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "\n",
    "for feature_batch in titanic_slices.take(1):\n",
    "  for key, value in feature_batch.items():\n",
    "    print(\"  {!r:20s}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff97409",
   "metadata": {},
   "source": [
    "Un acercamiento más ameno es cargar desde el disco cuando sea necesario.\n",
    "\n",
    "el modulo tiene métodos para extraer rgistros de uno o más archivos CSV que cumplan con la [RFC 4180](https://tools.ietf.org/html/rfc4180)\n",
    "\n",
    "la función `experimental.make_csv_dataset` es una interfaz para leer conjuntos de archivos CSV, con lo cual podemos hacer inferencia por columna y crear lotes de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff04e64",
   "metadata": {},
   "source": [
    "Se puede usar el argumento `select_columns` si solo se necesitan algunas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2612ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_batches = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file, batch_size=4,\n",
    "    label_name=\"survived\", select_columns=['class', 'fare', 'survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60072f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_batch, label_batch in titanic_batches.take(1):\n",
    "  print(\"'survived': {}\".format(label_batch))\n",
    "  for key, value in feature_batch.items():\n",
    "    print(\"  {!r:20s}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683e9b4",
   "metadata": {},
   "source": [
    "### Consumir conjuntos de archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ad033",
   "metadata": {},
   "source": [
    "Es normal que los datos estén distribuidos en múltiples archivos, con cada archivo teniendo ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c78da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_root = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)\n",
    "flowers_root = pathlib.Path(flowers_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0195ac6",
   "metadata": {},
   "source": [
    "Cada directorio de la carpeta raíz contiene un directorio de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in flowers_root.glob(\"*\"):\n",
    "  print(item.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcffa27",
   "metadata": {},
   "source": [
    "Cada archivo en los directorios son ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*'))\n",
    "\n",
    "for f in list_ds.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa6639",
   "metadata": {},
   "source": [
    "usando `tf.io.read_file` podemos ler los datos y extraer las etiquetas, obteniendo (imagen, etiqueta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08963304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = tf.strings.split(file_path, os.sep)[-2]\n",
    "  return tf.io.read_file(file_path), label\n",
    "\n",
    "labeled_ds = list_ds.map(process_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_raw, label_text in labeled_ds.take(1):\n",
    "  print(repr(image_raw.numpy()[:100]))\n",
    "  print()\n",
    "  print(label_text.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2addee72",
   "metadata": {},
   "source": [
    "## Loteo de elementos del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2676f",
   "metadata": {},
   "source": [
    "### Loteo simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bdfeb",
   "metadata": {},
   "source": [
    "La transformación `Dataset.batch()` es la forma más sencilla de hacer un lote de `n` elementos consecutivos. Para cada componente, todos los elementos deben tener un tensor de exactamente la misma dimensión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "for batch in batched_dataset.take(4):\n",
    "  print([arr.numpy() for arr in batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7556d0",
   "metadata": {},
   "source": [
    "### Loteo de tensores con acolchamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1ee760",
   "metadata": {},
   "source": [
    "Con el loteo simple todos los tensores debe tener la misma dimensión, pero esto no va a ser el caso todas las veces. Utilizando `Dataset.padded_batch` se hace un acolchamiento de los tensores de distintas formas, específicando las dimensiones a las cuales hay que aplicar acolchamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3eefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(100)\n",
    "dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\n",
    "dataset = dataset.padded_batch(4, padded_shapes=(None,))\n",
    "\n",
    "for batch in dataset.take(2):\n",
    "  print(batch.numpy())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86393b8",
   "metadata": {},
   "source": [
    "## Flujo de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0559b46a",
   "metadata": {},
   "source": [
    "### Procesando múltiples epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ea876",
   "metadata": {},
   "source": [
    "La API ofrece dos maneras dde procesar múltiples epochs de los mismos datos.\n",
    "\n",
    "La primera manera es iterando sobre el el conjunto de datos utilizando `Dataset.repeat()`. volvemos al ejemplo de texto del Titanic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb100fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch_sizes(ds):\n",
    "  batch_sizes = [batch.shape[0] for batch in ds]\n",
    "  plt.bar(range(len(batch_sizes)), batch_sizes)\n",
    "  plt.xlabel('Batch number')\n",
    "  plt.ylabel('Batch size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03d2446",
   "metadata": {},
   "source": [
    "`Dataset.repeat` hace una concatenación de los argumentos sin señalar el inicio o el final de un epoch. Si aplicamos\n",
    "`Dataset.batch` Después de esta, se producirán lotes que van más allá de los límites e los epochs.\n",
    "\n",
    "Si la función `repeat` no tiene argumentos, se hara una repetición infinita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101543cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_batches = titanic_lines.repeat(3).batch(128)\n",
    "plot_batch_sizes(titanic_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3a7a1",
   "metadata": {},
   "source": [
    "si queremos una separación clara de los epoch, se aplica `Dataset.batch` antes de `repeat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d908a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_batches = titanic_lines.batch(128).repeat(3)\n",
    "\n",
    "plot_batch_sizes(titanic_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc609b7",
   "metadata": {},
   "source": [
    "Si queremos, por ejemplo, recopilar estadísticas al final de cada epoch, podemos hacer una iteración y reiniciar después de cada epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1125f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "dataset = titanic_lines.batch(128)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for batch in dataset:\n",
    "    print(batch.shape)\n",
    "  print(\"End of epoch: \", epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb311604",
   "metadata": {},
   "source": [
    "## Mezclar los datos de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a7dc0f",
   "metadata": {},
   "source": [
    "la transformación `Dataser.shuffle()` toma una muestra de un tamaño predeterminado y selecciona el siguiente dato del buffer.\n",
    "\n",
    "Le agregaremos un indice a los datos del titanic para que el efecto sea visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caee603",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = tf.data.TextLineDataset(titanic_file)\n",
    "counter = tf.data.experimental.Counter()\n",
    "\n",
    "dataset = tf.data.Dataset.zip((counter, lines))\n",
    "dataset = dataset.shuffle(buffer_size=100)\n",
    "dataset = dataset.batch(20)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26880f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,line_batch = next(iter(dataset))\n",
    "print(n.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1f1bc",
   "metadata": {},
   "source": [
    "`shuffle` no señala el fin de un epoch hasta que el buffer esté vacío. si aplicamos `repeat` antes de este, se podrá ver el momento en el que termina un epoch y empieza otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.zip((counter, lines))\n",
    "shuffled = dataset.shuffle(buffer_size=100).batch(10).repeat(2)\n",
    "\n",
    "print(\"esta es la lista de indices cercanos al fin del epoch:\\n\")\n",
    "for n, line_batch in shuffled.skip(60).take(5):\n",
    "  print(n.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af533fc",
   "metadata": {},
   "source": [
    "gráficamente se puede apreciar mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbb48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_repeat = [n.numpy().mean() for n, line_batch in shuffled]\n",
    "plt.plot(shuffle_repeat, label=\"shuffle().repeat()\")\n",
    "plt.ylabel(\"Mean item ID\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cee372",
   "metadata": {},
   "source": [
    "si ponemos `repeat`antes de la mezcla, los límites de los epoch se mantendrán iguales hasta que no hayan más objetos que mezclar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67caa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.zip((counter, lines))\n",
    "shuffled = dataset.repeat(2).shuffle(buffer_size=100).batch(10)\n",
    "\n",
    "print(\"esta es la lista de indices cercanos al fin del epoch:\\n\")\n",
    "for n, line_batch in shuffled.skip(55).take(15):\n",
    "  print(n.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_shuffle = [n.numpy().mean() for n, line_batch in shuffled]\n",
    "\n",
    "plt.plot(shuffle_repeat, label=\"shuffle().repeat()\")\n",
    "plt.plot(repeat_shuffle, label=\"repeat().shuffle()\")\n",
    "plt.ylabel(\"Mean item ID\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18dcabb",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ae4d1",
   "metadata": {},
   "source": [
    "si se quiere aplicar alguna función a los datos en cuestión, se utiliza  la transformación `Dataset.map(f)`. Esta toma los objetos `t f.Tensor` de un solo elemento y saca nuevos objetos en un nuevo conjunto de datos.\n",
    "\n",
    "Aquí mostramos dos ejemplos muy comunes de pre procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d4d6cc",
   "metadata": {},
   "source": [
    "### Decodificando imagenes y cambiar su tamaño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a97606",
   "metadata": {},
   "source": [
    "Al trabajar con imagenes de la vida cotidiana, lo más probable es que necesitemos estandarizar los tamaños a uno en común. \n",
    "\n",
    "Utilizaremos la lista de flores para este ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(flowers_root/'*/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61258b35",
   "metadata": {},
   "source": [
    "escribimos una función para manipular datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee una imagen de un archivo, la decodifica en un tensor y cambia su tamaño\n",
    "# a una forma predeterminada\n",
    "def parse_image(filename):\n",
    "  parts = tf.strings.split(filename, os.sep)\n",
    "  label = parts[-2]\n",
    "\n",
    "  image = tf.io.read_file(filename)\n",
    "  image = tf.image.decode_jpeg(image)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  image = tf.image.resize(image, [128, 128])\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = next(iter(list_ds))\n",
    "image, label = parse_image(file_path)\n",
    "\n",
    "def show(image, label):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(label.numpy().decode('utf-8'))\n",
    "  plt.axis('off')\n",
    "\n",
    "show(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ca90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ds = list_ds.map(parse_image)\n",
    "\n",
    "for image, label in images_ds.take(2):\n",
    "  show(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e05077",
   "metadata": {},
   "source": [
    "### Aplicando funciones de python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f1a76",
   "metadata": {},
   "source": [
    "Por razones de rendimiento, es mejor usar únicamente funciones de Tensorflow para manipular datos, pero a veces es necesario usar herramientas de otros paquetes de python.\n",
    "\n",
    "Para esto utilizamos `tf.py_function()` como función en `Dataset.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142fd91",
   "metadata": {},
   "source": [
    "Supongamos que queremos hacer una rotación aleatoria en un conjunto dde imágenes. Tensorflow sólo tiene `tf.image.rot90`, lo cual no sirve para la intención que se tiene. por suerte, el paquete scipy cuenta con `scipy.ndimage.rotate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndimage\n",
    "\n",
    "def random_rotate_image(image):\n",
    "  image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(images_ds))\n",
    "image = random_rotate_image(image)\n",
    "show(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_random_rotate_image(image, label):\n",
    "  im_shape = image.shape\n",
    "  [image,] = tf.py_function(random_rotate_image, [image], [tf.float32])\n",
    "  image.set_shape(im_shape)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24789039",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_ds = images_ds.map(tf_random_rotate_image)\n",
    "\n",
    "for image, label in rot_ds.take(2):\n",
    "  show(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b5fa9",
   "metadata": {},
   "source": [
    "## Ventaneo De series de tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb536e",
   "metadata": {},
   "source": [
    "En el caso de modelos de series de tiempo, estos datos están organizados con el axis de tiempo intacto. Muchas veces se le alimentaran secciones de tiempo adyacentes a los modelos como datos. Hay dos maneras de generar estos cortes. La primera es utilizando lotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ds = tf.data.Dataset.range(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983169c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = range_ds.batch(10, drop_remainder=True)\n",
    "\n",
    "for batch in batches.take(5):\n",
    "  print(batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6d13b",
   "metadata": {},
   "source": [
    "Para hacer predicciones un paso hacia el futuro, es ideal mover los datos y etiquetas un paso relativo a ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_1_step(batch):\n",
    "  # Se mueven las características y etiquetas un paso hacia la derecha\n",
    "  return batch[:-1], batch[1:]\n",
    "\n",
    "predict_dense_1_step = batches.map(dense_1_step)\n",
    "\n",
    "for features, label in predict_dense_1_step.take(3):\n",
    "  print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e456a3",
   "metadata": {},
   "source": [
    "Para predecir una ventana completa de tiempo, podemos separar los lotes en dos partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = range_ds.batch(15, drop_remainder=True)\n",
    "\n",
    "def label_next_5_steps(batch):\n",
    "  return (batch[:-5],   # Se toman los primeros 10 pasos\n",
    "          batch[-5:])   # se toma el residuo\n",
    "\n",
    "predict_5_steps = batches.map(label_next_5_steps)\n",
    "\n",
    "for features, label in predict_5_steps.take(3):\n",
    "  print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25566a",
   "metadata": {},
   "source": [
    "Para permitir que se superpongan las características de un lote y las etiquetas de otro, podemos usar `Dataset.zip()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_length = 10\n",
    "label_length = 3\n",
    "\n",
    "features = range_ds.batch(feature_length, drop_remainder=True)\n",
    "labels = range_ds.batch(feature_length).skip(1).map(lambda labels: labels[:label_length])\n",
    "\n",
    "predicted_steps = tf.data.Dataset.zip((features, labels))\n",
    "\n",
    "for features, label in predicted_steps.take(5):\n",
    "  print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bf71c6",
   "metadata": {},
   "source": [
    "Por supuesto, a veces se necesitan más control de las ventanas. Razón por la que se puede usar `Dataset.window`, pero para usarla correctamente, necesitamos algo de cuidado en lso datos. Esta transformación retorna un conjunto de conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ca603",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "\n",
    "windows = range_ds.window(window_size, shift=1)\n",
    "for sub_ds in windows.take(5):\n",
    "  print(sub_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be27b0",
   "metadata": {},
   "source": [
    "¿Pero qué pasó aquí? para ver los datos como un solo conjunto, usamos `Dataset.flat_map`. Al mismo tiempo casi siempre es necesario hacer lotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76eb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in windows.flat_map(lambda x: x).take(30):\n",
    "   print(x.numpy(), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe674529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_to_batch(sub):\n",
    "  return sub.batch(window_size, drop_remainder=True)\n",
    "\n",
    "for example in windows.flat_map(sub_to_batch).take(5):\n",
    "  print(example.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe59df",
   "metadata": {},
   "source": [
    "Haciéndolo todo junto, obtendríamos una función como esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n",
    "  windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "\n",
    "  def sub_to_batch(sub):\n",
    "    return sub.batch(window_size, drop_remainder=True)\n",
    "\n",
    "  windows = windows.flat_map(sub_to_batch)\n",
    "  return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f86203",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = make_window_dataset(range_ds, window_size=10, shift = 5, stride=3)\n",
    "\n",
    "for example in ds.take(10):\n",
    "  print(example.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac57a3",
   "metadata": {},
   "source": [
    "Es sencillo extraer etiquetas con estos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_labels_ds = ds.map(dense_1_step)\n",
    "\n",
    "for inputs,labels in dense_labels_ds.take(3):\n",
    "  print(inputs.numpy(), \"=>\", labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34415f-6a11-4d5e-bd49-294925530ce1",
   "metadata": {},
   "source": [
    "##  Remuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c73e4-959d-4df9-876f-4c38dcc151bd",
   "metadata": {},
   "source": [
    "Es usual encontrarse con datasets desbalanceados a nivel de clases. Es buena idea aquí el hacer un remuestreo del dataset. `tf.data` da dos métodos para esto\n",
    "\n",
    "Se usará el dataset de fraude de tarjetas de crédito es perfecto para demostrarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1007d7f-2472-4f27-8e88-2ada2fe8733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/creditcard.zip\n",
      "69156864/69155632 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/download.tensorflow.org/data/creditcard.zip',\n",
    "    fname='creditcard.zip',\n",
    "    cache_dir='/media/storage',\n",
    "    cache_subdir='Datasets',\n",
    "    extract=True)\n",
    "\n",
    "csv_path = zip_path.replace('.zip', '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "490f74c8-1652-4a95-87f0-39a79887c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_ds = tf.data.experimental.make_csv_dataset(\n",
    "    csv_path, batch_size=1024, label_name=\"Class\",\n",
    "    # Set the column types: 30 floats and an int.\n",
    "    column_defaults=[float()]*30+[int()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99834524-d019-4370-aa7b-1076a1f4cdd8",
   "metadata": {},
   "source": [
    "Se revisará ahora la distribución de las clases a clasificar, para ver qué tan sesgados están"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67469b-0438-4e87-9f9c-ce92704dc607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(counts, batch):\n",
    "  features, labels = batch\n",
    "  class_1 = labels == 1\n",
    "  class_1 = tf.cast(class_1, tf.int32)\n",
    "\n",
    "  class_0 = labels == 0\n",
    "  class_0 = tf.cast(class_0, tf.int32)\n",
    "\n",
    "  counts['class_0'] += tf.reduce_sum(class_0)\n",
    "  counts['class_1'] += tf.reduce_sum(class_1)\n",
    "\n",
    "  return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d0916-3c83-4578-a3c0-ea0803e6110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = creditcard_ds.take(10).reduce(\n",
    "    initial_state={'class_0': 0, 'class_1': 0},\n",
    "    reduce_func = count)\n",
    "\n",
    "counts = np.array([counts['class_0'].numpy(),\n",
    "                   counts['class_1'].numpy()]).astype(np.float32)\n",
    "\n",
    "fractions = counts/counts.sum()\n",
    "print(fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb2701-8c80-4bf0-91ff-e83790be58c6",
   "metadata": {},
   "source": [
    "Para poder trabajar con datos desbalanceados, la mejor idea es balancearlos. Aquí algunos métodos para esto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7358b9-a0d8-4ba3-8a47-703a991e7b7a",
   "metadata": {},
   "source": [
    "### Muestreo de Datasets\n",
    "\n",
    "La forma más sencilla es usar `sample_from_datasets`. Esto es particularmente mejor cuando se tienen datasets separados por clase. Para este caso se va a filtrar los datos de fraude para esta razón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c964a6-c766-48c9-b826-acab83ed17f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_ds = (\n",
    "  creditcard_ds\n",
    "    .unbatch()\n",
    "    .filter(lambda features, label: label==0)\n",
    "    .repeat())\n",
    "positive_ds = (\n",
    "  creditcard_ds\n",
    "    .unbatch()\n",
    "    .filter(lambda features, label: label==1)\n",
    "    .repeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3411beb-7b19-4015-add3-4dfab0689522",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in positive_ds.batch(10).take(1):\n",
    "  print(label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc584bec-d89e-4355-8ce9-e733e9711bbe",
   "metadata": {},
   "source": [
    "Se pasarán los datasets, junto con los pesos que se quieren por `tf.data.experimental.sample_from_datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabccce-b803-463c-88f9-8a168f79e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ds = tf.data.experimental.sample_from_datasets(\n",
    "    [negative_ds, positive_ds], [0.5, 0.5]).batch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2211ed0-03c7-48dd-9fc9-38ee53a533f3",
   "metadata": {},
   "source": [
    "Ahora se generarán ejemplos de las clases con una probabilidad 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702740b-0360-45a2-8869-10ccc8497c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, labels in balanced_ds.take(10):\n",
    "  print(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91442a84-fdcd-4d4f-9526-a6f67b5dc98a",
   "metadata": {},
   "source": [
    "## Remuestreo de rechazo\n",
    "\n",
    "Como se dijo, necesitamos que los datasets estén separados por clase. Podemos por supuesto usar `Dataset.filter`, pero eso haría que los datos se cargaran dos veces.\n",
    "\n",
    "La función `data.experimental.rejection_resample` permite rebalancear los datos sin tener que cargarlos otra vez. Esto se logra eliminando elementos del dataset para llegar al balance.\n",
    "\n",
    "Esta función toma un argumento `class_func`. Esta función es aplicada a cada elemento del dataset para determinar la clase que tiene.\n",
    "\n",
    "Los elementos de `creditcard_ds` ya están separados en pares `(features,label)`. Así que la función solo tiene que retornar la etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791caf9-3d4d-4ff2-9dd8-7ca86258992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_func(features, label):\n",
    "  return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d40608-e453-4059-8dc4-f60406e34caa",
   "metadata": {},
   "source": [
    "De igual forma es necesaria una distribución objetivo y preferiblemente un estimado de esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2dfbb2-3b17-48ab-a5c5-bf7db5bf34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = tf.data.experimental.rejection_resample(\n",
    "    class_func, target_dist=[0.5, 0.5], initial_dist=fractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a283ba5-7481-4a97-b08b-36545b413d33",
   "metadata": {},
   "source": [
    "`resampler` trabaja con las observaciones de manera individual, así que hay que aplicar `unbatch()` antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3c93d-c728-4c31-a4e2-bf278728f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_ds = creditcard_ds.unbatch().apply(resampler).batch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8bb51-4ca5-4488-97c1-46a5858c0f17",
   "metadata": {},
   "source": [
    "el resampler retorna pares del tipo `(class, example)` a partír de la salida de `class_func`. En este caso ya tenemos `(feature, label)`, así que se hace un map para obtener una copia extra de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07fe5e-f22f-4844-b61a-f5519c368d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ds = resample_ds.map(lambda extra_label, features_and_label: features_and_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837f56d-65b9-4652-88db-d0a0e95e5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, labels in balanced_ds.take(10):\n",
    "  print(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb94a9-5bc1-4cf8-b3ef-6fb6f1f492bd",
   "metadata": {},
   "source": [
    "Cuál es el problema de este método? si el desbalanceo es muy grande, se va a perder una cantidad muy grande de datos. ¿Qué es más importante: La cantidad de datos o la cantidad de recursos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de788d2a-0405-4645-8248-91baa06df733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
