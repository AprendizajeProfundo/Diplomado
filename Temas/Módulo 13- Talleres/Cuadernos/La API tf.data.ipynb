{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91305041",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab4281",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Canalización  de datos. La API tf.data</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7e154",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dcabbf",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44789764",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ba0f5",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a9c1a",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2aa11",
   "metadata": {},
   "source": [
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaad8a2",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45a739",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5e69ba6",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a2fef",
   "metadata": {},
   "source": [
    "Basado en [tf.data](https://www.tensorflow.org/guide/data).\n",
    "\n",
    "La API `tf.data` permite crear tuberías de entrada complejas a partir de piezas simples y reutilizables. Por ejemplo, la canalización de un modelo de imagen podría agregar datos de archivos en un sistema de archivos distribuido, aplicar perturbaciones aleatorias a cada imagen y fusionar imágenes seleccionadas al azar en un lote para entrenamiento. La canalización de un modelo de texto puede implicar extraer símbolos de datos de texto sin procesar, convertirlos en identificadores incrustados con una tabla de búsqueda y agrupar secuencias de diferentes longitudes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce2610",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Importa librerías</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94aed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f3228",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Esenciales</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d32497",
   "metadata": {},
   "source": [
    "Para crear una canalización de entrada, debe comenzar con una fuente de datos. Por ejemplo, para construir un `Dataset` de datos a partir de datos en la memoria, puede usar *tf.data.Dataset.from_tensors()* o *tf.data.Dataset.from_tensor_slices()*. Alternativamente, si sus datos de entrada están almacenados en un archivo en el formato *TFRecord* de TensorFlow puede usar *tf.data.TFRecordDataset()*.\n",
    "\n",
    "El objeto Dataset es un iterable de Python. Esto hace posible consumir sus elementos usando un bucle for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee81b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d48b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f9a376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n",
      "0\n",
      "8\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset:\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3f4e2",
   "metadata": {},
   "source": [
    "o se pueden crear explícitamente un iterador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7938634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "it = iter(dataset)\n",
    "print(next(it).numpy())\n",
    "print(next(it).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff212ae",
   "metadata": {},
   "source": [
    "### Consumo de datos usando reducción: reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b40569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(dataset.reduce(0, lambda state, value: state+value).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423cd4a1",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Estructura del conjunto de datos</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4026dd3",
   "metadata": {},
   "source": [
    "Un conjunto de datos produce una secuencia de elementos , donde cada elemento tiene la misma estructura (anidada) de componentes . \n",
    "\n",
    "Los componentes individuales de la estructura pueden ser de cualquier tipo representable por *tf.TypeSpec*, incluidos *tf.Tensor* , *tf.sparse.SparseTensor* ,*tf.RaggedTensor* , *tf.TensorArray* o *tf.data.Dataset*.\n",
    "\n",
    "Las construcciones de Python que se pueden usar para expresar la estructura (anidada) de elementos incluyen *tuple , dict , NamedTuple y OrderedDict*. \n",
    "\n",
    "En particular, *list* no es una construcción válida para expresar la estructura de los elementos del conjunto de datos. \n",
    "\n",
    "Si desea que una entrada de *list* se trate como una estructura, debe convertirla en tuple y si desea que una lista de salida, entonces debe empaquetarla explícitamente usando *tf.stack*.\n",
    "\n",
    "\n",
    "La propiedad *Dataset.element_spec* permite inspeccionar el tipo de cada componente del elemento. La propiedad devuelve una estructura anidada de objetos *tf.TypeSpec*, que coincide con la estructura del elemento, que puede ser un solo componente, una tupla de componentes o una tupla anidada de componentes. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b197719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (10,), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))\n",
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f70ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7701 0.552  0.7585 0.4115 0.8178 0.644  0.5679 0.1752 0.4314 0.8794]\n",
      "[0.2899 0.756  0.6285 0.7384 0.1255 0.4635 0.6919 0.9342 0.3346 0.502 ]\n",
      "[0.3587 0.9728 0.4452 0.4349 0.2622 0.8186 0.6079 0.0305 0.0648 0.0877]\n",
      "[0.8672 0.6902 0.4152 0.436  0.0207 0.2833 0.8699 0.324  0.7565 0.297 ]\n"
     ]
    }
   ],
   "source": [
    "for i in dataset1:\n",
    "    print(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ff5531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a53853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(100,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random.uniform([4]),\n",
    "     tf.random.uniform([4,100], maxval=100, dtype=tf.int32)))\n",
    "\n",
    "dataset2.element_spec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4f6352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8dd0db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(10,), dtype=tf.float32, name=None),\n",
       " (TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(100,), dtype=tf.int32, name=None)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "dataset3.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3939bca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c53bb5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.ZipDataset"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d01c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6c1a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([0.005 , 0.8077, 0.5108, 0.9167, 0.8164, 0.3464, 0.8314, 0.5843,\n",
      "       0.3102, 0.061 ], dtype=float32)>, (<tf.Tensor: shape=(), dtype=float32, numpy=0.42063427>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([94, 69, 73, 69, 12, 22, 78, 91, 27, 35, 72,  2, 47, 65, 49, 48, 31,\n",
      "       60, 81, 18, 47,  9, 25,  0, 51,  4, 46, 66, 47, 67, 91, 21, 41, 11,\n",
      "       25, 92, 79, 57, 43, 84, 14, 42, 36, 27,  4, 82, 39, 98, 34, 60, 44,\n",
      "       30, 83, 55, 82, 48,  9, 53, 43, 44, 20, 37, 78, 81, 80, 39, 27, 72,\n",
      "       76, 86, 51,  5, 18, 22, 51, 19, 14, 22,  1, 84, 48, 83, 48, 68, 25,\n",
      "       32, 15, 44, 62, 67, 10, 68, 86, 76,  2, 76, 98,  8, 52, 97],\n",
      "      dtype=int32)>)) \n",
      "\n",
      "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([0.8523, 0.9912, 0.8094, 0.8738, 0.2482, 0.9336, 0.6535, 0.4829,\n",
      "       0.6793, 0.1769], dtype=float32)>, (<tf.Tensor: shape=(), dtype=float32, numpy=0.47015595>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([15, 58, 80, 36, 40, 67, 59, 57,  5, 42, 99, 10, 97, 99, 19,  5, 93,\n",
      "       16, 48, 42, 98, 98, 48, 20, 35, 82, 56, 73, 65, 12, 21, 88,  0, 31,\n",
      "       94, 43, 45, 10, 98,  0, 43, 19, 50, 58, 65, 46, 64, 72, 85, 55, 69,\n",
      "       31, 57, 42, 58, 47, 70, 33, 42, 19, 61, 81, 13, 62, 52, 66, 35,  8,\n",
      "       57, 60, 43, 72,  1, 83, 84, 66, 45,  9, 85, 90, 14, 26, 23, 13,  9,\n",
      "       94, 12, 92, 20, 18, 41, 95, 79, 37, 25, 64, 65, 83,  5, 60],\n",
      "      dtype=int32)>)) \n",
      "\n",
      "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([0.7595, 0.7873, 0.1764, 0.3435, 0.271 , 0.0647, 0.5544, 0.5785,\n",
      "       0.3854, 0.1654], dtype=float32)>, (<tf.Tensor: shape=(), dtype=float32, numpy=0.08954549>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([67, 17, 99, 81, 34, 51,  3, 47, 82, 87, 27, 79, 29, 73,  7, 50, 24,\n",
      "       85, 16, 21, 42, 41, 15, 58, 23, 33, 36, 26, 49, 30,  7, 71, 75, 65,\n",
      "       41, 80, 11, 18,  0, 94, 42, 80, 78, 22, 59, 28,  1, 60,  8, 39, 44,\n",
      "       77, 29, 56, 80, 18, 83, 66, 24, 96, 51, 56, 41, 50, 56, 11, 21, 75,\n",
      "       28,  7, 28, 75, 77, 32, 90, 60, 60, 38, 53, 43, 27, 58, 30, 71, 83,\n",
      "       29, 32, 27, 59, 80, 28, 74, 74, 41,  4, 57, 72, 88, 90, 89],\n",
      "      dtype=int32)>)) \n",
      "\n",
      "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([2.2304e-04, 3.9328e-01, 1.6936e-01, 7.0020e-01, 7.1070e-01,\n",
      "       9.5673e-03, 7.0323e-01, 4.2085e-01, 2.1215e-01, 6.5685e-01],\n",
      "      dtype=float32)>, (<tf.Tensor: shape=(), dtype=float32, numpy=0.9034705>, <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
      "array([42, 54, 59, 40, 69, 71, 98, 17, 26, 74, 95, 42, 36, 92, 52, 45, 88,\n",
      "        8, 63, 22, 34, 24, 38, 67, 82, 85, 61, 29, 45, 66, 92, 71, 13, 25,\n",
      "       34, 25,  6, 48,  6, 51, 73, 32, 53, 77, 90, 61, 24, 29, 15, 47, 59,\n",
      "       28, 35, 61, 32, 34,  0, 45,  7, 37, 57, 29, 24, 70, 53, 19, 51, 31,\n",
      "       87, 17, 60, 21, 37, 54, 80, 66, 96, 70,  5, 81, 59, 50, 88, 90, 75,\n",
      "       64, 49,  8, 15, 79, 12,  7, 86, 76, 28, 98, 21, 76, 53, 82],\n",
      "      dtype=int32)>)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(i.next(), \"\\n\")\n",
    "print(i.next(), \"\\n\")\n",
    "print(i.next(), \"\\n\")\n",
    "print(i.next(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a77aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensorSpec(TensorShape([3, 4]), tf.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset con tensores dispersos\n",
    "dataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0, 0],[1, 2]], values=[1, 2], dense_shape=[3, 4]))\n",
    "dataset4.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eedfb926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.sparse_tensor.SparseTensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4.element_spec.value_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4bea5151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (10,), (), (100,)\n",
      "shapes: (10,), (), (100,)\n",
      "shapes: (10,), (), (100,)\n",
      "shapes: (10,), (), (100,)\n"
     ]
    }
   ],
   "source": [
    "for a, (b,c) in dataset3:\n",
    "    print('shapes: {a.shape}, {b.shape}, {c.shape}'.format(a=a, b=b, c=c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637109c",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Leer datos de entrada</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9bccfe",
   "metadata": {},
   "source": [
    "### Consumir matrices Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bb59be",
   "metadata": {},
   "source": [
    "Si todos sus datos de entrada caben en la memoria, la forma más sencilla de crear un Dataset a partir de ellos es convertirlos en objetos tf.Tensor y usar Dataset.from_tensor_slices() ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cea8d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e28f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28), ()), types: (tf.float64, tf.uint8)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenes, labels  = train\n",
    "imagenes = imagenes /255.\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((imagenes, labels))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1dfb3",
   "metadata": {},
   "source": [
    "### Consumir generadores de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6f218a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def count(stop):\n",
    "    i=0\n",
    "    while i<stop:\n",
    "        yield i\n",
    "        i+= 1\n",
    "        \n",
    "for n in count(5):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ac52d",
   "metadata": {},
   "source": [
    "El constructor `Dataset.from_generator` convierte el generador de Python en un `tf.data.Dataset` completamente funcional.\n",
    "\n",
    "El constructor toma un invocable como entrada, no un iterador. Esto le permite reiniciar el generador cuando llega al final. Toma un argumento args opcional, que se pasa como argumentos del invocable.\n",
    "\n",
    "El argumento *output_types* es necesario porque *tf.data* crea un *tf.Graph* internamente y los bordes del gráfico requieren un tf.dtype .\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f0120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_counter = tf.data.Dataset.from_generator(count, args=[25], output_types=tf.int32, output_shapes=(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b0762d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24  0  1  2  3  4]\n",
      "[ 5  6  7  8  9 10 11 12 13 14]\n",
      "[15 16 17 18 19 20 21 22 23 24]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24  0  1  2  3  4]\n",
      "[ 5  6  7  8  9 10 11 12 13 14]\n",
      "[15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "for count_batch in ds_counter.repeat().batch(10).take(10):\n",
    "    print(count_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2adb0",
   "metadata": {},
   "source": [
    "El argumento `output_shapes` no es necesario, pero se recomienda, ya que muchas operaciones de flujo tensorial no admiten tensores con rango desconocido. Si la longitud de un eje en particular es desconocida o variable, output_shapes puede colcarse como None.\n",
    "\n",
    "También es importante tener en cuenta que `output_shapes` y `output_types` siguen las mismas reglas de anidamiento que otros métodos de conjuntos de datos.\n",
    "\n",
    "Aquí hay un generador de ejemplo que demuestra ambos aspectos, devuelve tuplas de matrices, donde la segunda matriz es un vector con longitud desconocida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91e3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_series():\n",
    "    i = 0\n",
    "    while True:\n",
    "        size = np.random.randint(0,10)\n",
    "        yield i, np.random.normal(size = (size,))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b4fa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [-0.589  -0.1256  0.1138  0.6881 -1.1627  1.226   0.3724 -0.1009]\n",
      "1 : [ 0.4862  2.7924 -0.5485  0.4517 -0.8274 -0.5066 -0.079 ]\n",
      "2 : [-2.0796e+00 -1.7316e-05  1.2649e+00  1.2178e+00 -6.4795e-02 -1.2795e+00\n",
      " -2.1617e+00 -5.6905e-02]\n",
      "3 : [-0.2579  1.3068  0.4814]\n",
      "4 : [0.8903 1.1579]\n",
      "5 : [ 1.1675 -0.9602  0.8503  0.0468]\n",
      "6 : [ 1.1075  0.1869  1.099  -1.0206 -0.0775]\n"
     ]
    }
   ],
   "source": [
    "for i, series in gen_series():\n",
    "    print(i, \":\", str(series))\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb7888",
   "metadata": {},
   "source": [
    "La primera salida es un *int32* la segunda es un *float32*.\n",
    "\n",
    "El primer elemento es un escalar, forma () , y el segundo es un vector de longitud desconocida, forma (None,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0838c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: ((), (None,)), types: (tf.int32, tf.float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_series = tf.data.Dataset.from_generator(\n",
    "    gen_series,\n",
    "    output_types=(tf.int32, tf.float32),\n",
    "    output_shapes=((), (None, )))\n",
    "\n",
    "ds_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851d61b",
   "metadata": {},
   "source": [
    "Ahora se puede utilizar como un *tf.data.Dataset* normal. Tenga en cuenta que al procesar por lotes un conjunto de datos con una forma variable, debe usar *Dataset.padded_batch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e2f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 11 10 12  6 17 24  2 27  9]\n",
      "\n",
      "[[-1.4308e+00  1.2503e-03  1.3745e+00 -2.3217e+00  7.8626e-02  3.0368e-01\n",
      "  -8.8505e-01  6.8241e-01]\n",
      " [ 2.7771e-01 -2.8299e-01  5.7397e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [ 4.7146e-01  1.0614e-02  6.7689e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [ 1.5210e+00  3.3249e-01  2.0336e-01 -1.2920e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [-4.5420e-01 -5.6538e-02  2.1903e+00 -8.4784e-02  3.2478e-01 -1.7719e+00\n",
      "  -1.0545e+00  5.3183e-01]\n",
      " [-3.9575e-01 -7.3953e-01 -1.9150e+00  1.9243e+00  6.4415e-01  1.3259e+00\n",
      "   6.1047e-01  7.0616e-01]\n",
      " [-5.2022e-01 -3.6112e-01 -5.0845e-01 -5.7890e-01  9.5692e-01  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [ 6.5591e-01  2.2062e+00  8.2903e-01  4.3211e-01 -6.5034e-01 -2.1691e-01\n",
      "   0.0000e+00  0.0000e+00]\n",
      " [-5.7040e-01 -9.4705e-01  1.2774e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00  0.0000e+00]]\n"
     ]
    }
   ],
   "source": [
    "ds_series_batch = ds_series.shuffle(20).padded_batch(10)\n",
    "\n",
    "ids, sequence_batch = next(iter(ds_series_batch))\n",
    "\n",
    "print (ids.numpy())\n",
    "print()\n",
    "print(sequence_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823a94af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 15  3  0 18  1 14 16 27  5]\n",
      "\n",
      "[[-1.061  -0.9733 -1.086  -0.9015 -0.0504  0.      0.      0.      0.    ]\n",
      " [-0.0574  0.7203 -0.9158  1.0477  0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.622   1.1692 -1.946   0.0864 -0.8531  0.711  -1.5698  3.2136  0.5569]\n",
      " [-0.65    0.4697 -0.6727 -0.9256 -2.3336 -0.872  -0.1654  0.      0.    ]\n",
      " [-0.5982 -0.3164  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.4281  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.4866 -0.5384 -0.3614 -0.1805 -1.3637 -1.2998  0.      0.      0.    ]\n",
      " [-1.4777 -0.8462  0.6291  0.8153 -0.7571  0.7379 -0.3234  0.      0.    ]\n",
      " [-1.0155 -0.2286  0.4975 -1.0118  0.9367 -0.2049  0.9626 -1.4553  0.    ]]\n",
      "[20 28  4  7 10 26 19 33 34 37]\n",
      "\n",
      "[[ 0.6415  0.2909  0.6327  0.7194  0.9924  0.3216  0.9457  1.3295 -0.297 ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.4123  0.249  -0.3707 -1.1176  1.2714 -0.4981  0.1749  0.      0.    ]\n",
      " [ 1.0497  0.2161 -1.5642 -1.0194 -1.339  -0.4206 -0.4466  0.      0.    ]\n",
      " [-0.4691  0.3843 -0.4399 -0.0827 -0.037  -1.2655  0.      0.      0.    ]\n",
      " [ 1.3068 -0.1152 -0.9747  0.5002  0.5194 -2.4075  0.69   -0.8024  0.    ]\n",
      " [ 0.9479 -0.5621  0.4167  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.2892 -0.1233  0.2965 -1.0062 -0.8388 -0.1377  1.7866  0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-2.2404  0.7434  0.482  -2.0774  0.6526  1.449  -0.4649  1.3537  0.    ]]\n",
      "[21 29 17 11 30 35 13 32 24  6]\n",
      "\n",
      "[[ 0.091   1.86   -1.613   2.1924 -0.8233  0.      0.      0.      0.    ]\n",
      " [-0.5686  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.6955  1.2547  1.1846  0.0726 -1.248   2.2344  0.      0.      0.    ]\n",
      " [ 1.109   0.5102 -1.5476  0.8743  0.      0.      0.      0.      0.    ]\n",
      " [ 1.0322 -0.3177 -0.6883  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.0356 -1.0002  0.1431  0.7197  0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.28    1.0436 -0.7285 -0.2547 -1.6978 -2.2856 -0.6472  0.0967 -1.1045]\n",
      " [ 0.3716  0.8146  0.4355  0.7917  0.      0.      0.      0.      0.    ]\n",
      " [ 0.5569 -1.2342 -3.6194 -1.958   0.0583 -0.8167  0.4711 -0.0936  0.    ]]\n",
      "[12 43 48 23 45 46 47 36 52 56]\n",
      "\n",
      "[[ 1.2062 -1.1236 -0.048  -0.0438 -0.6262 -0.2112  1.0346  0.      0.    ]\n",
      " [-0.2326 -0.0269 -0.2311 -0.7235  0.3564  0.2441  0.      0.      0.    ]\n",
      " [-1.6974 -0.2189  0.491  -1.3288  0.      0.      0.      0.      0.    ]\n",
      " [ 0.0213 -1.3896  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.8177  0.2192  0.2072  1.5999  1.1342  0.1494  1.4222 -0.0525  0.    ]\n",
      " [-0.1186 -1.8247  1.4119 -0.3185 -2.4551 -2.2378  1.4648  0.5712 -0.0174]\n",
      " [ 1.2405 -0.1798  0.8166  0.8488 -0.7695  0.      0.      0.      0.    ]\n",
      " [ 0.1639 -0.8201  0.7183 -0.4152  0.      0.      0.      0.      0.    ]\n",
      " [ 0.4919 -0.4651  0.      0.      0.      0.      0.      0.      0.    ]]\n",
      "[ 9 49 44 40 58 22 51 64 41 68]\n",
      "\n",
      "[[-1.0382  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.0762 -1.1752 -1.0222 -0.6238  0.      0.      0.      0.      0.    ]\n",
      " [ 1.0578  0.0443  0.3129  0.7043 -1.0824  1.6281  1.4794  0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-2.9071  0.1692 -0.4456  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.9951 -0.0948  0.5371 -0.5327 -0.9355  0.3269 -0.3262 -0.4353 -2.0679]\n",
      " [-1.185  -0.5563 -0.2186 -1.2259 -0.1062 -1.3341 -2.3542  0.      0.    ]\n",
      " [ 1.5576 -2.5929  0.6207  0.3497  0.0442 -1.2365  0.      0.      0.    ]\n",
      " [-0.9038 -0.3967  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.3752  0.1753  0.0404  0.2315  0.7343 -1.1412  0.5085  0.1616  0.    ]]\n",
      "[ 2 53 54 25 39 70 42 73 71 61]\n",
      "\n",
      "[[ 0.1069 -0.795   1.7239  0.7955 -0.9159  0.3252 -0.5409  0.      0.    ]\n",
      " [ 0.8746 -0.4516  0.7034  0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.3709  0.1908  1.9067  1.0218 -1.539   0.0224  1.0625  0.1118 -0.2185]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.5401  0.3357  0.9631 -1.4324  0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.2262  0.8504 -0.3917  1.2562 -0.1926 -0.6387  1.2296  0.2896  0.    ]\n",
      " [ 0.7385  0.0576  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.7807 -0.2055  2.576   0.0649  0.1558  0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]]\n",
      "[31 38 60 79 57 84 76 85 55 69]\n",
      "\n",
      "[[ 1.0282 -0.9697  0.1665  0.5753  0.6974  0.602   0.6128 -0.0055 -0.1214]\n",
      " [-1.3045  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.3483  2.2697 -2.0837 -0.1758 -0.2648 -0.5521  0.0613  0.      0.    ]\n",
      " [ 0.6735  0.3745 -0.9292  0.7181  0.0915  0.6997  0.      0.      0.    ]\n",
      " [ 1.6229  0.8262  1.0865  0.3144  1.1952  0.      0.      0.      0.    ]\n",
      " [ 0.7018  1.2427  0.5242  0.5466 -1.1127  1.2862  0.5914  0.      0.    ]\n",
      " [ 1.1784  0.7991  1.0707  0.9579  1.5032  0.3039  0.724  -0.189   1.1448]\n",
      " [-0.0158 -0.5564  2.1265  0.1532 -0.3716  0.3793  1.352   0.295   0.    ]\n",
      " [ 1.2571  0.6774  0.8748 -1.9973 -0.8848  0.1811  0.7692  1.1288 -1.7268]\n",
      " [ 0.2996 -0.9278  0.463  -1.5246 -0.1851  1.3015  0.5428  0.      0.    ]]\n",
      "[78 86 91 59 66 88 93 50 89 67]\n",
      "\n",
      "[[ 1.0541  0.1648  0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.897   0.3443  1.2535 -0.5569  0.9309  0.      0.    ]\n",
      " [-0.8435 -1.3927  0.      0.      0.      0.      0.    ]\n",
      " [-0.4433 -0.0435  0.2736  0.3609 -0.3608 -1.8202 -0.5321]\n",
      " [-0.0614 -0.7187  0.      0.      0.      0.      0.    ]\n",
      " [-0.0929 -0.669  -1.4745 -0.2946  0.      0.      0.    ]\n",
      " [ 0.5474  0.0566  0.1551  0.5368 -1.2945  0.      0.    ]\n",
      " [ 0.025   1.4574  0.8196  0.736  -1.3252  0.9304  0.6404]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.    ]]\n",
      "[ 98  99  96 100  92  77  72  97  94 106]\n",
      "\n",
      "[[-2.6717 -0.2488  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.2295  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-1.3222  0.3027 -0.7591 -0.5921  0.0696 -0.3168 -0.5843  0.2897  0.    ]\n",
      " [-0.6431  0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.5212 -0.5611 -0.0837  0.1093  0.      0.      0.      0.      0.    ]\n",
      " [ 1.7704  0.1023 -1.1097  0.9471  0.5703  0.3061  0.      0.      0.    ]\n",
      " [ 0.2904  0.7919 -0.8194 -0.5143  0.64   -0.9226  0.7745 -0.1132  1.6467]\n",
      " [-0.0967  0.2127  2.5712  0.4878  0.      0.      0.      0.      0.    ]\n",
      " [ 0.1793 -0.9324  1.7617  1.6121 -0.7636  0.7994  1.151   0.8001 -0.126 ]\n",
      " [-0.5864  0.5013  0.8564  1.9404  0.3083 -0.871   0.      0.      0.    ]]\n",
      "[102 110 108 104 109  82  65  90 115  87]\n",
      "\n",
      "[[ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-0.3764  0.6626  2.1808  0.5353  0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 1.1854 -0.0532  1.0557 -0.5879 -0.0735 -0.3586  0.5515  0.7449  0.    ]\n",
      " [ 0.1942 -0.4841  0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.3521  0.4924  0.3921  1.0547 -0.3878  0.      0.      0.      0.    ]\n",
      " [-0.3893 -0.5739  0.8038  1.7658 -1.5248 -0.0503 -1.2213 -0.3445  0.    ]\n",
      " [ 2.6701  0.5938  0.9605  0.1734  0.2227 -0.2345  0.6217  0.      0.    ]\n",
      " [-1.2166  1.0228 -0.4143  1.3087  0.2272  0.0957  1.23   -0.3671 -1.4558]\n",
      " [-1.6257  0.6211 -0.6578 -0.3894  2.0263  0.      0.      0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "it = iter(ds_series_batch)\n",
    "for i in range(10):\n",
    "    ids, sequence_batch = next(it)\n",
    "    print (ids.numpy())\n",
    "    print()\n",
    "    print(sequence_batch.numpy())\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c90462",
   "metadata": {},
   "source": [
    "### Ejemplo realista con imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e531237",
   "metadata": {},
   "source": [
    "Para obtener un ejemplo más realista, intente `tf.data.Dataset` `preprocessing.image.ImageDataGenerator` como un `tf.data.Dataset` .\n",
    "\n",
    "Primero descargue los datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb11a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228818944/228813984 [==============================] - 100s 0us/step\n"
     ]
    }
   ],
   "source": [
    "flowers = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9335c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alvaro/.keras/datasets/flower_photos\n"
     ]
    }
   ],
   "source": [
    "print(flowers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd87ab6",
   "metadata": {},
   "source": [
    "Cree la `image.ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7677d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b82eacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(image_gen.flow_from_directory(flowers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "959a7d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (32, 256, 256, 3)\n",
      "float32 (32, 5)\n"
     ]
    }
   ],
   "source": [
    "print(images.dtype, images.shape)\n",
    "print(labels.dtype, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "790b066c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(32, 256, 256, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 5), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_generator(\n",
    "    lambda: image_gen.flow_from_directory(flowers),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([32,256,256,3],[32,5]))\n",
    "\n",
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e62253",
   "metadata": {},
   "source": [
    "### Consumir datos de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef26f03",
   "metadata": {},
   "source": [
    "Muchos conjuntos de datos se distribuyen como uno o más archivos de texto. `tf.data.TextLineDataset` proporciona una manera fácil de extraer líneas de uno o más archivos de texto. \n",
    "\n",
    "Dados uno o más nombres de archivo, un `TextLineDataset` producirá un elemento con valor de cadena por línea de esos archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "605a2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt\n",
      "819200/815980 [==============================] - 12s 14us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n",
      "811008/809730 [==============================] - 21s 26us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n",
      "811008/807992 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
    "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
    "\n",
    "file_paths = [\n",
    "    tf.keras.utils.get_file(file_name, directory_url +file_name)\n",
    "    for file_name in file_names\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db3d3e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/alvaro/.keras/datasets/cowper.txt',\n",
       " '/home/alvaro/.keras/datasets/derby.txt',\n",
       " '/home/alvaro/.keras/datasets/butler.txt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a4d3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854860a",
   "metadata": {},
   "source": [
    "Estas son las primeras líneas del primer archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4165db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\xef\\xbb\\xbfAchilles sing, O Goddess! Peleus' son;\"\n",
      "b'His wrath pernicious, who ten thousand woes'\n",
      "b\"Caused to Achaia's host, sent many a soul\"\n",
      "b'Illustrious into Ades premature,'\n",
      "b'And Heroes gave (so stood the will of Jove)'\n"
     ]
    }
   ],
   "source": [
    "for line in dataset.take(5):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb46f1",
   "metadata": {},
   "source": [
    "Para alternar líneas entre archivos, use `Dataset.interleave` . Esto facilita la reproducción aleatoria de archivos. Aquí están la primera, segunda y tercera líneas de cada traducción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5ccc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds = tf.data.Dataset.from_tensor_slices(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd77f921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/home/alvaro/.keras/datasets/cowper.txt'\n",
      "b'/home/alvaro/.keras/datasets/derby.txt'\n",
      "b'/home/alvaro/.keras/datasets/butler.txt'\n"
     ]
    }
   ],
   "source": [
    "for i in file_ds: print(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_ds = files_ds.interleave(tf.data.TextLineDataset, cycle_length=3)\n",
    "\n",
    "for i, line in enumerate(lines_ds.take(9)):\n",
    "    if i%3 ==0:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5626a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]]\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],]) \n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09ed2482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrae la primera capa\n",
      " tf.Tensor(\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]], shape=(2, 5), dtype=int32)\n",
      "Extrae la segunda capa\n",
      " tf.Tensor(\n",
      "[[10 11 12 13 14]\n",
      " [15 16 17 18 19]], shape=(2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('Extrae la primera capa\\n', t[0,:,:])\n",
    "print('Extrae la segunda capa\\n', t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9aa103",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Manipular formas</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9be66783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "[3, 1]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1],[2],[3]])\n",
    "print(x.shape)\n",
    "print(x.shape.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "519c9215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]]\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "reshaped = tf.reshape(x,[1,3])\n",
    "print(reshaped.numpy())\n",
    "print(x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d2147",
   "metadata": {},
   "source": [
    "Con *tf.reshape* los datos mantienen su disposición en la memoria y se crea un nuevo tensor, con la forma solicitada, apuntando a los mismos datos. TensorFlow usa un orden de memoria de \"fila principal\" de estilo C, donde incrementar el índice de la derecha corresponde a un solo paso en la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a845e09",
   "metadata": {},
   "source": [
    "![tensor before](../Imagenes/tensor_before.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e033ee",
   "metadata": {},
   "source": [
    "Tensor antes de reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058d637",
   "metadata": {},
   "source": [
    "<img src=\"../Imagenes/tensor_after.png\" align=\"left\" width=\"40%\">\n",
    "<img src=\"../Imagenes/tensor_after2.png\" align=\"right\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecdd5d",
   "metadata": {},
   "source": [
    "Tensores despues de reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684d11e",
   "metadata": {},
   "source": [
    "### Aplana un tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7192cfba",
   "metadata": {},
   "source": [
    "Esta operación permite ver el orden como están organizados los datos en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d9e7df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t actual: \n",
      " [[[ 1  2  3  4  5]\n",
      "  [ 6  7  8  9 10]\n",
      "  [11 12 13 14 15]]\n",
      "\n",
      " [[16 17 18 19 20]\n",
      "  [21 22 23 24 25]\n",
      "  [26 27 28 29 30]]]\n",
      "\n",
      " t aplanado: \n",
      " [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n"
     ]
    }
   ],
   "source": [
    "print(\"t actual: \\n\", t.numpy())\n",
    "flat = tf.reshape(t, [-1])\n",
    "print(\"\\n t aplanado: \\n\", flat.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f4904",
   "metadata": {},
   "source": [
    "Normalmente, el único uso razonable de tf.reshape es combinar o dividir ejes adyacentes (o agregar / eliminar 1 s).\n",
    "\n",
    "Para este tensor de 2x3x5, remodelar a (2x3)x5 o 2x (3x5) son dos cosas razonables, ya que los cortes no se mezclan:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "768a5395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "print(t.shape.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fa4a0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]\n",
      " [11 12 13 14 15]\n",
      " [16 17 18 19 20]\n",
      " [21 22 23 24 25]\n",
      " [26 27 28 29 30]], shape=(6, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(t, [2*3,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67298ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      " [16 17 18 19 20 21 22 23 24 25 26 27 28 29 30]], shape=(2, 15), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(t, [2,3*5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e07a5",
   "metadata": {},
   "source": [
    "No es necesario definir todos tamaños en todas las dimensiones. veámos como rehacer los dos ejemplos ateriores, respecitivamente. El -1 le dice a tf que decida cuál es la dimensión correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1324a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]], shape=(6, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(t, [-1,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fde967f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(t, [3,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c2311",
   "metadata": {},
   "source": [
    "Aunque es posible hacer el siguiente reshape no tiene sentido, porque se pierde la integridad de la información. \n",
    "\n",
    "Asegúrese que enti3nde la razón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c4c570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1  2  3  4  5]\n",
      "  [ 6  7  8  9 10]]\n",
      "\n",
      " [[11 12 13 14 15]\n",
      "  [16 17 18 19 20]]\n",
      "\n",
      " [[21 22 23 24 25]\n",
      "  [26 27 28 29 30]]], shape=(3, 2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(t, [3,2,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73480c40",
   "metadata": {},
   "source": [
    "### Definición Conversión de tipos. Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e43fb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 4. 6.], shape=(3,), dtype=float64)\n",
      "tf.Tensor([2. 4. 6.], shape=(3,), dtype=float16)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "f64_tensor = tf.constant([2.0, 4.0, 6.0], dtype = tf.float64)\n",
    "print(f64_tensor)\n",
    "\n",
    "f16_tensor = tf.cast(f64_tensor,dtype= tf.float16)\n",
    "print(f16_tensor)\n",
    "\n",
    "u8_tensor = tf.cast(f16_tensor, dtype = tf.uint8)\n",
    "print(u8_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66a240",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Radiofusión (broadcasting)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5bbe8",
   "metadata": {},
   "source": [
    "La radiodifusión es un concepto tomado de la función equivalente en NumPy . En resumen, bajo ciertas condiciones, los tensores más pequeños se \"estiran\" automáticamente para adaptarse a tensores más grandes cuando se ejecutan operaciones combinadas en ellos.\n",
    "\n",
    "El caso más simple y común es cuando intenta multiplicar o agregar un tensor a un escalar. En ese caso, el escalar se transmite para que tenga la misma forma que el otro argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da3177cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 2 ,3])\n",
    "y = tf.constant(2)\n",
    "z = tf.constant([2, 2 ,2])\n",
    "\n",
    "# el mismo resultado\n",
    "print(tf.multiply(x,2))\n",
    "print(x*y)\n",
    "print(x*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b4b9f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32) \n",
      "\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.reshape(x, [3,1])\n",
    "y = tf.range(1,5)\n",
    "print(x, \"\\n\")\n",
    "print(y, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e3c78b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.multiply(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28dbb4",
   "metadata": {},
   "source": [
    "Del mismo modo, los ejes con longitud 1 se pueden estirar para que coincidan con los otros argumentos. Ambos argumentos se pueden estirar en el mismo cálculo.\n",
    "\n",
    "En este caso, una matriz de 3x1 se multiplica por elementos por una matriz de 1x4 para producir una matriz de 3x4. Observe que el 1 inicial es opcional: la forma de y es [4]. En matemáticas esta multiplicación se conoce como producto externo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19682d19",
   "metadata": {},
   "source": [
    "### tf.broadcast_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "054e989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.broadcast_to([1,2,3], [3,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dbb65b",
   "metadata": {},
   "source": [
    "### tf.convert_to_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b26b9",
   "metadata": {},
   "source": [
    "La mayoría de las operaciones, como *tf.matmul* y *tf.reshape* toman argumentos de la clase *tf.Tensor*. Sin embargo, notará que en el caso anterior, se aceptan objetos de Python con forma de tensores.\n",
    "\n",
    "La mayoría, pero no todas, las operaciones llaman a *tf.convert_to_tensor* con argumentos no tensoriales. Existe un registro de conversiones, y la mayoría de las clases de objetos como *ndarray* , *TensorShape* , de Python, y *tf.Variable* se convertirán todas automáticamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f5bb41",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Tensores irregulares (ragged tensors) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f14ad",
   "metadata": {},
   "source": [
    "Un tensor con números variables de elementos a lo largo de algún eje se llama \"irregular\". Utilice tf.ragged.RaggedTensor para datos irregulares.\n",
    "\n",
    "Por ejemplo, esto no se puede representar como un tensor regular:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e06755",
   "metadata": {},
   "source": [
    "![ragged](../Imagenes/ragged.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eef7c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9efbf77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tensor = tf.constant(ragged_list)\n",
    "except Exception as e:\n",
    "     print(f\"{type(e).__name__}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317100b",
   "metadata": {},
   "source": [
    "En su lugar, cree un *tf.RaggedTensor* usando *tf.ragged.constant* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d32bec9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, None)\n"
     ]
    }
   ],
   "source": [
    "ragged_t = tf.ragged.constant(ragged_list)\n",
    "\n",
    "print(ragged_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ab6b6",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Tensores de strings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "416fac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Este tensor string', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "st = tf.constant(\"Este tensor string\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e33b25e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Este tensor string' b'Cadena 2' b'Cadena 3' b'\\xf0\\x9f\\xa5\\xb3'], shape=(4,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "st = tf.constant([\"Este tensor string\",\n",
    "                 \"Cadena 2\",\n",
    "                 \"Cadena 3\",\n",
    "                 \"🥳\"])\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "El prefijo b indica que el tipo (dtype)  tf.string no es unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9538e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[b'Este', b'tensor', b'string'], [b'Cadena', b'2'], [b'Cadena', b'3'], [b'\\xf0\\x9f\\xa5\\xb3']]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.split(st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a537671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Este' b'tensor' b'string'], shape=(3,), dtype=string)\n",
      "tf.Tensor([b'Cadena' b'2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'Cadena' b'3'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'\\xf0\\x9f\\xa5\\xb3'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "st_split = tf.strings.split(st)\n",
    "for i in st_split:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94751f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### string to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c9aa051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 1.  10.  10.4], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "st = tf.constant(\"1 10 10.4\")\n",
    "\n",
    "print(tf.strings.to_number(tf.strings.split(st, \" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9623f66",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Tensores dispersos.  SparseTensor</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c168107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
      "\n",
      "tf.Tensor(\n",
      "[[0 1 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#  tensor disperso\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices = [[0,1], [1,2]],\n",
    "                                       values = [1,2],\n",
    "                                       dense_shape\n",
    "                                        =[3,4])\n",
    "print(sparse_tensor, \"\\n\")\n",
    "\n",
    "# convierte a tensor denso\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf85da4",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">zip</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5e509e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.data.Dataset.range(1,4) # ==> [1, 2, 3]\n",
    "b = tf.data.Dataset.range(4,7) # ==> [4, 5, 6]\n",
    "\n",
    "ds = tf.data.Dataset.zip((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67408f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "723ba095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=2>, <tf.Tensor: shape=(), dtype=int64, numpy=5>)\n",
      "(<tf.Tensor: shape=(), dtype=int64, numpy=3>, <tf.Tensor: shape=(), dtype=int64, numpy=6>)\n"
     ]
    }
   ],
   "source": [
    "for i in ds:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27d6a744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (3, 6)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3dc227ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.data.Dataset.range(7,11) # ==> [7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0dfc307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 4, 1), (8, 5, 2), (9, 6, 3)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = tf.data.Dataset.zip((c,b,a))\n",
    "list(ds1.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c15100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
