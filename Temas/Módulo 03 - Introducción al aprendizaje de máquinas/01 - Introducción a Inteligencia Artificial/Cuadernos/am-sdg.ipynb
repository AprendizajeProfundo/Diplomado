{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Gradiente Descendiente Estocástico</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Métodos basados en el gradiente](#Métodos-basados-en-el-gradiente)\n",
    "* [Gradiente descendiente en lote](#Gradiente-descendiente-en-lote)\n",
    "* [Gradiente descendiente estocástico](#Gradiente-descendiente-estocástico)\n",
    "* [Gradiente descendiente por mini-lotes](#Gradiente-descendiente-por-mini-lotes)\n",
    "* [Método del momento](#Método-del-momento)\n",
    "* [RMSprop](#RMSprop)\n",
    "* [Algoritmo Adam](#Algoritmo-Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de los algoritmos de aprendizaje profundo implican optimización de algún tipo. La optimización se refiere a la tarea de minimizar o maximizar alguna función $ f (x) $ alterando $ x $. Por lo general, expresamos la mayoría de los problemas de optimización en términos de minimizar $ f (x) $.\n",
    "\n",
    "\n",
    "**Enteremos como la frase  minimizar una función $ f (x) $ como un procedimiento para encontrar valor $x^*$ de tal manera que $ f (x^*) $ tenga el menor valor posible**\n",
    "\n",
    "Los matemáticos escribe esta frase en símbolos de la siguiente manera.\n",
    "\n",
    "$$\n",
    "x^* = \\underset{x}{\\operatorname{argmin}}  f(x).\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "La función que queremos minimizar  se llama función o criterio **objetivo (objetivo)**. \n",
    "\n",
    "Cuando estamos minimizando, también podemos llamarla función de costo, **función de pérdida** o función de error.\n",
    "\n",
    "\n",
    "La búsqueda de un mínimo global puede ser una tarea muy dura en aprendizaje de máquinas si se tiene en cuenta que se tienen muchas dimensiones y no podemos *ver*. En la siguiente imagen la función tiene dos variables (features). En aprendizaje de máquinas se pueden tener cientos  miles y hasta más features.\n",
    "\n",
    "\n",
    "\n",
    "La imagen muestra una función con varios máximos y varios mínimos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Función con múltiple minimos](../Imagenes/multiple_minimum.png)\n",
    "\n",
    "[Fuente](https://www.r-bloggers.com/2014/09/multivariable-gradient-descent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Métodos de optimización basados en el gradiente</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección vamos concentrarnos en las técnicas más modernas de optimización desarrolladas para el hacer posible el aprendizaje de máquinas. En este contexto se tiene que \n",
    "\n",
    "**<center>El problema de entrenar una máquina es un problema de optimización</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menudo minimizamos las funciones que tienen múltiples entradas: $ f: \\mathbb{R}^n \\to \\mathbb {R} $. \n",
    "\n",
    "Para que el concepto de \"minimización\" para tener sentido, debe haber una sola salida (función escalar).\n",
    "\n",
    "\n",
    "Para funciones con múltiples entradas, se hace uso del concepto de derivadas parciales. La derivada parcial $\\frac{\\partial}{\\partial x_i} f(x)$  mide como cambia $f$  cuando la\n",
    "variable $x_i$ crece o decrece desde el punto  $x$. \n",
    "\n",
    "\n",
    "El gradiente generaliza la noción de derivada al caso en que la derivada es con respecto a un vector: el gradiente de $ f $ es el vector que contiene todas las derivadas parciales, denotado $ \\nabla_xf (x) $. El elemento $ i $ del gradiente es la derivada parcial de f con respecto a $ x_i $.\n",
    "\n",
    "\n",
    "\n",
    "En múltiples dimensiones, los puntos críticos son puntos donde cada elemento del gradiente es igual a cero.\n",
    "\n",
    "\n",
    "Por otro lado, se puede verificar que el gradiente $ \\nabla_xf (x) $  es el vector geométrico que con base en el punto $X$ apunta en la direección en la cual crece más rápidamente la función. En consecuencia, $ -\\nabla_xf (x) $ apunta en la dirección contraria, es decir en la dirección hacia la cual la función decrece más rápido, desde el punto $x$. Esta es la base de los métodos de optimización basados en el gradiente. \n",
    "\n",
    "La siguiente gráfica ilustra el gradiente proyactado en el plano $xy$ de la función $f(x,y)= -(\\cos x^2 + \\sin x^2)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../Imagenes/512px-3d-gradient-cos.svg.png)\n",
    "\n",
    "Gradientes de la función $f(x,y)= -(\\cos x^2 + \\sin x^2)^2$ proyectados en el plano $xy$\n",
    "\n",
    "[Fuente](https://commons.wikimedia.org/wiki/File:3d-gradient-cos.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El término **gradiente descediente** indica que se usará $ -\\nabla_xf (x) $ para moverse a un siguiente punto en busca de un minimo local.\n",
    "\n",
    "El método general se escribe como:\n",
    "\n",
    "$$\n",
    "x^{(k+1)} = x^{(k)} − \\eta_{k} \\nabla_x f(x^{(k)})\n",
    "$$\n",
    "\n",
    "\n",
    "Los  valores  $\\eta_k$ se denominan genéricamente  **tasa de aprendizaje**.\n",
    "\n",
    "\n",
    "La razón de incorporar la tasa de aprendizaje es controlar el tamaño de paso. Si no hace esta corrección podemos alejarnos en lugar de acercarnos al mínimo que se está buscando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradiente descendiente](../Imagenes/350px-Gradient_descent.svg.png)\n",
    "\n",
    "Ilustración usando curvas de nivel de como ocurren las iteraciones en el método del gradiente descendiente.\n",
    "\n",
    "[Fuente](https://en.wikipedia.org/wiki/Gradient_descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Gradiente descendiente en lote</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En el descenso de gradiente  descendiente vainilla (vainilla se refiere al ejemplo básico), también conocido como descenso de gradiente por lotes, calcula el gradiente de la función de pérdida con respecto a los parámetros $\\boldsymbol{\\theta}$ para el **conjunto de datos de entrenamiento completo** $(\\mathbf{x}_{train},\\mathbf{y}_{train})$. Si $\\mathfrak{L}$ es la función de pérdida del problema, entonces se tiene que \n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta}_{k+1} =  \\boldsymbol{\\theta}_k - \\eta_k \\nabla_{\\boldsymbol{\\theta}} \\mathfrak{L}(\\mathbf{x}_{train},\\mathbf{y}_{train},\\boldsymbol{\\theta}_k),\n",
    "$$\n",
    "\n",
    "\n",
    "El principal problema a resolver con los métodos de gradiente descendiente es cómo definir y actualizar en cada paso la tasa de aprendizaje $\\eta_k $.\n",
    "\n",
    "Un fragmento de código puede lucir como sigue. Supongamos que al comenzar $0<\\eta_0<1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(theta, x_train, y_train, loss_func, epochs):\n",
    "    for i in range (epochs):\n",
    "        gradient = evaluate_gradient(loss_func, x_train, y_train, theta)\n",
    "        theta -=  eta * gradient\n",
    "        eta   *= eta\n",
    "    return theta, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Gradiente descendiente estocástico</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El descenso de gradiente estocástico (SGD), por el contrario, realiza una actualización de parámetros para cada ejemplo de entrenamiento $x_{train}^{(i)} $ y etiqueta $ y_{train}^ {(i)} $, **seleccionados al azar en cada época**.\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta}_{k+1} =  \\boldsymbol{\\theta}_k - \\eta_k \\nabla_{\\boldsymbol{\\theta}} \\mathfrak{L}({x}_{train}^{(i)},{y}_{train}^{(i)},\\boldsymbol{\\theta}_k),\n",
    "$$\n",
    "\n",
    "\n",
    "En el artículo original de [Robbins and Monro (1951)](https://projecteuclid.org/download/pdf_1/euclid.aoms/1177729586) $\\eta$ cambia en cada iteración como acabamos de mostrar y se asume que  $\\{\\eta_k\\}$ es una sucesión tal que $\\sum_k \\eta_k = \\infty$, and $\\sum_k \\eta_k^2 < \\infty$. Por ejemplo $\\eta_k = 1/k$. Robbins y Monro demostraron que bajo condiciones muy generales este algoritmo converge a la solución de problema, con probabilidad 1. \n",
    "\n",
    "Un fragmento de código del algoritmo de Robbins and Monro podría lucir como sigue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(theta, data_train, loss_func, epochs):\n",
    "    for i in range (epochs):\n",
    "        np.random.shuffle (data)\n",
    "        for example in data:\n",
    "            x, y = example\n",
    "            gradient = evaluate_gradient(loss_func,x, y, theta )\n",
    "            theta = theta - eta * gradient\n",
    "            eta *= eta\n",
    "    return theta, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Gradiente descendiente estocástico por mini-lotes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El descenso de gradiente por mini-lotes finalmente toma lo mejor de los dos mundos anteriores y realiza una actualización para cada mini-lote de $n$ ejemplos de entrenamiento:\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta}_{k+1} =  \\boldsymbol{\\theta}_k - \\eta_k \\nabla_{\\boldsymbol{\\theta}} \\mathfrak{L}(\\mathbf{x}_{train}^{(i:i+n)},\\mathbf{y}_{train}^{(i:i+n)},\\boldsymbol{\\theta}_k),\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Desde este punto de la lección, asumiremos que **tomamos mini-lotes**, por lo que omitimos super-índices en los datos $(\\mathbf{x}_{train}^{(i:i+n)},\\mathbf{y}_{train}^{(i:i+n)})$ en todas las expresiones.\n",
    "\n",
    "un fragmento de código para este método podria lucir como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_mini_batch(theta, data_train, loss_func, epochs, batch_size):\n",
    "    for i in range (epochs):\n",
    "        np.random.shuffle (data_train)\n",
    "        for batch in get_batches(data_train , batch_size = batch_size):\n",
    "            x, y = batch\n",
    "            gradient = evaluate_gradient(loss_func,x, y, theta )\n",
    "            theta -=  eta * gradient\n",
    "            eta *= eta\n",
    "    return theta, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de los mini-lotes depende del problema y puede ser 32, 64, 128, etc. En el ejemplo, la función *get batches()* es un función generadora que va entregando lotes de datos a la medida que el algortimo los requiere. Para las TPU se esperan mini-lotes de tamaño que sea múltiplo de 128. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método vainilla del descenso de gradiente  no garantiza una buena convergencia, y ofrece algunos desafíos que deben abordarse:\n",
    "\n",
    "1. Elegir un ritmo de aprendizaje adecuado puede resultar complicado. Una tasa de aprendizaje demasiado pequeña conduce a una convergencia dolorosamente lenta, mientras que una tasa de aprendizaje demasiado grande puede dificultar la convergencia y hacer que la función de pérdida fluctúe alrededor del mínimo o incluso diverja.\n",
    "2. Los horarios de actualización de la tasa de aprendizaje intentan ajustar la tasa de aprendizaje durante la entrenamiento, es decir, reducir la tasa de aprendizaje de acuerdo con un programa predefinido o cuando el cambio función de pérdida entre epochs cae por debajo de un umbral. Sin embargo, estos horarios y umbrales deben definirse con anticipación y, por lo tanto, no pueden adaptarse a las características de un conjunto de datos.\n",
    "3. Además, la misma tasa de aprendizaje se aplica a todas las actualizaciones de parámetros. Si nuestros datos son escasos y nuestras características tienen frecuencias muy diferentes, es posible que no queramos actualizarlas todas en la misma medida, sino realizar una actualización más grande para las características que ocurren con poca frecuencia.\n",
    "4. Otro desafío clave al minimizar las funciones de error altamente no convexas comunes para las redes neuronales es evitar quedar atrapado en sus numerosos mínimos locales subóptimos. Algunos autores argumentan que, de hecho, la dificultad no surge de los mínimos locales sino de los puntos de silla, es decir, puntos donde una dimensión se inclina hacia arriba y otra hacia abajo. Estos puntos de silla suelen estar rodeados por una meseta del mismo error, lo que dificulta notablemente el escape de SGD, ya que el gradiente es cercano a cero en todas las dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ejemplo de punto de silla](../Imagenes/585px-Gradient_ascent_(surface).png)\n",
    "\n",
    "Ejemplo de un punto de silla.\n",
    "\n",
    "[Fuente](https://en.wikipedia.org/wiki/Gradient_descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una revisión contemporáneas de los algoritmos de optimización modernos puede consultar [An overview of gradient descent optimization\n",
    "algorithms](https://arxiv.org/pdf/1609.04747.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Método del momento</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "SGD tiene problemas para navegar por los barrancos, es decir, áreas donde la superficie se curva mucho más abruptamente en una dimensión que en otra, que son comunes en los óptimos locales. En estos escenarios, SGD oscila a lo largo de las pendientes del barranco mientras solo avanza vacilante por el fondo hacia el óptimo local.\n",
    "\n",
    " Este es un método que ayuda a acelerar SGD en la dirección relevante y amortigua oscilaciones. Lo hace sumando una fracción $\\lambda$ del vector de actualización del paso anterior al vector de actualización actual. \n",
    " \n",
    "El método  se esquematiza como sigue\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{v}_k &= \\lambda \\mathbf{v}_{k-1} +  \\eta \\nabla_{\\boldsymbol{\\theta}} \\mathfrak{L}({x}_{train}^{(i)},{y}_{train}^{(i)},\\boldsymbol{\\theta}_k)\\\\\n",
    "\\theta_{k+1} &= \\theta_{k} - v_k,\n",
    "\\end{align}\n",
    "$$\n",
    "$\\lambda<1$. Ussually, $\\lambda= 0.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/moment_method.png\" width=\"300\" height=\"200\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">SGD.Momento</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "[Imagen tomada de](https://www.google.com/search?q=momentum+method+gradient+descent&source=lnms&tbm=isch&sa=X&ved=2ahUKEwi22sKXn4DsAhVHk1kKHaYyB2wQ_AUoAXoECA4QAw&biw=1366&bih=540)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">RMSprop</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrollado por Goeff Hinton, no publicado. Se basa en dividir la tasa de aprendizaje en cada caso por un promedio del cuadrado de las componentes del gradiente en el paso anterior. Por cada componente $\\theta$ del vector de parámetros $\\boldsymbol{\\theta}$, sea $g$ la respectiva componente del gradiente asociada a $\\theta$, entonces el métodos es como sigue:\n",
    "\n",
    "1. $E[g^2]_t= \\lambda E[g^2]_{t-1} + (1-\\lambda)g_t^2$\n",
    "2. $\\theta_{t+1} = \\theta_t - \\tfrac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}}g_t$\n",
    "\n",
    "$\\epsilon >0$ es para evitar divisiones por cero. \n",
    "\n",
    "- $\\lambda$ es el parámetro de decaimiento. Típicamente $\\lambda = 0.9$.\n",
    "- $\\eta$ es la tasa de aprendizaje. Típicamente el valor por defecto es 0.001.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Algoritmo Adam</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo [Adam a method for Stochastic optimization](https://arxiv.org/pdf/1412.6980.pdf) de Kingma y Lei es actualmente el método más utilizado. El siguiente es el algoritmo.\n",
    "\n",
    "El símbolo  $g^2_t$ indica los elementos del producto de Hadamard (componente por componente)  $g_t\\bigodot g_t$. Según los autores, los mejores resultados han sido obtenidos para los valores de los hiperparámetros  $\\alpha = 0.001$, $\\beta_1 = 0.9$, $\\beta_2 = 0.999$ y $\\epsilon = 10−8$. Todas operaciones entre vectores son hechas componente por componente (producto de Hadamard). con $\\beta_1^t$ and $\\beta_2^t$ se denota la potencia $t$-ésima.\n",
    "1. Requerido: $\\alpha$: Valor de salto (Stepsize)\n",
    "2. Requerido: $\\beta_1^t$ y $\\beta_2^t \\in [0, 1)$. Ratas de decaimiento exponencial para la estimación de losd momentos.\n",
    "3. Requerido: $f(\\theta)$: Función de pérdida objetivo con parámetros $\\theta$\n",
    "4. Requerido: $\\theta_0$: Vector de valores iniciales del vector de parámetros\n",
    "5.  $m_0  = 0$ (Inicialización del vector momento de primer orden)\n",
    "6. $v_0 =  0$ (Inicialización del vector momento de segundo orden)\n",
    "7. $t =  0$ (Inicialización del contador de iteraciones)\n",
    "8. while $(||\\theta_t - \\theta_{t-1}||>\\delta$) (Mientras no haya covergencia repita los siguientes pasos:)\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "t  &= t + 1 \\\\\n",
    "g_t &=  \\nabla f_t(\\theta_{t-1}) \\text{ (Obtenga los gradientes de la función de pérdida en el paso t con respeto a los parámetros)}\\\\\n",
    "m_t  &= \\beta_1 m_{t−1} + (1 − \\beta_1) · g_t \\text{ (Actualice la estimación del vector de  momentos de primer orden)}\\\\\n",
    "v_t  &= \\beta_2 v_{t−1} + (1 − \\beta_2) · g_t^2 \\text{ (Actualice la estimación del vector de  momentos de segundo orden)}\\\\\n",
    "\\hat{m}_t  &= \\frac{m_t}{1 − \\beta_1^t}   \\text{ (Calcule la corrección de sesgo de la estimación del vector de momentos de primer orden)}\\\\ \n",
    "\\hat{v}_t  &=  \\frac{v_t}{1 − \\beta_2^t}  \\text{ (Calcule la corrección de sesgo de la estimación del vector de momentos de segundo orden)}\\\\ \n",
    "\\theta_t &=   \\theta_{t-1}  - \\alpha  \\frac{\\hat{m}_t}{\\hat{v}_t + epsilon} \\text{ (Actualice los parámetros)}\\\\\n",
    "\\end{align}\n",
    "$\n",
    " \n",
    "end while\n",
    "\n",
    "return $\\theta_t$ (Resulting parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparacion](../Imagenes/Adam_MsProp.png)\n",
    "\n",
    "Comparación de los diferentes métodos de gradiente descendiente estocástico\n",
    "\n",
    "[Fuente](https://ai.plainenglish.io/comparative-performance-of-deep-learning-optimization-algorithms-using-numpy-e9f63b908c7f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al inicio](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
