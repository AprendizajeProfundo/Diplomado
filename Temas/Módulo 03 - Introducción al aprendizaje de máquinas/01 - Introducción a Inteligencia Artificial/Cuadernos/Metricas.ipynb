{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85df66ef",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:#4361EE\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bf0ff",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b851f7-c675-4a2a-8932-59bf23db8edb",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"><center>Métricas en el aprendizaje de máquinas</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01a6ff",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/metricas_ini.jpg\" width=600 height= 400 align=\"center\" />      \n",
    "</center>\n",
    "</figure>\n",
    "<center><a href=\"https://commons.wikimedia.org/wiki/File:Menschliche_Hand_umgrenzt_menschliche_Silhouette_20200911_DSC3711.jpg\">PantheraLeo1359531</a>, <a href=\"https://creativecommons.org/licenses/by/4.0\">CC BY 4.0</a>, via Wikimedia Commons</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955eceb8",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77adc208",
   "metadata": {},
   "source": [
    "1. Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "1. Camilo José Torres Jiménez, Msc, cjtorresj@unal.edu.co\n",
    "1. Daniel  Montenegro, Msc, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d65916",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Asesora Medios y Marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55236b",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com\n",
    "5. Jessica López Mejía, jelopezme@unal.edu.co\n",
    "6. Venus Puertas, vpuertasg@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f18fed",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Jefe Jurídica</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79eabb2",
   "metadata": {},
   "source": [
    "7. Paula Andrea Guzmán, guzmancruz.paula@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e0862",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Coordinador Jurídico</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7039be2",
   "metadata": {},
   "source": [
    "8. David Fuentes, fuentesd065@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839467b4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Desarrolladores Principales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5ea68",
   "metadata": {},
   "source": [
    "9. Dairo Moreno, damoralesj@unal.edu.co\n",
    "10. Joan Castro, jocastroc@unal.edu.co\n",
    "11. Bryan Riveros, briveros@unal.edu.co\n",
    "12. Rosmer Vargas, rovargasc@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b07bc",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Expertos en Bases de Datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e8915",
   "metadata": {},
   "source": [
    "13. Giovvani Barrera, udgiovanni@gmail.com\n",
    "14. Camilo Chitivo, cchitivo@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab698e08-33bf-45c2-8b16-306084b6bf78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0386d0e-d3ef-45ca-8548-aa11ce06319c",
   "metadata": {},
   "source": [
    "Evaluar nuestro algoritmo de aprendizaje automático es una parte esencial de cualquier proyecto. Las métricas permite evaluar el desempeño de un modelo de acuerdo a criterios que el diseñador del modelo desea observar.\n",
    "\n",
    "Por ejemplo, el puntaje de precisión `precision_score`, puede arrojar resultados deficientes cuando se evalúa con otras métricas, como `cross_entropy` o cualquier otra métrica similar. \n",
    "\n",
    "La mayoría de las veces usamos la `exactitud` de la clasificación para medir el rendimiento de nuestro modelo, sin embargo, no es suficiente para juzgar verdaderamente nuestro modelo. En esta lección, cubriremos los diferentes tipos de métricas de evaluación disponibles.\n",
    "\n",
    "\n",
    "Las funciones de pérdida pueden ser usada como métricas ne algunos casos. Por ejemplo, es bastante común tener como función de pérdida en un problema el error cuadrático medio (ECM) y como métrica el el error absoluto medio (EAM). En esta lección no revisaremos las funciones de pérdida, pero podemos tener en cuenta de varias de ellas  se puede usar como métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29358e5f-0919-4b2a-bdfc-50b28d03b6d3",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Matriz de confusión </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e670e627-7e0b-40b7-a688-e99074a03f15",
   "metadata": {},
   "source": [
    "</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f89e16-f4c8-4d44-9415-1e37106eb254",
   "metadata": {},
   "source": [
    "La matriz de confusión, como sugiere el nombre, nos da una matriz como resultado y describe el rendimiento completo del modelo.\n",
    "\n",
    "Supongamos que tenemos un problema de clasificación binaria. Tenemos algunas muestras pertenecientes a dos clases: SÍ o NO. Además, tenemos nuestro propio clasificador que predice una clase para una muestra de entrada dada. Al probar nuestro modelo en N muestras, obtenemos el siguiente resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ff311-41a8-48f5-9fd2-353146557263",
   "metadata": {},
   "source": [
    "|                            | Clasificados como Positivos | Clasificados como Negativos |\n",
    "|----------------------------|-----------------------------|-----------------------------|\n",
    "| Etiquetados como Positivos | Verdaderos Positivos        | Falsos Negativos            |\n",
    "| Etiquetados como Negativos | Falsos Positivos            | Verdaderos Negativos        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a270941-090e-407c-9903-ae18c07246be",
   "metadata": {},
   "source": [
    "Fuente [Wiki-commons](https://commons.wikimedia.org/wiki/Main_Page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a6b0e-9aa7-43e1-8f8e-69e86e9945d8",
   "metadata": {},
   "source": [
    "En problemas con varias clases, la matriz de confusión permite tener una idea de primera mano de como está funcionando el modelo. Revise el siguiente ejemplo. La matriz de confusión, como sugiere el nombre, nos da una matriz como resultado y describe el rendimiento completo del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732614f-bc06-4c0a-acb2-a15d29a45e45",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/Wikidata_P407_analysis_matrix.png\" width=600 height= 600 align=\"center\" />      \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478979a-da98-4648-95d2-f4564f5d6d3e",
   "metadata": {},
   "source": [
    "Fuente [Wiki-commons](https://commons.wikimedia.org/wiki/Main_Page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47cdcf-8114-46b1-8d0f-fbab431cc166",
   "metadata": {},
   "source": [
    "Aparentemente el modelo esta confundiendo muchos ejemplo en la clase *en*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd76ca8-0fc7-43f5-b3a9-c8b6f1843620",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Métricas en clasificación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746e49f-db3d-4d45-8b59-f676c2461f16",
   "metadata": {},
   "source": [
    "La mayor parte de las métricas son explicados para el caso binario, pero en general pueden ser aplicadas al caso de $J$ clases.\n",
    "\n",
    "|                            | Clasificados como Positivos | Clasificados como Negativos |\n",
    "|----------------------------|-----------------------------|-----------------------------|\n",
    "| Etiquetados como Positivos | Verdaderos Positivos        | Falsos Negativos            |\n",
    "| Etiquetados como Negativos | Falsos Positivos            | Verdaderos Negativos        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa74791-0ef5-4974-888f-d7d69689e33c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Exactitud:  Accuracy</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad9967-732c-4ebe-ba42-074e47bdf434",
   "metadata": {},
   "source": [
    "La exactitud de la clasificación es lo que generalmente queremos decir cuando usamos el término exactitud. Es la relación entre el número de predicciones correctas y el número total de muestras de entrada. En el caso binario es usual la siguiente nomenclatura.\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{\\text{verdaderos positivos} + \\text{verdaderos negativos} }{\\text{total de la muestra}}\n",
    "$$\n",
    "\n",
    "El mejor valor es 1 y el peor valor es 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d26bfc-324a-46de-b0d2-3e0ad4c22dd2",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Precisión: precision_score</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f50ba-83e1-44dc-b2e9-ddad1dda8d1c",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "Precision = \\frac{\\text{verdaderos positivos}}{\\text{verdaderos positivos}+ \\text{falsos positivos}}\n",
    "$$\n",
    "\n",
    "Esta métrica indica que tan preciso es el número  de positivos detectados por el modelo. Se puede pensar como enfocada en minimizar los falsos positivos.\n",
    "\n",
    "\n",
    "El mejor valor es 1 y el peor valor es 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7f355-8ff6-42a0-961e-fa9d41c3a60e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Recuperación: recall_score</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b0680-d618-413f-98b9-92daad083899",
   "metadata": {},
   "source": [
    "La sensibilidad o recuperación (recall) es intuitivamente la capacidad del clasificador para encontrar todas las muestras positivas. El mejor valor es 1 y el peor valor es 0.\n",
    "\n",
    "$$\n",
    "Recall = \\frac{\\text{verdaderos positivos}  }{\\text{verdaderos positivos}+ \\text{falsos negativos}}\n",
    "$$\n",
    "\n",
    "En algunos problemas con datos altamente desbalanceados como en el problema de detección de fraude en tarjetas de crédito o la detección temprana de cáncer de seno, un valor alto de exactitud, no es realmente lo mejor. En estos problemas, la recuperación, que es la métrica que mide la capacidad del modelo para detectar muestras positivas es la métrica que se privilegia por encima de las demás.  En estos casos es usual el uso de pesos diferenciados de las observaciones. Se puede pensar como enfocada en minimizar los falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827dde42-548d-4ee5-9582-4e65ed455897",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Puntaje F1: F1 score</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00df4e5-7989-443e-8d03-ce32e3e3c2d5",
   "metadata": {},
   "source": [
    "</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a0b2a-2680-47b4-951a-70a2bb5f92ec",
   "metadata": {},
   "source": [
    "La puntuación F1 es la media armónica entre la precisión y la recuperación. El rango para F1 Score es $[0, 1]$. F1 nos dice qué tan preciso es el clasificador (cuántas instancias clasifica correctamente), así como qué tan robusto es (no pierde una cantidad significativa de instancias).\n",
    "\n",
    "Alta precisión pero menor recuperación, le brinda una precisión extrema, pero luego pierde una gran cantidad de instancias que son difíciles de clasificar. Cuanto mayor sea el F1 Score, mejor será el rendimiento de nuestro modelo. Matemáticamente, se puede expresar como:\n",
    "$$\n",
    "F1 = 2 \\times \\frac{1}{\\frac{1}{precision} + \\frac{1}{recall}} \n",
    "$$ \n",
    "\n",
    "El puntaje F1 intenta encontrar el equilibrio entre precision y recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5e21c-2a80-4a0e-8a60-2dd48457ea65",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Métricas disponibles en Keras</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722142a-6ea6-46b7-9bc6-35e5b0d3a3a0",
   "metadata": {},
   "source": [
    "Las siguientes son las métricas disponibles de Keras en el año 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681671e-0977-4c2f-bc08-445b678d96b4",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Métricas de exactitud</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4d197-d849-44fc-8591-c96f23597553",
   "metadata": {},
   "source": [
    "* Accuracy\n",
    "* BinaryAccuracy \n",
    "* CategoricalAccuracy \n",
    "* SparseCategoricalAccuracy \n",
    "* TopKCategoricalAccuracy \n",
    "* SparseTopKCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2dc91-c9fb-4697-a527-7dca5f89d7d4",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Métricas de clasificación basadas en positivos y negativos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7e5bc-58cb-467c-8bd3-e1857b6ee186",
   "metadata": {},
   "source": [
    "* AUC \n",
    "* Precision \n",
    "* Recall \n",
    "* TruePositives \n",
    "* TrueNegatives \n",
    "* FalsePositives \n",
    "* FalseNegatives \n",
    "* PrecisionAtRecall \n",
    "* SensitivityAtSpecificity \n",
    "* SpecificityAtSensitivity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8af8b-35f2-4a93-a236-493518c23cd1",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Métricas probabilisticas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e52c8-6ff2-4481-aebc-69b669acdbeb",
   "metadata": {},
   "source": [
    "* BinaryCrossentropy \n",
    "* CategoricalCrossentropy \n",
    "* SparseCategoricalCrossentropy \n",
    "* KLDivergence \n",
    "* Poisson "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb09ca6-6112-404e-8b30-a8af4e25e2b6",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Métricas de regresión</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84891dca-1ad9-4caa-8433-b77c5966469c",
   "metadata": {},
   "source": [
    "* MeanSquaredError \n",
    "* RootMeanSquaredError \n",
    "* MeanAbsoluteError \n",
    "* MeanAbsolutePercentageError \n",
    "* MeanSquaredLogarithmicError \n",
    "* CosineSimilarity \n",
    "* LogCoshError "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe333fb2-f7f9-4b0d-9e22-776409003371",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Métricas para segmentación de imágenes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a481a-9066-423f-9bd2-707e81616e27",
   "metadata": {},
   "source": [
    "* MeanIoU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05d8a2-40c6-4772-bf7f-4340e0736725",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Métricas para clasificación para máximo margen (hinge)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d5fc9-9b1d-4efc-8e82-43da3be3c776",
   "metadata": {},
   "source": [
    "* Hinge metrics for \"maximum-margin\" ification\n",
    "* Hinge \n",
    "* SquaredHinge \n",
    "* CategoricalHinge "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e50c9d-750b-4108-9577-74041bffd851",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Forma de uso en Keras</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962c98b-b4ff-4e13-819e-9b845a7ca4b3",
   "metadata": {},
   "source": [
    "En el momento de compilar el modelo las métricas para el modelo se definen en una lista, como se observa en el siguiente fragmento de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3162386-d71f-4df6-9ee8-cb0e75dc0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[\n",
    "        metrics.MeanSquaredError(),\n",
    "        metrics.AUC(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671af421-2fba-4f1a-a26d-8655a4f11961",
   "metadata": {},
   "source": [
    "En general las métricas van acumulado resultados a lo largo de cada época. En necesario reiniciarlas al comienza de la época y totalizarlas al final. Sin embargo todo lo hace Keras debajo del capó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c63ae-bc90-4d35-b14b-f4066c336945",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Métricas disponibles en Pytorch</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a23fe1-7f3a-49df-971a-24ef070adde5",
   "metadata": {},
   "source": [
    "En Pytorch es necesario instalar el módulo TorchMetrics como sigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dce3bc-66ec-420b-8a62-c81c8df64b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9f579-a3b3-4125-bba8-338e52aeb3f4",
   "metadata": {},
   "source": [
    "Este módulo ha sido desarrollado principalmente por [Pytorch-Lightning](https://www.pytorchlightning.ai/). El módulo incluye más de 80 métricas para cada uno se las siguientes áreas:\n",
    "\n",
    "* Audio\n",
    "* Clasificación general\n",
    "* Clasificación de imágenes.\n",
    "* Detección de objetos\n",
    "* Emparejamiento (pairwise)\n",
    "* Regresión\n",
    "* Recuperación\n",
    "* Textual\n",
    "* Agregación\n",
    "\n",
    "\n",
    "Para los detalles visite  [torchmetrics](https://torchmetrics.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220a4fc-d478-44ce-8834-a389fcd79630",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Forma de uso en Pytorch</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84badb6e-b848-4b70-a7ce-880d04a9f56d",
   "metadata": {},
   "source": [
    "`TorchMetrics` puede usarse directamente en Python como se ilustra en el siguiente fragmento de código. Vaya  la lección de Pytorch-lightning, para verficar como usarlas alli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153e734-a37a-4138-9935-7e0709b38792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import Accuracy\n",
    "\n",
    "train_accuracy = Accuracy()\n",
    "valid_accuracy = Accuracy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x, y in train_data:\n",
    "        y_hat = model(x)\n",
    "\n",
    "        # training step accuracy\n",
    "        batch_acc = train_accuracy(y_hat, y)\n",
    "        print(f\"Accuracy of batch{i} is {batch_acc}\")\n",
    "\n",
    "    for x, y in valid_data:\n",
    "        y_hat = model(x)\n",
    "        valid_accuracy.update(y_hat, y)\n",
    "\n",
    "    # total accuracy over all training batches\n",
    "    total_train_accuracy = train_accuracy.compute()\n",
    "\n",
    "    # total accuracy over all validation batches\n",
    "    total_valid_accuracy = valid_accuracy.compute()\n",
    "\n",
    "    print(f\"Training acc for epoch {epoch}: {total_train_accuracy}\")\n",
    "    print(f\"Validation acc for epoch {epoch}: {total_valid_accuracy}\")\n",
    "\n",
    "    # Reset metric states after each epoch\n",
    "    train_accuracy.reset()\n",
    "    valid_accuracy.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c9ffa",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"right\"/> \n",
    "</figure>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
