{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure> \n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Redes GRU (Gated Recurrent Unit)</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "1. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "1. Campo Elías Pardo Turriago, cepardot@unal.edu.co \n",
    "1. Oleg Jarma, ojarmam@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introducción a Redes LSTM](Intro_LSTM.ipynb)\n",
    "1. [Time Series Forecasting with LSTMs using TensorFlow 2 and Keras in Python](https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651/)\n",
    "1. [Dive into Deep Learnig](https://d2l.ai/)\n",
    "1. [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "1. [Ralf C. Staudemeyer and Eric Rothstein Morris, *Understanding LSTM a tutorial into Long Short-Term Memory Recurrent Neural Networks*, , arxiv, September 2019](https://arxiv.org/pdf/1909.09586.pdf)\n",
    "1. [Karpathy, *The Unreasonable Effectiveness of Recurrent Neural Networks*](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "1.  [Cho et al. 2014, On the Properties of Neural Machine Translation: Encoder–Decoder\n",
    "Approaches](https://arxiv.org/pdf/1409.1259.pdf)\n",
    "1. [J. Chung, C. Gulcehre, K. Cho, Y. Bengio, Empirical Evaluation of Gated Recurrent Neural Networks on Sequence  Modeling](https://arxiv.org/pdf/1412.3555v1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Funcionamiento de una red GRU](#Funcionamiento-de-una-red-GRU)\n",
    "* [Puerta de actualización-update](#Puerta-de-actualización-update)\n",
    "* [Puerta reinicio](#Puerta-reinicio)\n",
    "* [Activación candidata](#Activación-candidata)\n",
    "* [Actualización del estado recurrente](#Actualización-del-estado-recurrente)\n",
    "* [Resumen de la matemática en la red GRU](#Resumen-de-la-matemática-en-la-red-GRU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Una red neuronal recurrente (RNR) es una extensión de una red neuronal convencional,\n",
    "que es capaz de manejar una entrada de secuencia de longitud variable. La RNR maneja la longitud variable de las secuencias mediante un estado oculto recurrente cuya activación en cada momento depende del estado anterior. \n",
    "\n",
    "Más formalmente, dada una secuencia $\\mathbf{x}= (x_1, x_2, \\ldots, x_T)$, la RNR actualiza su estado oculto recurrente $h_t$ mediante \n",
    "\n",
    "\n",
    "$$\n",
    "h_t = \\begin{cases}\n",
    "0,  &\\text{ si } t=0,\\\\\n",
    "\\phi(h_{t-1},x_t), &\\text{en otro caso}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Si $g$ es una función de activación  suave, como un sigmoide o una tangente hiperbólica, es común definir\n",
    "\n",
    "$$\n",
    "h_t = g(Wh_{t-1} + Ux_t+ b)\n",
    "$$\n",
    "\n",
    "En el tratamiento del lenguaje natural una RNR generativa calcula en cada paso una distribución de probabilidad para el siguiente elemento de la secuencia, dado su estado actual $h_t$, y este modelo generativo puede capturar una distribución sobre secuencias de longitud variable mediante el uso de un símbolo de salida especial para representar el final de la secuencia. La probabilidad se puede descomponer en\n",
    "\n",
    "$$\n",
    "p (x_1,\\ldots, x_T) = p (x_1) p (x_2 | x_1) p (x_3 | x_1, x_2) \\ldots p (x_T | x_1,\\ldots, x_{T − 1}), \n",
    "$$\n",
    "\n",
    "en donde el último elemento es un valor especial de final de secuencia. En la ecuación anterior cada probabilidad condicional es aproximada mediante\n",
    "\n",
    "$$\n",
    "p (x_t | x_1,\\ldots, x_{t − 1}) = g (h_t)\n",
    "$$\n",
    "\n",
    "El problema con este modelo, es que el cálculo del gradiente tiende a volverse cero o a explotar. \n",
    "\n",
    "Dos líneas de trabajo fueron impulsadas por esta situación. Por un lado se inició la búsqueda de nuevas técnicas para el cálculo del gradiente en el proceso de optimización de la función de pérdida, y por el otro, el desarrollo de nuevos modelos de redes neuronales. \n",
    "\n",
    "\n",
    "La primera línea ha producido nuevas técnicas de optimización estocástica basados en el gradiente, que han sido usadas exitosamente en redes generales. \n",
    "\n",
    "La segunda línea llevó al desarrollo de las redes [LSTM](Intro_LSTM.ipynb), en las cuales la función de activación consiste en una transformación afinada seguida por una simple no linealidad de elementos mediante el uso de unidades de compuerta, [Hochreiter y Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf). \n",
    "\n",
    "\n",
    "Más recientemente, otro tipo de unidad recurrente, a la que nos referimos como una unidad recurrente cerrada (GRU), fue propuesta por [Cho et al. 2014](https://arxiv.org/pdf/1409.1259.pdf). Puede consultar una comparación entre LSTM y GRU en [Junyoung Chung et al., 2014](https://arxiv.org/pdf/1412.3555v1.pdf). De estas unidades recurrentes se ha demostrado que funcionan bien en tareas que requieren captura de dependencias a largo plazo.  Esas tareas incluyen, pero no se limitan a reconocimiento de voz, música,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Funcionamiento de una red GRU</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red de unidad recurrente cerrada (GRU) permite que cada unidad recurrente capture de forma adaptativa dependencias de diferentes escalas de tiempo. De manera similar a la unidad LSTM, la GRU tiene compuertas que modulan el flujo de información dentro de la unidad.  Sin embargo, a diferencia de las redes LSTM no tiene celdas de memoria separadas. Las dos  imágenes muestran la estructura general de las compuertas GRU.\n",
    "\n",
    "![Gru-1](../Imagenes/gru-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos diagramas muestran la estructura matemática dentro de la compuerta en el tiempo $t$, con reinicio antes o después de de la multiplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/compuerta_GRU_after_false.jpg\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Imagen: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ reset_after: convención GRU (si aplicar la puerta de reinicio  antes o después de la multiplicación de matrices). False = \"antes\", True = \"después\" (este es el caso por defecto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/compuerta_GRU_after_true.jpg\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Imagen: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La notación que usamos es bastante estándar. \n",
    "\n",
    "1. $+$ : indica suma de vectores\n",
    "1. $\\sigma$ : representa a la función de activación sigmoide\n",
    "1. $\\tanh$ : representa a la función de activación tangente hiperbólica.\n",
    "1. $\\ast$ : es producto componente a componente (producto de Hamard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una GRU tien dos tipos de puerta: actualización (update) y reinicio (reset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Puerta de actualización-update</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Comenzamos calculando la salida de la compuerta de actualización. Supogamos que $z_t$ es la salida de la compuerta en el tiempo $t$, entonces tenemos que\n",
    "\n",
    "$$\n",
    "z_t = \\sigma(W_z x_t + U_zh_{t-1} + b_z)\n",
    "$$\n",
    "\n",
    "en donde $W_z$ y $U_z$ son los pesos asociados a la nueva entrada $x_t$  y al estado oculto $h_{t-1}$  respectivamente y en donde $b_z$ es el respectivo vector de sesgo. En realidad esta formula es equivalente a la que utlizamos en la lección de LSTM, en donde concatenamos $x_t$ con $h_t$ y usamos un única matriz de pesos.\n",
    "\n",
    "\n",
    "La puerta de actualización ayuda al modelo a determinar qué cantidad de la información pasada (de los pasos de tiempo anteriores) debe transmitirse al futuro, combinandola  con la nueva información. \n",
    "\n",
    "\n",
    "Eso es realmente poderoso porque el modelo puede decidir copiar toda la información del pasado y eliminar el riesgo de desvanecer del gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Puerta reinicio</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esencialmente, esta puerta se utiliza para que el modelo decida qué cantidad de información pasada debe olvidar. La salida de la compuerta se calcula como\n",
    "\n",
    "$$\n",
    "r_t = \\sigma(W_r x_t + U_rh_{t-1} + b_r),\n",
    "$$\n",
    "\n",
    "en donde $W_r$ y $U_r$ son pesos asociados $x_t$ (la nueva entrada) y $h_{t-1}$, (el estado oculto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Activación candidata</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo afectarán exactamente las puertas al resultado final. Primero, comenzamos con el uso de la puerta de reinicio. Introducimos un nuevo contenido de memoria que utilizará la puerta de reinicio para almacenar la información relevante del pasado. Se calcula de la siguiente manera:\n",
    "\n",
    "\n",
    "$$\n",
    "\\tilde{h}_t = \\tanh(W_nx_t + U_n(r_t\\ast h_{t-1})+b_n),\n",
    "$$\n",
    "\n",
    "en donde $W_n$ y $U_n$ son pesos asociados a las  $x$'s y a las $h$'s respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Actualización del estado recurrente</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La activación de la GRU en tiempo $t$ es una interpolación lineal entre la activación previa ${h}_{t-1}$ y la activación candidata $\\tilde{h}_t$ definida arriba. En símbolos tenemos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "h_t = (1-z_t)\\ast h_{t-1} + z_t \\ast \\tilde{h}_t \n",
    "$$\n",
    "\n",
    "La siguiente imagen ilustra la arquitectura de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/plano_gru.jpg\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Imagen: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Resumen de la matemática en la red GRU</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z_t = \\sigma(W_z x_t + U_zh_{t-1} + b_z)\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_t = \\sigma(W_r x_t + U_rh_{t-1} + b_r),\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{h}_t = \\tanh(W_nx_t + U_n(r_t\\odot h_{t-1})+b_n),\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t = (1-z_t)\\odot h_{t-1} + z_t \\odot \\tilde{h}_t \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Computación  en una capa GRU de Keras</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cualquier capa de Keras siempre espera un batch de datos. En el caso de una capa GRU Keras espera tensores 3D de la siguiente forma\n",
    "\n",
    "+ [batch_size, window_len, num_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo un tensor de entrada de tamaño [32, 10, 8], la capa Keras lo interpreta como\n",
    "- batch_size = 32, es decir 32 ejemplos.\n",
    "- window_len = 10, es decir secuencias de entrada de tamaño 10. Por ejemplo en una serie de tiempo este es el tamaño de la ventana de entrada.\n",
    "- num_features = 8, es decir la variable de entrada es de tamaño 8. Por ejemplo, en series de timepo univariadas, feature = 1. En una serie multivariada con 8 variables, features = 8. En modelos de lenguaje natural feature = tamaño de representación de a cada token. Usualmente correspondería al tamaño del sumergimiento(embedding).\n",
    "\n",
    "La salida de la capa corresponde al tamaño del estado oculto. Por ejemplo, si el estado oculto tiene tamaño, la salida de la capa es de tamaño [batch_size, 4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputs = tf.random.normal([32,10,8])\n",
    "gru = tf.keras.layers.GRU(4) # gru es una capa de tamaño de salidad 4.\n",
    "output = gru(inputs)\n",
    "print (output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recibiendo toda la secuencia del valor del estado oculto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos es necesario disponer del valor del estado oculto para cada valor en la secuencia de entrada. Esta secuencia tiene tamaño [batch_size, window_len, output_size]\n",
    "En el siguiente ejemplo se tiene que\n",
    "\n",
    "- `return_sequences` son todos lo estados del estado oculto\n",
    "- `return_state` es el último valor del estado oculto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = tf.keras.layers.GRU(4, return_sequences = True, return_state=True)\n",
    "whole_seq_output, final_memory_state = gru(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 4)\n",
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "print(whole_seq_output.shape)\n",
    "print(final_memory_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_seq_output[:,-1] == final_memory_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de los pesos de la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = gru.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que los pesos de la capa GRU Están organizados de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 4 # tamaño del estado oculto\n",
    "W = gru.get_weights()[0]\n",
    "W_z = W[:,:units]\n",
    "W_r = W[:, units:units*2]\n",
    "W_n = W[:, units*2:units*3]\n",
    "\n",
    "\n",
    "U = gru.get_weights()[1]\n",
    "U_z = W[:,:units]\n",
    "U_r= W[:, units:units*2]\n",
    "U_n = W[:, units*2:units*3]\n",
    "\n",
    "b = gru.get_weights()[2] \n",
    "b_z = b[:units]\n",
    "b_r = b[ units:units*2]\n",
    "b_n = b[units*2:units*3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al inicio](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
