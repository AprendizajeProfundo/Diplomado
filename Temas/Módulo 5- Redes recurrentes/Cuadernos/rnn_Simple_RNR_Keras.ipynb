{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Redes Recurrentes Simples en Keras</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adapatado parcialmente de [Miguel Sotaquirá](https://www.youtube.com/watch?v=aA9QaPu_QpA)\n",
    "2. Ralf C. Staudemeyer and Eric Rothstein Morris, [Understanding LSTM a tutorial into Long Short-Term Memory Recurrent Neural Networks*, arxiv, September 2019](https://arxiv.org/pdf/1909.09586.pdf)\n",
    "3. Karpathy, [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "4. [Time Series Forecasting with LSTMs using TensorFlow 2 and Keras in Python](https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651/)\n",
    "5. [Dive into Deep Learnig](https://d2l.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [RNR simple en Kera](#RNR-simple-en-Kera)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección se introduce el modelo recurrente más simple, disponible en Keras. Hacemos un ejemplo para predecir nombres de personas. Consulte los detalles de la API [aquí](https://keras.io/api/layers/recurrent_layers/simple_rnn/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">RNR simple en Keras</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de una capa recurrente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar de manera muy simple vamos a crear un modelo muy simpe que recibe a la entrada secuencias de tamaño 8.\n",
    "\n",
    "En concreto el ejemplo es construido de la siguiente forma:\n",
    "\n",
    "1. Se construyen 32 conjuntos de datos. Por ejemplo 32 sentencias. Tamb ién pueden ser 32 ventanas de datos de uan serie de tiempo univariada.\n",
    "2. Cada conjunto de datos consiste de 10 secuencias de tamaño 8\n",
    "3. Se esperan secuencias de salida de tamaño 4. Por lo tanto la capa recurrente oculta tendrá tamaño 4\n",
    "\n",
    "Como se presentó en la lección anterior de introducción a redes recurrentes el proceso que hace la capa recurrente es como sigue. Para cada uno de los 32 conjuntos de datos, se sigue el siguiente procedimiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices Wxh, Whh y bh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capa inicializa los pesos por defecto de la sigiente forma\n",
    "\n",
    "1. Inicializa el kernel $W_{xh}$ usando por ejemplo [glorot uniform](http://proceedings.mlr.press/v9/glorot10a.html). Este es el kerel usado para transformar las entradas. En el ejemplo será una matriz de tamaño 8 x 4.\n",
    "2. Inicializa el kernel recurrente $W_{hh}$. Por defecto Keras usa el método llamado [orthogonal](https://smerity.com/articles/2016/orthogonal_init.html). En el ejemplo será una matriz 4 x 4, la cual transforma el estado recurrente.\n",
    "3. Inicializa el bias en cero, por defecto. Este parámetro es opcional. Su tamaño en el ejemplo es 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso recurrente de cada secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo, cada una de las 10 secuencias de cada conjunto de datos se procesa d ela sigueinte forma.\n",
    "\n",
    "1. Inicializa le estado recurrente $h = x_0W_{xh}$. \n",
    "2. Cada elemento $i, i = 1,\\ldots,9$ de la secuencia ingresa y transforma el estado recurrente de la siguiente forma $h = x_iW_{xh} + hW_{hh} + b$.\n",
    "3. Al finalizar el último valor del estado recurrente se pasa por la función de activacion , por defecto `tanh` y esta es es la salida de la capa.\n",
    "\n",
    "Entonces como vamos a introducir 32 conjuntos de datos, cada uno con 10 secuencias de tamaño 8 y esperamos secuencias de tamaño 4, a la salida esperamos a la salida 32 secuencias de tamaño 4.\n",
    "\n",
    "Vamos al código!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos para la entrada un mini-lote de 32 ejemplos de tamaño 10 x 8\n",
    "inputs = np.random.random([32, 10, 8]).astype(np.float32)\n",
    "\n",
    "# creamos una capa recurrente oculta simple con cuatro unidades de salida.\n",
    "simple_rnn = SimpleRNN(4) \n",
    "\n",
    "output = simple_rnn(inputs)  # la salida tiene tamaño [32,4]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(simple_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de las matrices de peso de la capa recurrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25773692, -0.37057853, -0.6288117 , -0.06746429],\n",
       "       [-0.07627904,  0.10132539,  0.5143829 , -0.3161408 ],\n",
       "       [ 0.07873738, -0.4994464 , -0.6341361 ,  0.01751536],\n",
       "       [-0.08485186,  0.2943967 , -0.15574878,  0.02918971],\n",
       "       [ 0.6802049 ,  0.03849101, -0.1479801 ,  0.42080826],\n",
       "       [ 0.6787345 ,  0.11882985,  0.16254926,  0.31508023],\n",
       "       [-0.08014339, -0.06870526,  0.6325106 , -0.41527593],\n",
       "       [ 0.6408685 , -0.19379896,  0.3370865 ,  0.44241053]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_x_h = simple_rnn.get_weights()[0]\n",
    "W_x_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38325727, -0.41429952, -0.81510204, -0.13068363],\n",
       "       [ 0.68143183,  0.06215988, -0.4446668 ,  0.57797766],\n",
       "       [ 0.6015466 , -0.534525  ,  0.08308589, -0.5878107 ],\n",
       "       [-0.16403064, -0.73401296,  0.36190706,  0.55076504]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_h_h = simple_rnn.get_weights()[1]\n",
    "W_h_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_h = simple_rnn.get_weights()[2]\n",
    "b_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 8)\n",
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción del estado recurrente en cada  paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible y conveniente para algunos problemas, extraer el estado recurrente en cada paso. Veámpos el ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn = tf.keras.layers.SimpleRNN(\n",
    "    4, return_sequences=True, return_state=True)\n",
    "\n",
    "# whole_sequence_output tiene forma `[32, 10, 4]`.\n",
    "# final_state tiene forma `[32, 4]`.\n",
    "whole_sequence_output, final_state = simple_rnn(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
