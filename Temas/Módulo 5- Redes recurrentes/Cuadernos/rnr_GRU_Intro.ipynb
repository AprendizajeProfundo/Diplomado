{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Redes GRU (Gated Recurrent Unit)</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introducción a Redes LSTM](Intro_LSTM.ipynb)\n",
    "1. [Time Series Forecasting with LSTMs using TensorFlow 2 and Keras in Python](https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651/)\n",
    "1. [Dive into Deep Learnig](https://d2l.ai/)\n",
    "1. [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "1. Ralf C. Staudemeyer and Eric Rothstein Morris,[*Understanding LSTM a tutorial into Long Short-Term Memory Recurrent Neural Networks*](https://arxiv.org/pdf/1909.09586.pdf), arxiv, September 2019\n",
    "1. Karpathy, [*The Unreasonable Effectiveness of Recurrent Neural Networks*](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "1.  Cho et al. 2014 [On the Properties of Neural Machine Translation: Encoder–Decoder\n",
    "Approaches](https://arxiv.org/pdf/1409.1259.pdf)\n",
    "1. J. Chung, C. Gulcehre, K. Cho, Y. Bengio, [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence  Modeling](https://arxiv.org/pdf/1412.3555v1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Funcionamiento de una red GRU](#Funcionamiento-de-una-red-GRU)\n",
    "* [Puerta de actualización-update](#Puerta-de-actualización-update)\n",
    "* [Puerta reinicio](#Puerta-reinicio)\n",
    "* [Activación candidata](#Activación-candidata)\n",
    "* [Actualización del estado recurrente](#Actualización-del-estado-recurrente)\n",
    "* [Resumen de la matemática en la red GRU](#Resumen-de-la-matemática-en-la-red-GRU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Una red neuronal recurrente (RNR) es una extensión de una red neuronal convencional,\n",
    "que es capaz de manejar una entrada de secuencia de longitud variable. La RNR maneja la longitud variable de las secuencias mediante un estado oculto recurrente cuya activación en cada momento depende del estado anterior. \n",
    "\n",
    "Más formalmente, dada una secuencia $\\mathbf{x}= (x_1, x_2, \\ldots, x_T)$, la RNR actualiza su estado oculto recurrente $h_t$ mediante \n",
    "\n",
    "\n",
    "$$\n",
    "h_t = \\begin{cases}\n",
    "0,  &\\text{ si } t=0,\\\\\n",
    "\\phi(h_{t-1},x_t), &\\text{en otro caso}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Si $g$ es una función de activación  suave, como un sigmoide o una tangente hiperbólica, es común definir\n",
    "\n",
    "$$\n",
    "h_t = g(Wh_{t-1} + Ux_t+ b)\n",
    "$$\n",
    "\n",
    "Una RNR generativa genera una distribución de probabilidad sobre el siguiente elemento de la secuencia, dado su estado actual $h_t$, y este modelo generativo puede capturar una distribución sobre secuencias de longitud variable mediante el uso de un símbolo de salida especial para representar el final de la secuencia. La secuencia la probabilidad se puede descomponer en\n",
    "\n",
    "$$\n",
    "p (x_1,\\ldots, x_T) = p (x_1) p (x_2 | x_1) p (x_3 | x_1, x_2) \\ldots p (x_T | x_1,\\ldots, x_{T − 1}), \n",
    "$$\n",
    "\n",
    "donde el último elemento es un valor especial de final de secuencia. Modelamos cada probabilidad condicional distribución con\n",
    "\n",
    "$$\n",
    "p (x_t | x_1,\\ldots, x_{t − 1}) = g (h_t)\n",
    "$$\n",
    "\n",
    "El problema con este modelo, es que el cálculo del gradiente tiende a volverse cero o a explotar. \n",
    "\n",
    "Dos líneas de trabajo impulsó esta situación. Por un lado se inició la búsqueda de nuevas técnicas para para el uso del gradiente en el proceso de optimización de  la función de costo y por el otro, el desarrollo de nuevos modelos de redes neuronales. \n",
    "\n",
    "\n",
    "La primera línea ha producido nuevas técnicas de optimización estocástica basados en el gradiente, que han sido usado exitosamente en redes generales. \n",
    "\n",
    "La segunda línea llevó al desarrollo de las redes [LSTM](Intro_LSTM.ipynb), en las cuales la función de activación consiste en una transformación afinada seguida por una simple no linealidad de elementos mediante el uso de unidades de compuerta, [Hochreiter y Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf). \n",
    "\n",
    "\n",
    "Más recientemente, otro tipo de unidad recurrente, a la que nos referimos como una unidad recurrente cerrada (GRU), fue propuesta por [Cho et al. 2014](https://arxiv.org/pdf/1409.1259.pdf). Puede consultar una comparación entre LSTM y GRU en [Junyoung Chung et al., 2014](https://arxiv.org/pdf/1412.3555v1.pdf). De estas unidades recurrentes se ha demostrado que funcionan bien en tareas que requieren captura de dependencias a largo plazo.  Esas tareas incluyen, pero no se limitan a reconocimiento de voz, música,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Funcionamiento de una red GRU</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red de unidad recurrente cerrada (GRU) permite que cada unidad recurrente capture de forma adaptativa dependencias de diferentes escalas de tiempo. De manera similar a la unidad LSTM, la GRU tiene puertas que modulan el flujo de información dentro de la unidad.  Sin embargo, a diferencia de las redes LSTM no tiene celdas de memoria separadas. Las dos  imágenes muestran la estructura general de las compuertas GRU.\n",
    "\n",
    "![Gru-1](../Imagenes/gru-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos diagramas muestran la estructura matemática dentro de la compuerta en el tiempo $t$, con reinicio antes o después de de la multiplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/compuerta_GRU_after_false.jpg\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Imagen: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset_after: convención GRU (si aplicar la puerta de reinicio después o antes de la multiplicación de matrices). False = \"antes\", True = \"después\" (este es el caso por defecto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/compuerta_GRU_after_true.jpg\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Imagen: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La notación que usamos es bastante estándar. \n",
    "\n",
    "1. $+$ : indica suma de vectores\n",
    "2. $\\sigma$ : representa a la función de activación sigmoide\n",
    "3. $\\tanh$ : representa a la función de activación tangente hiperbólica.\n",
    "4.$\\odot$ : es producto componente a componente (producto de Hamard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una GRU tien dos tipos de puerta: actualización (update) y reinicio (reset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Puerta de actualización-update</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Comenzamos calculando la puerta de actualización $z_t$ para el paso de tiempo $t$ usando la fórmula:\n",
    "\n",
    "$$\n",
    "z_t = \\sigma(W_z x_t + U_zh_{t-1} + b_z)\n",
    "$$\n",
    "\n",
    "en donde $W_z$ y $U_z$ son pesos asociados $x_t$ (la nueva entrada) y $h_{t-1}$, (la  información procedente de la unidad anterior).\n",
    "\n",
    "\n",
    "La puerta de actualización ayuda al modelo a determinar qué cantidad de la información pasada (de los pasos de tiempo anteriores) debe transmitirse al futuro, combinandola  con la nueva información. \n",
    "\n",
    "\n",
    "Eso es realmente poderoso porque el modelo puede decidir copiar toda la información del pasado y eliminar el riesgo de desvanecer del gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Puerta reinicio</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esencialmente, esta puerta se utiliza para que el modelo decida qué cantidad de información pasada debe olvidar. Para calcularla, utilizamos:\n",
    "\n",
    "$$\n",
    "r_t = \\sigma(W_r x_t + U_rh_{t-1} + b_r),\n",
    "$$\n",
    "\n",
    "en donde $W_r$ y $U_r$ son pesos asociados $x_t$ (la nueva entrada) y $h_{t-1}$, (la  información procedente de la unidad anterior)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Activación candidata</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Veamos cómo afectarán exactamente las puertas al resultado final. Primero, comenzamos con el uso de la puerta de reinicio. Introducimos un nuevo contenido de memoria que utilizará la puerta de reinicio para almacenar la información relevante del pasado. Se calcula de la siguiente manera:\n",
    "\n",
    "\n",
    "$$\n",
    "\\tilde{h}_t = \\tanh(W_nx_t + U_n(r_t\\odot h_{t-1})+b_n),\n",
    "$$\n",
    "\n",
    "en donde $W_n$ y $U_n$ son pesos asociados a las  $x$'s y a las $h$'s respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Actualización del estado recurrente</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La activación de la GRU en tiempo $t$ es una interpolación lineal entre la activación previa ${h}_{t-1}$ y la activación candidata $\\tilde{h}_t$ definida arriba. \n",
    "\n",
    "En símbolos tenemos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "h_t = (1-z_t)\\odot h_{t-1} + z_t \\odot \\tilde{h}_t \n",
    "$$\n",
    "\n",
    "La siguiente imagen ilustra la arquitectura de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/plano_gru.jpg\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Imagen: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Resumen de la matemática en la red GRU</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z_t = \\sigma(W_z x_t + U_zh_{t-1} + b_z)\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_t = \\sigma(W_r x_t + U_rh_{t-1} + b_r),\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{h}_t = \\tanh(W_nx_t + U_n(r_t\\odot h_{t-1})+b_n),\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t = (1-z_t)\\odot h_{t-1} + z_t \\odot \\tilde{h}_t \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Computación  en una capa GRU de Keras</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cualquier capa de Keras siempre espera un batch de datos. En el caso de una capa LSTM Keras espera tensores 3D de la siguiente forma\n",
    "\n",
    "+ [batch_size, time_step, feature]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo un tensor de entrada de tamaño [32, 10, 8], la capa Keras lo interpreta como\n",
    "- batch_size = 32, es decir 32 ejemplos.\n",
    "- time_step = 10, es decir secuencias de entrada de tamaño 10. Por ejemplo en una serie de tiempo este es el tamaño de la ventana de entrada.\n",
    "- feature = 8, es decir la variable de entrada es de tamaño 8. Por ejemplo, en series de timepo univariadas, feature = 1. En una serie multivariada con 8 variables, features = 8. En modelos de lenguaje natural feature = tamaño de representación de acada token. Usualmente correspondería al tamaño del embedding.\n",
    "\n",
    "La salida de la capa corresponde al tamaño del estado oculto. Por ejemplo, si el estado oculto tiene tamaño, la salida de la capa es de tamaño [batch_size, 4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputs = tf.random.normal([32,10,8])\n",
    "gru = tf.keras.layers.GRU(4) # gru es una capa de tamaño de salidad 4.\n",
    "output = gru(inputs)\n",
    "print (output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recibiendo toda la secuencia del valor del estado oculto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos es necesario disponer del valor del estado oculto para cada valor en la secuenci de entrada. Esta secuencia tiene tamaño [batch_size, time_step, output_size]\n",
    "En el sugiente ejemplo se tiene que\n",
    "\n",
    "- `return_sequences` son todos lo estados del estado oculto\n",
    "- `return_state` es el último valor del estado oculto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = tf.keras.layers.GRU(4, return_sequences = True, return_state=True)\n",
    "whole_seq_output, final_memory_state = gru(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 4)\n",
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "print(whole_seq_output.shape)\n",
    "print(final_memory_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_seq_output[:,-1] == final_memory_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de los pesos de la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = gru.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que los pesos de la capa GRU Están organizados de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 4 # tamaño del estado oculto\n",
    "W = gru.get_weights()[0]\n",
    "W_z = W[:,:units]\n",
    "W_r = W[:, units:units*2]\n",
    "W_n = W[:, units*2:units*3]\n",
    "\n",
    "\n",
    "U = gru.get_weights()[1]\n",
    "U_z = W[:,:units]\n",
    "U_r= W[:, units:units*2]\n",
    "U_n = W[:, units*2:units*3]\n",
    "\n",
    "b = gru.get_weights()[2] \n",
    "b_z = b[:units]\n",
    "b_r = b[ units:units*2]\n",
    "b_n = b[units*2:units*3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Regresar al inicio](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
