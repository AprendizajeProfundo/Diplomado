{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Introducción a Redes Neuronales Recurrentes</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Ejemplo 1: Serie de tiempo simulada</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introducción a Redes LSTM](Intro_LSTM.ipynb)\n",
    "2. [Time Series Forecasting with LSTMs using TensorFlow 2 and Keras in Python](https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651/)\n",
    "3. [Dive into Deep Learnig](https://d2l.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Series de tiempo y aprendizaje profundo](#Series-de-tiempo-y-aprendizaje-profundo)\n",
    "* [Modelo recurrente](Modelo-recurrente)\n",
    "* [Importar módulos requeridos](#Importar-módulos-requeridos)\n",
    "* [Datos sintéticos](#Datos-sintéticos)\n",
    "* [Modelo LSTM](#Modelo-LSTM)\n",
    "* [Modelo GRU](#Modelo-GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introducción a Redes LSTM](Intro_LSTM.ipynb)\n",
    "2. [Time Series Forecasting with LSTMs using TensorFlow 2 and Keras in Python](https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de la serie temporal introducen una \"dependencia dura\" de los pasos de tiempo anteriores, por lo que no se cumple la independencia de las observaciones. ¿Cuáles son algunas de las propiedades que puede tener una serie temporal?\n",
    "\n",
    "La *estacionalidad* y la *autocorrelación* son algunas de las propiedades de la serie temporal en las que puede estar interesado.\n",
    "\n",
    "Se dice que una serie de tiempos es **estacionaria** cuando la media y la varianza permanecen constantes en el tiempo. \n",
    "\n",
    "Una serie temporal tiene una **tendencia** si la media varía con el tiempo. A menudo puede eliminarlo y hacer que la serie sea estacionaria aplicando transformación(es) logarítmicas de los datos.\n",
    "\n",
    "\n",
    "**La estacionalidad** se refiere al fenómeno de las variaciones en plazos específicos. por ejemplo, personas que compran más árboles de Navidad durante Navidad (quién lo hubiera pensado). Un enfoque común para eliminar la estacionalidad es usar la diferenciación.\n",
    "\n",
    "**La autocorrelación** se refiere a la correlación entre el valor actual con una copia de un tiempo anterior (retraso).  \n",
    "\n",
    "Usaremos redes neuronales para el modelamiento de esta series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Series de tiempo y aprendizaje profundo</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una serie de tiempo univariada es una sucesión de valores en el tiempo, digamos\n",
    "\n",
    "$$\n",
    "x_1, x_2, x_3, \\ldots x_T.\n",
    "$$\n",
    "\n",
    "Por ejemplo consideremos la serie dada pos los siguientes valores: \n",
    "\n",
    "$$\\{3.4, 5.2, 4.6, 6.2, 5.5, 4.0, 7.2, 8.1, 6.9, 9.2, 9.5, 9.8, 8.9, 9.6, 9.7, 9.9 \\}\n",
    "$$\n",
    "\n",
    "\n",
    "El problema de hacer pronósticos a partir de una serie de tiempo puede verse como un problema de aprendizaje profundo , si la información se organiza inicialmente como un problema de regresión o de clasificación. La siguiente imagen ilustra el procedimiento más común."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/series.jpg\"  width=\"800\" height=\"800\" align=\"center\"/> \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la imagen se observan varias cosas interesantes.\n",
    "\n",
    "1. Los datos de la serie se han organizado como si se tuviera un regresión. La matriz de diseño $X$ está constituida por filas con 8 columnas. El número de columnas corresponde al rezago (núnro de pasos hacia atrás en la serie para poder predecir el sigueinte valor.\n",
    "2. La variable de interés $Y$ es la variable que se quiere predecir.\n",
    "\n",
    "Observe que para la primera fila se tomaron los primeros 8 datos de la serie y el valor de la variable a predecir es la novena observación. En la segunda fila nos hemos desplazado un casilla a la derecha en la serie.\n",
    "\n",
    "Puesto de esta forma, cada fila de la matriz $X$ es independiente de las demás y constituye y tensor de dimensión 1 en la entrada de una red neuronal. La variable target es es el tensor $Y$.\n",
    "\n",
    "Visto de esta forma tenemos un problema de aprendizaje profundo, por lo que un por ejemplo un perceptron podría usarse para construir un modelo predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediccioón a más de un paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo que se desea es hacer predicciones, varios pasos adelante y no del siguiente paso, el único cambio es en la variable objetivo (target). La imagen muestra el caso de predcciones tres pasos adelante. Observe que en esta caso la variable objetivo se toma tre pasos adelante del último elemenot de cada fila. \n",
    "\n",
    "Observe además que las dos últimas filas de la matriz no se pueden utilizar, debido a que no tenemos datos más allá de el útlimo dato de la serie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/prediccion_tres_dias.jpg\"  width=\"800\" height=\"800\" align=\"center\"/> \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Multivariadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas situaciones tenemos  más de una serie. La siguiente imagen muestra la nueva situación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/Serie_Multivariada.jpg\"  width=\"800\" height=\"800\" align=\"center\"/> \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, ahora los tensores de datos de entrada tiene una dimensión más, la cual en el lenguaje de los modelos convolucionales, que estudiarmeos más adelante, llamaremos canales. En el ejemplo, se muestra como se preparan los datos de tres series de tiempos para tratarlos como un problema de aprendizaje profundo.\n",
    "\n",
    "La imagen ilustra claramente, la semejanza de los datos de imágenes en donde hay varia canales de color. Esta forma de organización de los datos para aprendizaje profundo llevó a los diseñadores de capas neuronales para este tipo de problemas a considerar tanto en problemas de visión por computador como para redes recurrentes, que los tensores de entrada siempre sean de dimensión 3: largo, ancho y canales. \n",
    "\n",
    "En el caso de las series siempre se tendrá \n",
    "\n",
    "1. tamaño de batch, por ejemplo 32,\n",
    "2. longitud del rezago, por ejemplo 8,\n",
    "3. número de canales, por ejemplo 3.\n",
    "\n",
    "Adicionalmente puede verse que la variable objetivo tiene por lo menos el tamaño del batch. Este tensor puede tener una segunda dimensión que podría corresponder  al número de canales, pero no es necesario. Por ejemplo, podría tenerse que la variable objetivo podría ser el promedio de los valores predichos de cada acanal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos multivariadas multi-cabeza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez las series de tiempo se presentan como un problema de aprendizaje profundo, es posible pensar en diferentes arquitecturas de redes. La siguiente imagen presenta un alternativa que consiste en que cada serie entran por una camino diferente a la red, sigue un camino separado por un tiempo y luego las predicciones se concadenan para llegar a una predicción final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/multicabeza.jpg\"  width=\"800\" height=\"800\" align=\"center\"/> \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Modelo recurrente</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código puede ser usado como base para la implementación de modelos mas complejos. Para un introdución teórica a las redes LSTM consulte el cuaderno [Redes LSTM (Long Short Term Memory Networks)](Intro_LSTM.ipynb). La siguiente imagen muestra la estructura general de una capa recurrente. LSTM es un caso particular y el gráfico ilustra bien la forma de procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/modelo_recurrente.jpg\"  width=\"800\" height=\"800\" align=\"center\"/> \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos con un ejemplo simple de pronosticar los valores de la función Seno utilizando una red LSTM simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Importar módulos requeridos</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "#from tensorflow import keras\n",
    "#\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "#\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#\n",
    "print(\"Versión de Tensorflow: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuraciones básicas generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "#\n",
    "#sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 16, 10\n",
    "#\n",
    "\n",
    "#tf.random.set_seed(RANDOM_SEED)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Datos sintéticos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar unos datos que siguen un comportamiento sinosoidal, con una tendencia ascendiente. Se introduce ruido Gaussiano. \n",
    "\n",
    "Modifique las siguientes dos líneas y haga su priopia simulación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "trend = .1\n",
    "#\n",
    "time = np.arange(0, 100, 0.1)\n",
    "sin =  trend*time + np.sin(time) + np.random.normal(scale=0.5, size=len(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer gráfico. Datos simulados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, sin, label='Función seno con tendencia ascendente y ruido Gaussiano');\n",
    "plt.title(\"Serie de tiempo simulada, con la función seno y una tendencia\", size = 20)\n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Número de datos: ', sin.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escala los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducimos un instancia de clase del escalador *MinMaxScaler* para llevar los datos a la escala $[0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crea un dataset \n",
    "#\n",
    "df1 = pd.DataFrame(sin, index=time, columns=['serie'])\n",
    "# crea el objeto  scaler y escala los datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df1.values)\n",
    "#\n",
    "dataset = pd.DataFrame(scaled_data,index=df1.index, columns=['serie'])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de datos escalados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serie_0_1 = dataset.serie_0_1.values\n",
    "\n",
    "plt.plot(time, dataset, label='Datos estandarizados a escala [0,1]');\n",
    "plt.title(\"Serie de tiempo simulada, con la función seno y una tendencia\", size = 20)\n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Separación de datos entrenamiento y de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las series de tiempo, los datos de entrenamiento se toman desde el comienzo de la serie y los de validación desde el final haci atras. \n",
    "\n",
    "Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset.iloc[0:train_size], dataset.iloc[train_size:len(df1)]\n",
    "len_train = len(train)\n",
    "len_test = len(test)\n",
    "print(len_train, len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot que muestra los datos de entrenamiento y los de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16,8))\n",
    "plt.plot(train, label='Conjunto de entrenamiento (Training set): ' + str(len_train) +' puntos (80%)')\n",
    "plt.plot(test, label='Conjunto de Validación (Validation set): '  + str(len_test) + ' puntos (20%)') \n",
    "plt.title(\"Serie de tiempo simulada, con la función seno y una tendencia\", size = 20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparar los datos para la predicción de series temporales (LSTM en particular) puede ser complicado.\n",
    "\n",
    "Intuitivamente, necesitamos predecir el valor en el paso de tiempo actual utilizando el historial ($n$ pasos de tiempo hacia atrás a partir de él). \n",
    "\n",
    "\n",
    "Aquí se propone una función genérica que hace el trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps=1):\n",
    "    # crea dos listas vacias para depositar los datos\n",
    "    Xs, ys = [], []\n",
    "    # el primer lote de datos empieza en la primera observación\n",
    "    # y toma time_steps  datos.\n",
    "    # Comienza a avanzar hacia adelante.\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La belleza de esta función es que trabaja con datos de series temporales univariadas (función única) y multivariadas (funciones múltiples). Usemos un historial de 50 pasos de tiempo para hacer nuestras secuencias. Esto significa que vamos a conservar la historia de 50 pasos atrás para predecir el valor actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 50\n",
    "\n",
    "# reshape to [samples, time_steps, n_features]\n",
    "\n",
    "X_train, y_train = create_dataset(train, train, time_steps)\n",
    "X_test, y_test = create_dataset(test, test, time_steps)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "print([X_train[0:2,], y_train[0:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Modelo LSTM</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un modelo LSTM en Keras es fácil. Utilizaremos la capa LSTM en un modelo secuencial para hacer nuestras predicciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crea el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes\n",
    "inputs_shape = (X_train.shape[1], X_train.shape[2])\n",
    "lstm_output = 60\n",
    "\n",
    "# layers\n",
    "inputs = Input(inputs_shape)\n",
    "x = LSTM(units=lstm_output, name='LSTM_layer')(inputs)\n",
    "outputs = Dense(1)(x)\n",
    "\n",
    "# model\n",
    "serie_0_1_model = Model(inputs=inputs, outputs=outputs, name='series_LSTM_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.Sequential()\n",
    "#model.add(keras.layers.LSTM(units=lstm_output,  input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "#model.add(keras.layers.Dense(units=1))\n",
    "serie_0_1_model.summary()\n",
    "\n",
    "plot_model(serie_0_1_model, to_file='../Imagenes/series_LSTM_model.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significa que el modelo tiene la primera de tipo LSTM capa con un input de tamaño $(50,1)$ y una salida de 60 neuronas.\n",
    "\n",
    "La segunda es una capa densa con entrada 60 neuronas y salida una neurona\n",
    "\n",
    "\n",
    "El cálculo del número de neuronas es como sigue: \n",
    "\n",
    "$$\n",
    "\\text{Número de parámetros capa LSTM } = 4(p^2+ pn +p)\n",
    "$$\n",
    "\n",
    "en donde $p$ es el tamaño de salida y $n$ el tamaño de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output =60\n",
    "input_size =1 # input size in the LSTM machine\n",
    "#\n",
    "# cada entrada de tamaño 50 es mostrada a la máquina  LSTM machine uno por uno.\n",
    "# luego se tiene\n",
    "#\n",
    "num_params = 4*(lstm_output*lstm_output + lstm_output*input_size+ lstm_output)\n",
    "num_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_0_1_model.compile(loss='mean_squared_error',\n",
    "  optimizer=Adam(0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo más importante para recordar al entrenar modelos de series temporales es no mezclar los datos (el orden de los datos es importante). El resto es bastante estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = serie_0_1_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =serie_0_1_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, len(y_train)), y_train, 'g', label=\"history\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test, marker='.', label=\"true\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred, 'r', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, marker='.', label=\"true\")\n",
    "plt.plot(y_pred, 'r', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforma a la escala original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.fit_transform(df1.values)\n",
    "dataset = pd.DataFrame(scaled_data)\n",
    "dataset.columns = ['sine']\n",
    "dataset.index = df1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = scaler.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = scaler.inverse_transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, marker='.', label=\"true\")\n",
    "plt.plot(y_pred, 'r', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Modelo GRU</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes\n",
    "inputs_shape = (X_train.shape[1], X_train.shape[2])\n",
    "lstm_output = 60\n",
    "\n",
    "# layers\n",
    "inputs = Input(inputs_shape)\n",
    "x = GRU(units=lstm_output, name='GRU_layer')(inputs)\n",
    "outputs = Dense(1)(x)\n",
    "\n",
    "# model\n",
    "serie_0_1_model_gru = Model(inputs=inputs, outputs=outputs, name='series_LSTM_model')\n",
    "\n",
    "\n",
    "# summary\n",
    "serie_0_1_model_gru.summary()\n",
    "\n",
    "plot_model(serie_0_1_model_gru, to_file='../Imagenes/series_LSTM_model.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compila\n",
    "serie_0_1_model_gru.compile(loss='mean_squared_error',\n",
    "  optimizer=Adam(0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrena\n",
    "history = serie_0_1_model_gru.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru =serie_0_1_model_gru.predict(X_test)\n",
    "# escala original\n",
    "y_pred_gru = scaler.inverse_transform(y_pred_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, marker='.', label=\"true\")\n",
    "plt.plot(y_pred, 'r', label=\"prediction lstm\")\n",
    "plt.plot(y_pred_gru, 'g', label=\"prediction gru\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= 60\n",
    "n=1\n",
    "3*(p*p +p*n+p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
