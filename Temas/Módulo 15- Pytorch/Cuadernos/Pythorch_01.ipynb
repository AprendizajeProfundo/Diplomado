{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b67704-b90c-4972-9a06-e77d2df5d8d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e679f-311a-4cbc-8a73-2781d022d31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center>Pytorch</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ac5fd-f121-40bd-9f03-100e8f021593",
   "metadata": {},
   "source": [
    "<center>Inicio Rápido</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae94eb3-c187-4817-86c6-1bf16c3a8eb4",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Autores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62501236-c78c-4622-90d5-e54b384986a0",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a5cb9-13e7-400e-abe1-05e4cfbd1d68",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Diseño gráfico y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e8ce5a-a021-443c-b630-3d89441d222b",
   "metadata": {},
   "source": [
    "1. Maria del Pilar Montenegro Reyes, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2034a8-1948-4d79-be17-802e4a0b1bad",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9160b8f4-2c02-44d8-bc58-05d1c419f316",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc6f02f-a4c3-4793-a3b8-539c5c8d2a06",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3f5375-4755-4a3e-aeb0-baf86a2acda1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a99e3f7b-fbdd-468f-84cf-d62033d07341",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a309907e-ae9a-4550-9b55-60dff181ed54",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Pipeline de HuggingFace](#Pipeline-de-HuggingFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab6ba0-f3d0-4b3f-b897-3c2e3bea1c9d",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce37fc-260c-4d69-8dde-5c103c99b975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44ed2454-ab8b-4d53-b4c4-586ae89cf899",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Trabajando con datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d863ec8-ba15-4416-828c-0fecf7f8982a",
   "metadata": {},
   "source": [
    "PyTorch tiene dos primitivas para trabajar con datos: `torch.utils.data.DataLoader` y `torch.utils.data.Dataset`. *Dataset* almacena las muestras y sus etiquetas correspondientes, y *DataLoader* envuelve un iterable alrededor de *Dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6868e674-f51e-416a-a3b6-152c2fb63240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import Flatten, Sequential, Linear, ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca011a5-72a1-4aaf-98b2-104d1f097d8e",
   "metadata": {},
   "source": [
    "PyTorch ofrece bibliotecas específicas de dominio como `TorchText`, `TorchVision` y `TorchAudio`, todas las cuales incluyen conjuntos de datos. Para este tutorial, usaremos un conjunto de datos de `TorchVision`.\n",
    "\n",
    "El módulo `torchvision.datasets` contiene objetos de conjunto de datos para muchos datos de visión del mundo real como CIFAR, COCO ([lista completa aquí](https://pytorch.org/vision/stable/datasets.html)). En este tutorial, usamos el conjunto de datos FashionMNIST. Cada conjunto de datos de TorchVision incluye dos argumentos: *transform* y *target_transform* para modificar las muestras y las etiquetas respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58016690-98ff-4a37-beaf-4729e4b1877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88e0f3-d4f1-446c-b9ac-182277f64dcb",
   "metadata": {},
   "source": [
    "Pasamos el *Dataset* como un parámetro para `DataLoader`\n",
    "Esto envuelve un iterable sobre nuestro conjunto de datos y admite procesamiento por lotes, muestreo, barajado y carga de datos multiproceso automáticos. Aquí definimos un tamaño de lote de 64, es decir, cada elemento en el cargador de datos iterable devolverá un lote de 64 características y etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bdd8cb0-cbe5-41b1-a10f-de71a09d8915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "#create data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print('X[N, C, H, W]: ', X.shape)\n",
    "    print('Shape of y: ', y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68aa4d-0a61-464d-bdf4-f379125de87c",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Creando modelos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0031c4-973e-4774-932a-bc37e14ae504",
   "metadata": {},
   "source": [
    "Para definir una red neuronal en PyTorch, creamos una clase que hereda de nn.Module. Definimos las capas de la red en la función __init__ y especificamos cómo pasarán los datos a través de la red en la función de reenvío. Para acelerar las operaciones en la red neuronal, lo trasladamos a la GPU si está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90a0146-c84a-4feb-9310-ba3a377ab154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get gpu or cpu device fro training\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using {} device'.format(device))\n",
    "\n",
    "# define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = Flatten()\n",
    "        self.linear_relu_stack = Sequential(\n",
    "            Linear(28*28, 512),\n",
    "            ReLU(),\n",
    "            Linear(512, 512),\n",
    "            ReLU(),\n",
    "            Linear(512, 10),\n",
    "            ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d703e-81d5-450c-b80f-3ea88b206d2a",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Optimización de los parámetros del modelo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd65a4b-82d7-48c4-bc29-b590a123d4b6",
   "metadata": {},
   "source": [
    "### Función de pérdida y optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4df5a794-e7dd-467a-a4f5-39e34137e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b14c9e-28d6-4d17-922e-34e4c1fc27ca",
   "metadata": {},
   "source": [
    "### Función de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d41cc87-05ad-4975-9094-5325d287eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer): \n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Calcula error de predicción\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:5d}/{size:>5d}]')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc49628-543a-42c6-bb66-ede339f6c36a",
   "metadata": {},
   "source": [
    "### Función Prueba (testeo) del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "572146bf-2fd3-46b5-b5f2-2d604603f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644db370-8de7-457c-bf5c-5029bde7e4a9",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f36b100-073b-460b-8cac-e4433b478e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.242770 [    0/60000]\n",
      "loss: 2.211176 [ 6400/60000]\n",
      "loss: 2.201343 [12800/60000]\n",
      "loss: 2.197439 [19200/60000]\n",
      "loss: 2.127711 [25600/60000]\n",
      "loss: 2.182701 [32000/60000]\n",
      "loss: 2.122766 [38400/60000]\n",
      "loss: 2.120491 [44800/60000]\n",
      "loss: 2.133974 [51200/60000]\n",
      "loss: 2.083036 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 2.077847 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.104970 [    0/60000]\n",
      "loss: 2.049480 [ 6400/60000]\n",
      "loss: 2.022767 [12800/60000]\n",
      "loss: 2.035321 [19200/60000]\n",
      "loss: 1.899264 [25600/60000]\n",
      "loss: 2.024711 [32000/60000]\n",
      "loss: 1.911178 [38400/60000]\n",
      "loss: 1.917189 [44800/60000]\n",
      "loss: 1.945168 [51200/60000]\n",
      "loss: 1.872132 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 1.857988 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.904570 [    0/60000]\n",
      "loss: 1.812600 [ 6400/60000]\n",
      "loss: 1.775489 [12800/60000]\n",
      "loss: 1.807234 [19200/60000]\n",
      "loss: 1.622221 [25600/60000]\n",
      "loss: 1.840290 [32000/60000]\n",
      "loss: 1.657998 [38400/60000]\n",
      "loss: 1.701059 [44800/60000]\n",
      "loss: 1.736604 [51200/60000]\n",
      "loss: 1.648887 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.637089 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.698441 [    0/60000]\n",
      "loss: 1.590649 [ 6400/60000]\n",
      "loss: 1.552447 [12800/60000]\n",
      "loss: 1.604510 [19200/60000]\n",
      "loss: 1.401471 [25600/60000]\n",
      "loss: 1.684036 [32000/60000]\n",
      "loss: 1.453601 [38400/60000]\n",
      "loss: 1.535203 [44800/60000]\n",
      "loss: 1.564623 [51200/60000]\n",
      "loss: 1.484156 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.468695 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.528475 [    0/60000]\n",
      "loss: 1.427008 [ 6400/60000]\n",
      "loss: 1.380648 [12800/60000]\n",
      "loss: 1.461191 [19200/60000]\n",
      "loss: 1.248481 [25600/60000]\n",
      "loss: 1.559406 [32000/60000]\n",
      "loss: 1.313488 [38400/60000]\n",
      "loss: 1.417245 [44800/60000]\n",
      "loss: 1.434797 [51200/60000]\n",
      "loss: 1.374960 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 1.349057 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0c6a25-ceba-4f4b-afbd-ac940d89bad2",
   "metadata": {},
   "source": [
    "### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32bbe6da-812c-416d-850c-37e91e550731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Modelo Pytotch guardado:  ../Checkpoints/Model_0\n"
     ]
    }
   ],
   "source": [
    "path = '../Checkpoints/Model_0'\n",
    "torch.save(model.state_dict(), path)\n",
    "print(' Modelo Pytotch guardado: ', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fdb1f-4bf2-4a8c-9f46-ed78a9ea4046",
   "metadata": {},
   "source": [
    "### Carga el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8347840-ea93-4627-8395-3c8cd16ae754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf9acb-8668-444d-90d3-c09e4816954f",
   "metadata": {},
   "source": [
    "### Predicciones con el modelo cargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a08b6c5-a124-4232-8af8-032c10ed66f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x,y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dcbc7a-6593-4a26-9125-3ce891f740f7",
   "metadata": {},
   "source": [
    "###  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
