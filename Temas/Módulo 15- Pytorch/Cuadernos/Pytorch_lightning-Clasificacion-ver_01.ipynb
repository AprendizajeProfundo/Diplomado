{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b851f7-c675-4a2a-8932-59bf23db8edb",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F72585\">Clasificación de imágenes con Pytorch-lightning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d026e31-2c95-4a27-9da0-45331b02c810",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/trainer.png\" width=\"800\" height=\"800\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab698e08-33bf-45c2-8b16-306084b6bf78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02e2c2-0e22-4f37-8e7d-021c3bad1b04",
   "metadata": {},
   "source": [
    "En esta lección aprendemos como construir una modelo de clasificación de imágenes a color. Usaremos el framework [Pytorch-lightning](https://www.pytorchlightning.ai/) para construir el modelo y el conjunto de datos [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). La siguiente figura los tipos de datos que se usarán en esta lección. El contenido es una adaptación libre del tutorial [Image Classification using PyTorch Lightning](https://wandb.ai/wandb/wandb-lightning/reports/Image-Classification-using-PyTorch-Lightning--VmlldzoyODk1NzY) de [WandB](https://wandb.ai/site)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bcd09b-7e30-47ed-b57d-d232193cb03f",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/cifar10.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: [Universidad de Toronto-Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21048ee9-8cbe-49f6-b8f6-03261e092621",
   "metadata": {},
   "source": [
    "Para esta lección usaremos los datos CIFAR10 disponibles en los datasets de la librería [Torchvision](https://pytorch.org/vision/stable/index.html). Adicionalmente usaremos [Weights and bias-Wandb](https://wandb.ai/site), una plataforma moderna que puede apoyar para crear mejores modelos, más rápido con el seguimiento de experimentos, el control de versiones de conjuntos de datos y la gestión de modelos. WandB debe instalarse por separado, pero se incorpora a la librería `pytorch_lightning.loggers`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e37e37-4c2f-4c66-8712-884061bb7225",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Carga las librerías requeridas</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea02acc2-4c38-4778-9914-f27a297fdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Carga DataLoader para crear los dataloaders\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Librería Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# métricas\n",
    "import torchmetrics \n",
    "\n",
    "# reproductibilidad\n",
    "from pytorch_lightning import seed_everything # reproducibilidad\n",
    "\n",
    "# Carga WandBLogger para hacer seguimiento (tracking) del entrenamiento\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# carga el dataset CIFAR10\n",
    "import torchvision.datasets as datasets\n",
    "CIFAR10 = datasets.CIFAR10\n",
    "\n",
    "# callbacks\n",
    "from pytorch_lightning.callbacks import Callback \n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14327a65-1c99-4832-b575-49ae84437201",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Preparación de los datos</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962b5c6-b5b5-49fb-b7da-2ab6656c1ac0",
   "metadata": {},
   "source": [
    "Los `DataModule` son una forma de desacoplar enlaces relacionados con datos del LightningModule para que pueda desarrollar modelos agnósticos de conjuntos de datos. En otra palabras, con DataModule puede preparar los datos por fuera del módulo de entrenamiento, de tal manera que peude cambiar sus datos sin tocar el módulo de entrenamiento.\n",
    "\n",
    "Con *DataModule* podemos organiza la canalización de datos en una clase compartible y reutilizable. Un módulo de datos encapsula los cinco pasos involucrados en el procesamiento de datos en PyTorch:\n",
    "\n",
    "* Descargar/tokenizar/procesar.\n",
    "* Limpiar y (tal vez) guardar en el disco.\n",
    "* Cargar dentro del conjunto de datos.\n",
    "* Aplicar transformaciones (rotar, tokenizar, etc.).\n",
    "* Envolver dentro de un DataLoader.\n",
    "\n",
    "\n",
    "Obtenga más información sobre los módulos de datos [aquí](https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html). Construyamos un módulo de datos para el conjunto de datos Cifar-10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c9bc5-bf5d-41bc-a8b6-7d15ee9c1e24",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Canalización (pipeline) de los datos con DataModule</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d42586-b397-470c-8ccb-41a58581ba35",
   "metadata": {},
   "source": [
    "Construimos una clase derivada de `LightningDataModule` específica para CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e554bb-eeb6-47b2-9820-883b2751fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, batch_size, data_dir: str = './', num_workers=4):\n",
    "        \"\"\"\n",
    "        Pasaremos los hiperparámetros necesarios para nuestra canalización de datos\n",
    "        utilizando el método __init__. También definiremos la canalización de \n",
    "        transformación de datos aquí.\n",
    "        params:\n",
    "        datadir\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        self.dims = (3, 32, 32)\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Aquí es donde definiremos la lógica para descargar nuestro conjunto de datos. \n",
    "        Estamos utilizando la clase de conjunto de datos CIFAR10 de torchvision para descargar.\n",
    "        Use este método para hacer cosas que podrían escribirse en el disco \n",
    "        o que deben hacerse solo desde una única GPU en configuraciones distribuidas. \n",
    "        No haga ninguna asignación de estado en esta función \n",
    "        (es decir, self.alguna_cosa = ...).\n",
    "        \"\"\"\n",
    "        # descarga\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Aquí es donde cargaremos los datos del archivo y prepararemos \n",
    "        los conjuntos de datos del tensor PyTorch para cada división de los datos. \n",
    "        La división de datos es por lo tanto reproducible. \n",
    "        Este método espera un argumento de etapa (stage) que se utiliza para separar \n",
    "        la lógica de 'entrenamiento' y de 'prueba'. \n",
    "        Esto es útil si no queremos cargar todo el conjunto de datos a la vez. \n",
    "        Las operaciones de datos que queremos realizar en cada GPU se definen aquí. \n",
    "        Esto incluye aplicar la transformación al conjunto de datos del tensor de PyTorch.\n",
    "        \"\"\"        \n",
    "        # Asigna datos a los datasets de entrenamiento/validación  \n",
    "        # para uso en los dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Asigna dataset de prueba para uso en los  dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    # Métodos para crear los dataloaders        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=self.batch_size, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ded3e1-3cf2-4f1e-88a4-def6bbf41d45",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Devolución de llamadas (Callbacks)</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfeab5-2add-46f5-913e-e56b3c479883",
   "metadata": {},
   "source": [
    "Una devolución de llamada o `callback` es un programa autónomo que se puede reutilizar en todos los proyectos. PyTorch Lightning viene con algunos callbacks integrados que se usan regularmente.\n",
    "Obtenga más información sobre callbacks en PyTorch Lightning [aquí](https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a454fe0c-98d7-4d59-b0ab-b590c20b6344",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Devoluciones  de llamada integrados</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a219f-6c4d-457e-b826-304cb432d4c1",
   "metadata": {},
   "source": [
    "En este tutorial, utilizaremos las devoluciones de llamada integradas de parada anticipada `Early Stopping` y punto de control `checkpoint` de modelo. Estos callback se pueden pasar al entrenador (`Trainer`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c264f-39f7-4c9e-bdfb-4c5054d4b5b4",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Devoluciones de llamada personalizados</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d48f6-0cce-4817-b1d4-d2a79bf88936",
   "metadata": {},
   "source": [
    "Si está familiarizado con la devolución de llamada personalizada de `Keras`, la capacidad de hacer lo mismo en su canalización de PyTorch es solo una cereza del pastel.\n",
    "\n",
    "Dado que estamos realizando una clasificación de imágenes, la capacidad de visualizar las predicciones del modelo en algunas muestras de imágenes puede resultar útil. Esto en forma de callback puede ayudar a depurar el modelo en una etapa temprana. Así que vamos a implementar un callback personalizado para tal fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab2ec98-0a0c-4601-bbd0-b4bd0478f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePredictionLogger(Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        \"\"\"\n",
    "        ImagePredictionLogger es una subclase de la clase Callback de PyTorch Lightning. \n",
    "        params:\n",
    "        val_samples: es una tupla de imágenes y etiquetas. \n",
    "        num_samples: es el número de imágenes que se registrarán en el panel de control de W&B.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        \"\"\"\n",
    "        Este método es llamado cuando finaliza la época de validación. \n",
    "        Se necesitan dos argumentos: \n",
    "        trainer: entrenador del modelo\n",
    "        pl_module: módulo del modelo\n",
    "        Ambios parámetros son pasadoa autompaticamente por el trainer.\n",
    "        Al usar trainer.logger.experimental podemos usar todas las funciones disponibles por Pesos y sesgos.\n",
    "        \"\"\"\n",
    "        # Trasladar los tensors a CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Obtener la predicción del modelo\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)\n",
    "        # Pasa la imágenes al logger como  wandb Image\n",
    "        trainer.logger.experiment.log({\n",
    "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
    "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
    "                                                 preds[:self.num_samples], \n",
    "                                                 val_labels[:self.num_samples])]\n",
    "            })\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc7bd8-0cec-488f-b0f8-20eb795744c7",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Define el modelo: backbone</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919af584-f434-4df5-8fc3-a8a1c4baea9c",
   "metadata": {},
   "source": [
    "Esta clase define el modelo de red neuronal que usaremos para nuestra investigación. Aunque en ocasiones elm modelo hacer parte del sistema que definimos en la siguiente sección, desacoplar el código de esta forma lo hace más agnóstico y fácil de reutilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f6bdef-6a5c-44c7-a1e1-325837a2002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(torch.nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        Modelo neorual de clasificación paar los datos CIFAR10.\n",
    "        parámetros:\n",
    "        input_shape: tamaño de los tensores de entrada\n",
    "        num_classes: número de clases en el problema\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # log hyperparameters\n",
    "        #self.save_hyperparameters()\n",
    "        #self.learning_rate = learning_rate\n",
    "        \n",
    "        # bloque convolucional: cuerpo de la red\n",
    "        \"\"\"\n",
    "        CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, \n",
    "        padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 1)\n",
    "        \"\"\"\n",
    "        CLASS torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, \n",
    "        return_indices=False, ceil_mode=False)\n",
    "        \"\"\"\n",
    "        self.pool1 = torch.nn.MaxPool2d(2)\n",
    "        self.pool2 = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "        # Calcula el tamaño de salida del bloque convolucional\n",
    "        n_sizes = self._get_conv_output(input_shape)\n",
    "        \n",
    "        # bloque Lineal: cabeza de la red\n",
    "        self.fc1 = nn.Linear(n_sizes, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    # métodos auxiliares para calcular el tamaño de salida\n",
    "    # del bloque convolucion. Se requiere ara poder configurar \n",
    "    # totalmente la red. No requrido en Keras\n",
    "    def _get_conv_output(self, shape):\n",
    "        \"\"\"\n",
    "        devuelve el tamaño del tensor de salida del bloque conv.\n",
    "        \"\"\"\n",
    "        batch_size = 1\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self._forward_features(input) \n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "        \n",
    "    def _forward_features(self, x):\n",
    "        \"\"\"\n",
    "        retorna el tensor de características de la salida el bloque conv\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        return x\n",
    "    \n",
    "    # modelo\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Cálculo del modelo. Corre cada vez que se llama al modelo\n",
    "        \"\"\"\n",
    "        # calcula el bloque convolucional\n",
    "        x = self._forward_features(x)\n",
    "        # aplana el tensor de salida del bloque convolucional\n",
    "        x = x.view(x.size(0), -1) # x.size(0) es el tamaño del lote de datos\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1) # log softmax es más estable que softmax\n",
    "       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3942a-b103-4171-ac33-809695545fb7",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">LightningModule - Definición del sistema</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea586c-1687-4d56-8d45-1e7057049bd3",
   "metadata": {},
   "source": [
    "`LightningModule` define un sistema y no un modelo. Aquí, un sistema agrupa todo el código de investigación en una sola clase para que sea autónomo. LightningModule organiza su código PyTorch en 5 secciones:\n",
    "\n",
    "* Bucle de entranamiento (training_step)\n",
    "* Bucle de validación (validation_step)\n",
    "* Bucle de prueba (test_step)\n",
    "* Optimizadores (configure_optimizers)\n",
    "\n",
    "\n",
    "Por lo tanto, se puede construir un modelo agnóstico del conjunto de datos que se puede compartir fácilmente. Construyamos un sistema para la clasificación Cifar-10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c8d5a6b-1c04-47e1-952a-ac6378e428dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self,  backbone, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "        # activa log para almacenar los hiperparámetros\n",
    "        self.save_hyperparameters()\n",
    "        # modelo\n",
    "        self.backbone = backbone\n",
    "        # rata  de aprendizaje para el optimizador\n",
    "        self.learning_rate = learning_rate\n",
    "        # métricas\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "        self.test_acc = torchmetrics.Accuracy()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Lightning automatiza la mayor parte del entrenamiento para nosotros, \n",
    "        la época y las iteraciones por lotes, todo lo que necesitamos mantener \n",
    "        es la lógica del paso de entrenamiento. El método training_step requiere argumentos \n",
    "        batch y batch_idx que el Entrenador pasa automáticamente. \n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y) # entropía cruzada: negative log likelihood\n",
    "        \n",
    "        # training metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.train_acc(preds, y)\n",
    "        self.log('perdida_entrenamiento', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('precision_entrenamiento', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        el ciclo de validación se puede implementar sobrescribiendo este método \n",
    "        de LightningModule\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.valid_acc(preds, y)\n",
    "        self.log('perdida_validacion', loss, prog_bar=True)\n",
    "        self.log('precision_validacion', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Este método similar al ciclo de validación. \n",
    "        La única diferencia es que en prueba solo se llama \n",
    "        cuando se usa trainer.test(). \n",
    "        Las métricas se registran automáticamente por épocas.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.test_acc(preds, y)\n",
    "        self.log('perdida_test', loss, prog_bar=True)\n",
    "        self.log('precision_test', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Podemos definir nuestro optimizador y programadores \n",
    "        de tasa de aprendizaje usando el método \n",
    "        configure_optimizer. \n",
    "        Incluso se pueden definir múltiples optimizadores \n",
    "        como en el caso de las GAN.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.backbone.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff167f-641b-4454-9769-5e95be9af68a",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Entrenamiento y Evaluación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fc9a4-d3e4-48d6-968c-f111578fe4ae",
   "metadata": {},
   "source": [
    "Ahora que organizamos nuestra canalización de datos con `DataModule` y modelamos la arquitectura del modelo con `nn.Module` y el ciclo de entrenamiento con `LightningModule`, PyTorch Lightning `Trainer` automatiza todo lo demás por nosotros.\n",
    "\n",
    "El Entrenador automatiza:\n",
    "\n",
    "* Iteración de época y lote\n",
    "* Llamada de `optimizer.step()`, `backward`, `zero_grad()`\n",
    "* Llamada de `.eval()`, habilitación/deshabilitación de gradientes\n",
    "* Guardar y cargar pesos\n",
    "* Registro de pesos y sesgos\n",
    "* Soporte de entrenamiento multi-GPU\n",
    "* Soporte de TPU\n",
    "* soporte de entrenamiento de 16 bits\n",
    "\n",
    "\n",
    "Primero inicializaremos nuestra canalización de datos. El Entrenador solo necesita un  DataLoader de PyTorch para los datos de entrenamiento/val/prueba. \n",
    "\n",
    "Podemos pasar directamente el objeto `dm` que hemos creado al Entrenador. Pero dado que necesitamos algunas muestras para nuestro `ImagePredictionLogger`, llamaremos manualmente a los métodos *prepare_data* y *setup*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575df58-12a7-4c57-a0bb-99735900c002",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia los datos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0b5830-b278-4409-a04a-f0f00ff51ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializa la canalización de los datos\n",
    "dm = CIFAR10DataModule(batch_size=32)\n",
    "# Para acceder al x_dataloader necesitamos llamar a prepare_data y setup.\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "# Muestras requeridas por el callback personalizado\n",
    "# ImagePredictionLogger para registrar predicciones de imágenes.  \n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f223c4-5ad7-46b8-9f88-f984d9904502",
   "metadata": {},
   "source": [
    "Solo necesitamos inicializar el modelo y nuestro logger favorito. Tenga en cuenta que hemos pasado checkpoint_callback por separado. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e05fba-eca3-4590-a344-ffff7994da9c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "812ed2f8-fec5-4855-b01d-ec282a1c3123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Backbone(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1600, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancia el modelo\n",
    "backbone = Backbone(dm.size(), dm.num_classes)\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05710d66-1223-453d-83b8-42b7ff49c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:244: UserWarning: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model = LitModel(backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34536afb-b003-4ed7-b866-dee50105f6b0",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia el trainer</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2670f39-1ac2-48b3-a8ee-55423dfbb05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f23d5694280>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f23d5694280>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Inicializa el logger wandb\n",
    "#wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')\n",
    "\n",
    "# instancia el trainer\n",
    "#trainer = pl.Trainer(gpus=4, precisión=16, limit_train_batches=0.5)\n",
    "max_epochs = 10\n",
    "acelerator = 'cpu'\n",
    "gpus = 0\n",
    "progress_bar_refresh_rate=1\n",
    "\n",
    "# reproducibilidad\n",
    "seed_everything(42, workers=True)\n",
    "# Al escribir la línea anterior es necesario escribir. \n",
    "# Caso contrario deterministic=False, que se tiene por defecto\n",
    "deterministic=True\n",
    "# Cuántas gpus usar\n",
    "# logger\n",
    "# logger=wandb_logger,\n",
    "logger = True, #TensorBoardLogger\n",
    "\n",
    "# ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"../\", save_top_k=2, monitor=\"val_loss\")\n",
    "\"\"\"\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     progress_bar_refresh_rate=progress_bar_refresh_rate, \n",
    "                     gpus=gpus, \n",
    "                     accelerator=acelerator,                     \n",
    "                     #logger=logger,\n",
    "                     callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\"),\n",
    "                                ImagePredictionLogger(val_samples)],\n",
    "                     checkpoint_callback=checkpoint_callback,\n",
    "                     deterministic=deterministic)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae5d0465-8a7d-4542-860d-d9b07bdd0fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=acelerator, max_epochs= max_epochs, \n",
    "                     deterministic=deterministic, gpus=gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f850465-4a7a-4da6-b98d-8bf178293907",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrena el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "165f41ea-411f-4afb-9ccc-1b94a2e34474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | backbone  | Backbone | 952 K \n",
      "1 | train_acc | Accuracy | 0     \n",
      "2 | valid_acc | Accuracy | 0     \n",
      "3 | test_acc  | Accuracy | 0     \n",
      "---------------------------------------\n",
      "952 K     Trainable params\n",
      "0         Non-trainable params\n",
      "952 K     Total params\n",
      "3.809     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc9d6c8b95e443ab406ce5046b81223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrena el modelo\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40b98b-522c-4d6d-895c-eb65c394862c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Evalua el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6781480-fdd4-483d-adcf-4c3b01ba34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalua el modelo en el conjunto de prueba retenido\n",
    "trainer.test()\n",
    "\n",
    "\n",
    "# Cierra el logger wandb.\n",
    "#wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36cf8658-4d09-40e3-a2b1-b713815c7e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "026de646-43d5-4f20-8c2e-54c7e55d1572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "***** TensorBoard Uploader *****\n",
      "\n",
      "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
      "the following directory:\n",
      "\n",
      "lightning_logs/\n",
      "\n",
      "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
      "data.\n",
      "\n",
      "Your use of this service is subject to Google's Terms of Service\n",
      "<https://policies.google.com/terms> and Privacy Policy\n",
      "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
      "<https://tensorboard.dev/policy/terms/>.\n",
      "\n",
      "This notice will not be shown again while you are logged into the uploader.\n",
      "To log out, run `tensorboard dev auth revoke`.\n",
      "\n",
      "Continue? (yes/NO) ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/bin/tensorboard\", line 10, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/main.py\", line 46, in run_main\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/absl/app.py\", line 312, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/absl/app.py\", line 258, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/program.py\", line 276, in main\n",
      "    return runner(self.flags) or 0\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 692, in run\n",
      "    return _run(flags, self._experiment_url_callback)\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 94, in _run\n",
      "    _prompt_for_user_ack(intent)\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 67, in _prompt_for_user_ack\n",
      "    response = input(\"Continue? (yes/NO) \")\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir \\\n",
    "    'lightning_logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f18387-1625-4061-ac5b-74cbad28bed2",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Modelo: la red neuronal</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967092f6-4706-4ee0-aa45-2f9c06015fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4711b2fb-c849-4ee5-bb0f-8ddcedff37c5",
   "metadata": {},
   "source": [
    "Es la red neuronal que se ha diseñado para resolver el problema que se tiene entre manos. Usualmente cosnstruimos una clase en la cual de defines los componentes que tendrá la red y que serás conjuntos de capas separadas de manera lógica. En Pytorch el modelo se implementa con el método `foreward`. En este método se determina exáctamente como funciona la red neuronal. Es el método de cálculo de la red neuronal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743b950-e042-4563-bac9-43a62ef4741a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrenador: pérdida optimizador, métricas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e02722-77f6-4e09-b09d-a25fe9254c74",
   "metadata": {},
   "source": [
    "Es el objeto que se encarga de hacer el entrenamiento de la red. El entrenador (trainer) usualmente tiene dos componentes escenciales:\n",
    "\n",
    "* `paso de optimización` en el cual se define lo que se debe hace en cada paso del proceso de optimización;\n",
    "* `ciclo de entrenamiento` que define como ocurrirá tos el entrenamiento: `número de épocas`,  `número de pasos de optimización por época`, `criterios de parada`,  lo que escribirá en el flufo de datos para seguimiento y evaluación (`writer`), y otras cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e123bb-41ee-4527-a013-75054a458530",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Instalar Pytorch-lightning</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88284dee-f27d-44d2-b1c4-8fecab39250d",
   "metadata": {},
   "source": [
    "En consola ejecute el siguiente comando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749ebbe-93c1-4f06-8623-29b7ee9bd00c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#conda install -c conda-forge pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3b9ad-e253-4a2f-97bf-c91b15a230fa",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Ejemplo de una plantilla para usar PyTorch Lightning</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ae178-4dcf-4dd4-897f-4ff332a380b8",
   "metadata": {},
   "source": [
    "Como ejemplo vamos a implementar un clasificador para los datos de MNIST, usando Lightning. Esta es una plantilla bastante general y está basada en la plantilla desarrollada por los autores de PyTorch Lightning. Puede revisar el código original en [Github](https://github.com/Lightning-AI/deep-learning-project-template/blob/master/project/lit_image_classifier.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb1368-831a-470d-b5a9-727baf7e0252",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Importa módulos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9adee6fd-279a-4408-acfd-1d7af590f848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchmetrics # métricas\n",
    "\n",
    "from pytorch_lightning import seed_everything # reproducibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef608b-d54d-4067-a813-af955f404d1d",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Clase Backbone: Nuestro modelo neuronal</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9bd477-d30d-4d08-8941-3f15f2fbbee0",
   "metadata": {},
   "source": [
    "Definimos nuestra red neuronal con la clase *Backbone* que deriva de  la clase `torch.nn.Module`. Al hacer esto, se gana toda la implementacion disponible en la clase Definimos nuestra red neuronal con la clase *Backbone* que deriva de  la clase *torch.nn.Module*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fb0ce4e-dae8-44b4-81a7-293f64f236d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modelo\n",
    "\n",
    "class Backbone(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(28 * 28, hidden_dim)\n",
    "        self.l2 = torch.nn.Linear(hidden_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.l1(x))\n",
    "        x = torch.relu(self.l2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73bb1c-750c-4682-a181-c2b80c340285",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Clase  LitClassifier Nuestra clase Lightning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba746771-5f8a-442b-8845-136d946c0b56",
   "metadata": {},
   "source": [
    "Esta clase heredada de `pl.LightningModule`  nos permite implementar los métodos que usará el entrenador para entrenr nuestra red. Es necesario especificar:\n",
    "\n",
    "* el método de cálculo d ela red (`forward`). En realidad podemos definir la red dentro de esta clase, pero para desacoplar la rede y hacerlo esta clase más genérica, mejor definimos el modleo por fuera. de esta clase pytorch-lightning;\n",
    "* el paso de entrenamiento, en el cual adicionalmente escribimos en el log para Tensorboard;\n",
    "* el paso de validación, que tambien escribe el en log para Tensorboard;\n",
    "* el paso de prueba, que tambien escribe el en log para Tensorboard; \n",
    "* se configura el optimizador;\n",
    "* las métricas de evaluación se definene en el constructor. Estas se van acumulando en cada paso de datos por el optimizador (trainig_step) y deben ser reinicializadas al final de cada época. De ésto último se encarga PyTorch-Lightning de manera automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8142e839-5c82-431d-9bdc-252a928ba128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, backbone, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        # modelo\n",
    "        self.backbone = backbone\n",
    "        # métricas\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "        self.test_acc = torchmetrics.Accuracy()\n",
    "        # rata de aprendizaje\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        # use forward para inferencia/predicciones\n",
    "        embedding = self.backbone(x)\n",
    "        return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # recibe batch de datos de entrenamiento\n",
    "        x, y = batch\n",
    "        # calcula el modelo(la red) con estos datos\n",
    "        y_hat = self.backbone(x)\n",
    "        # calcula la pérdida para estos datos\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        # sube la pérdida de entrenamiento al log \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        # actualiza las métricas para los datos de entrenamiento\n",
    "        self.train_acc(y_hat, y)\n",
    "        # sube las métricas de los datos de entrenamiento al log \n",
    "        self.log('train_acc', self.train_acc, on_step=True, on_epoch=True)\n",
    "        # retorna la pérdida\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # recibe batch de datos de valicación\n",
    "        x, y = batch\n",
    "        # calcula el modelo(la red) con estos datos\n",
    "        y_hat = self.backbone(x)\n",
    "        # calcula la pérdida para estos datos\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        # sube la pérdida de validación al log \n",
    "        self.log('valid_loss', loss, on_step=True, on_epoch=True)\n",
    "        # actualiza las métricas para los datos de validación\n",
    "        self.valid_acc(y_hat, y)\n",
    "        # sube las métricas de los datos de validación al log \n",
    "        self.log('valid_acc', self.valid_acc, on_step=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # recibe batch de datos de prueba\n",
    "        x, y = batch\n",
    "         # calcula el modelo(la red) con estos datos\n",
    "        y_hat = self.backbone(x)\n",
    "        # calcula la pérdida para estos datos\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        # sube la pérdida de prueba al log\n",
    "        self.log('test_loss', loss, on_epoch=True)\n",
    "         # actualiza las métricas para los datos de validación\n",
    "        self.test_acc(y_hat, y)\n",
    "        # sube las métricas de los datos de test al log \n",
    "        self.log('test_acc', self.test_acc,  on_epoch=True)\n",
    "        \n",
    "    def training_epoch_end(self, outs):\n",
    "        # define aqui las acciones al terminar una época en entrenamiento\n",
    "        pass\n",
    "    \n",
    "    def validation_epoch_endd(self, outs):\n",
    "        # define aqui las acciones al terminar una época en validación\n",
    "        pass\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40428aaf-6978-4dd5-9ed0-8328234ae5e9",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Datos: Datasets y Dataloaders</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "313a10d6-e2e5-4a88-9a5d-63b7856d70c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tamaño de los lotes de datos para el entrenamiento\n",
    "batch_size = 32\n",
    "# número de trabajadores para distribuir el trabajo de los dataloaders\n",
    "num_workers=4\n",
    "# Cuando mezclar los bloques de datos\n",
    "shuffle = True\n",
    "\n",
    "# creación de datasets desde Pytorch\n",
    "dataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = MNIST('', train=False, download=True, transform=transforms.ToTensor())\n",
    "mnist_train, mnist_val = random_split(dataset, [55000, 5000])\n",
    "\n",
    "# creación de los dataloaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
    "val_loader = DataLoader(mnist_val, batch_size=batch_size,num_workers=num_workers)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd1a9d1-a2f2-4348-9271-f74831b07959",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrenador</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57cf784-3f40-437b-9717-4c44ee8baaf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Instancia un entrenador que será una instancia de `Trainer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c61b2-3c60-4379-8549-f5ad426d856f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reproducibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9dc75-33aa-49c4-bb62-57294db230cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Para garantizar la reproducibilidad total de una ejecución a otra, debemos configurar semillas para generadores pseudoaleatorios y establecer una bandera determinista en *Trainer*. Usaremos *seed_everything*.\n",
    "\n",
    "Aquí *Workers=True* en *seed_everything()*, Lightning obtiene semillas únicas en todos los procesos y trabajadores del cargador de datos para generadores de números aleatorios *torch, numpy y stdlib*. Cuando está encendido, asegura que, p. los aumentos de datos no se repiten entre los trabajadores.\n",
    "\n",
    "También deberíamos notar: determinista=Verdadero en entrenador.\n",
    "\n",
    "Sin embargo, si solo planea establecer una semilla aleatoria para python, numpy, pytorch. y no usas pytorch lightning para entrenar. seed_everything() es de hecho.\n",
    "\n",
    "Porque seed_everything() se implementa de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc9fb3-9ebe-4cd4-a683-24095f2450d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b17643-8039-4e37-99a4-de14b3160035",
   "metadata": {},
   "source": [
    "#### Aceleradores de hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f503a-fa14-4f5d-877c-29830445f450",
   "metadata": {},
   "source": [
    "Con PyTorch Lightning es posible actualmente utilizar los siguientes tipos de aceleradores de hardware\n",
    "\n",
    "* GPU\n",
    "* TPU\n",
    "* IPU\n",
    "* HPU\n",
    "\n",
    "\n",
    "Tenga en cuenta que Pytorch no trabaja bien con múltiples cpu's y gpu's en entrenamiento. Nuestro consejo es:\n",
    "\n",
    "* Use multiples procesos (workers) en los dataloaders.\n",
    "* Use múliples gpu's en el Trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d53805-5e50-4da8-8052-3eddc119d621",
   "metadata": {},
   "source": [
    "#### Instanciando el entrenador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e991d548-81dc-4830-8416-bfa991877e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#trainer = pl.Trainer(gpus=4, precisión=16, limit_train_batches=0.5)\n",
    "max_epochs = 10\n",
    "acelerator = 'cpu'\n",
    "\n",
    "# reproducibilidad\n",
    "seed_everything(42, workers=True)\n",
    "# Al escribir la línea anterior es necesario escribir. \n",
    "# Caso contrario deterministic=False, que se tiene por defecto\n",
    "deterministic=True\n",
    "# Cuántas gpus usar\n",
    "gpus = 0 # depende de sus recursos\n",
    "\n",
    "trainer = pl.Trainer(accelerator=acelerator, max_epochs= max_epochs, \n",
    "                     deterministic=deterministic, gpus=gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733291c-3508-43f9-b71b-90fa8279e287",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrenamiento</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d93a64ab-5597-4367-90f8-44a755d8ecb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | backbone  | Backbone | 101 K \n",
      "1 | train_acc | Accuracy | 0     \n",
      "2 | valid_acc | Accuracy | 0     \n",
      "3 | test_acc  | Accuracy | 0     \n",
      "---------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30024c343d584fe085ab93b05083cc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_dim = 128\n",
    "\n",
    "model = LitClassifier(Backbone(hidden_dim=hidden_dim))\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3408f8-754d-43f4-881e-bd3a1e3f7265",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Prueba</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf20a332-ed3e-471a-a7be-6185492f60fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/alvaro/Documents/AprendizajeProfundo/Alejandría/Fundamentos_Programacion_03_08_22/Libro_Fundamentos_Programacion-main/Pytorch/Cuadernos/lightning_logs/version_0/checkpoints/epoch=9-step=17190.ckpt\n",
      "Loaded model weights from checkpoint at /home/alvaro/Documents/AprendizajeProfundo/Alejandría/Fundamentos_Programacion_03_08_22/Libro_Fundamentos_Programacion-main/Pytorch/Cuadernos/lightning_logs/version_0/checkpoints/epoch=9-step=17190.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aec4cdd92ed46238d62d4b639ac970d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_acc_epoch         0.8827000260353088\n",
      "        test_loss           0.3034259080886841\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'test_loss': 0.3034259080886841, 'test_acc_epoch': 0.8827000260353088}]\n"
     ]
    }
   ],
   "source": [
    "result = trainer.test(dataloaders=test_loader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a33585-cdec-424d-9a80-5ac0add3f382",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Lanzar Tensorboard para examinar los resultados</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b294305-ae71-429d-b63c-744064ab14bf",
   "metadata": {},
   "source": [
    "Terminamos esta lección ejecutando Tensorboard, la poderosa herramienta desarrolada por Google para visualziar los resultados del entrenamiento. Tensorboard tiene muchas características interesantes. Revise las lecciones de Tonsorboard para TensorFlow y PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8234665f-0c55-4463-861f-973aa51afad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9177), started 1:54:16 ago. (Use '!kill 9177' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928952fe-f9b5-4952-8d6a-2a28c00d386f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df420482-7230-4ffd-a9a3-12c9209d9eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
