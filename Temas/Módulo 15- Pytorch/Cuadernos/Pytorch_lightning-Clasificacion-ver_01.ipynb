{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b851f7-c675-4a2a-8932-59bf23db8edb",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F72585\">Clasificación de imágenes con Pytorch-lightning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d026e31-2c95-4a27-9da0-45331b02c810",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/trainer.png\" width=\"800\" height=\"800\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab698e08-33bf-45c2-8b16-306084b6bf78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02e2c2-0e22-4f37-8e7d-021c3bad1b04",
   "metadata": {},
   "source": [
    "En esta lección aprendemos como construir una modelo de clasificación de imágenes a color. Usaremos el framework [Pytorch-lightning](https://www.pytorchlightning.ai/) para construir el modelo y el conjunto de datos [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). La siguiente figura los tipos de datos que se usarán en esta lección. El contenido es una adaptación libre del tutorial [Image Classification using PyTorch Lightning](https://wandb.ai/wandb/wandb-lightning/reports/Image-Classification-using-PyTorch-Lightning--VmlldzoyODk1NzY) de [WandB](https://wandb.ai/site)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bcd09b-7e30-47ed-b57d-d232193cb03f",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/cifar10.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: [Universidad de Toronto-Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21048ee9-8cbe-49f6-b8f6-03261e092621",
   "metadata": {},
   "source": [
    "Para esta lección usaremos los datos CIFAR10 disponibles en los datasets de la librería [Torchvision](https://pytorch.org/vision/stable/index.html). Adicionalmente usaremos [Weights and bias-Wandb](https://wandb.ai/site), una plataforma moderna que puede apoyar para crear mejores modelos, más rápido con el seguimiento de experimentos, el control de versiones de conjuntos de datos y la gestión de modelos. WandB debe instalarse por separado, pero se incorpora a la librería `pytorch_lightning.loggers`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e37e37-4c2f-4c66-8712-884061bb7225",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Carga las librerías requeridas</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea02acc2-4c38-4778-9914-f27a297fdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Carga DataLoader para crear los dataloaders\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Librería Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# métricas\n",
    "import torchmetrics \n",
    "\n",
    "# reproductibilidad\n",
    "from pytorch_lightning import seed_everything # reproducibilidad\n",
    "\n",
    "# Carga WandBLogger para hacer seguimiento (tracking) del entrenamiento\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# carga el dataset CIFAR10\n",
    "import torchvision.datasets as datasets\n",
    "CIFAR10 = datasets.CIFAR10\n",
    "\n",
    "# callbacks\n",
    "from pytorch_lightning.callbacks import Callback \n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14327a65-1c99-4832-b575-49ae84437201",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Preparación de los datos</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962b5c6-b5b5-49fb-b7da-2ab6656c1ac0",
   "metadata": {},
   "source": [
    "Los `DataModule` son una forma de desacoplar enlaces relacionados con datos del LightningModule para que pueda desarrollar modelos agnósticos de conjuntos de datos. En otra palabras, con DataModule puede preparar los datos por fuera del módulo de entrenamiento, de tal manera que peude cambiar sus datos sin tocar el módulo de entrenamiento.\n",
    "\n",
    "Con *DataModule* podemos organiza la canalización de datos en una clase compartible y reutilizable. Un módulo de datos encapsula los cinco pasos involucrados en el procesamiento de datos en PyTorch:\n",
    "\n",
    "* Descargar/tokenizar/procesar.\n",
    "* Limpiar y (tal vez) guardar en el disco.\n",
    "* Cargar dentro del conjunto de datos.\n",
    "* Aplicar transformaciones (rotar, tokenizar, etc.).\n",
    "* Envolver dentro de un DataLoader.\n",
    "\n",
    "\n",
    "Obtenga más información sobre los módulos de datos [aquí](https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html). Construyamos un módulo de datos para el conjunto de datos Cifar-10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c9bc5-bf5d-41bc-a8b6-7d15ee9c1e24",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Canalización (pipeline) de los datos con DataModule</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d42586-b397-470c-8ccb-41a58581ba35",
   "metadata": {},
   "source": [
    "Construimos una clase derivada de `LightningDataModule` específica para CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e554bb-eeb6-47b2-9820-883b2751fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, batch_size, data_dir: str = './', num_workers=4):\n",
    "        \"\"\"\n",
    "        Pasaremos los hiperparámetros necesarios para nuestra canalización de datos\n",
    "        utilizando el método __init__. También definiremos la canalización de \n",
    "        transformación de datos aquí.\n",
    "        params:\n",
    "        datadir\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        self.dims = (3, 32, 32)\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Aquí es donde definiremos la lógica para descargar nuestro conjunto de datos. \n",
    "        Estamos utilizando la clase de conjunto de datos CIFAR10 de torchvision para descargar.\n",
    "        Use este método para hacer cosas que podrían escribirse en el disco \n",
    "        o que deben hacerse solo desde una única GPU en configuraciones distribuidas. \n",
    "        No haga ninguna asignación de estado en esta función \n",
    "        (es decir, self.alguna_cosa = ...).\n",
    "        \"\"\"\n",
    "        # descarga\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Aquí es donde cargaremos los datos del archivo y prepararemos \n",
    "        los conjuntos de datos del tensor PyTorch para cada división de los datos. \n",
    "        La división de datos es por lo tanto reproducible. \n",
    "        Este método espera un argumento de etapa (stage) que se utiliza para separar \n",
    "        la lógica de 'entrenamiento' y de 'prueba'. \n",
    "        Esto es útil si no queremos cargar todo el conjunto de datos a la vez. \n",
    "        Las operaciones de datos que queremos realizar en cada GPU se definen aquí. \n",
    "        Esto incluye aplicar la transformación al conjunto de datos del tensor de PyTorch.\n",
    "        \"\"\"        \n",
    "        # Asigna datos a los datasets de entrenamiento/validación  \n",
    "        # para uso en los dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Asigna dataset de prueba para uso en los  dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    # Métodos para crear los dataloaders        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=self.batch_size, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ded3e1-3cf2-4f1e-88a4-def6bbf41d45",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Devolución de llamadas (Callbacks)</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfeab5-2add-46f5-913e-e56b3c479883",
   "metadata": {},
   "source": [
    "Una devolución de llamada o `callback` es un programa autónomo que se puede reutilizar en todos los proyectos. PyTorch Lightning viene con algunos callbacks integrados que se usan regularmente.\n",
    "Obtenga más información sobre callbacks en PyTorch Lightning [aquí](https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a454fe0c-98d7-4d59-b0ab-b590c20b6344",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Devoluciones  de llamada integrados</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a219f-6c4d-457e-b826-304cb432d4c1",
   "metadata": {},
   "source": [
    "En este tutorial, utilizaremos las devoluciones de llamada integradas de parada anticipada `Early Stopping` y punto de control `checkpoint` de modelo. Estos callback se pueden pasar al entrenador (`Trainer`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c264f-39f7-4c9e-bdfb-4c5054d4b5b4",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Devoluciones de llamada personalizados</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d48f6-0cce-4817-b1d4-d2a79bf88936",
   "metadata": {},
   "source": [
    "Si está familiarizado con la devolución de llamada personalizada de `Keras`, la capacidad de hacer lo mismo en su canalización de PyTorch es solo una cereza del pastel.\n",
    "\n",
    "Dado que estamos realizando una clasificación de imágenes, la capacidad de visualizar las predicciones del modelo en algunas muestras de imágenes puede resultar útil. Esto en forma de callback puede ayudar a depurar el modelo en una etapa temprana. Así que vamos a implementar un callback personalizado para tal fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab2ec98-0a0c-4601-bbd0-b4bd0478f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePredictionLogger(Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        \"\"\"\n",
    "        ImagePredictionLogger es una subclase de la clase Callback de PyTorch Lightning. \n",
    "        params:\n",
    "        val_samples: es una tupla de imágenes y etiquetas. \n",
    "        num_samples: es el número de imágenes que se registrarán en el panel de control de W&B.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        \"\"\"\n",
    "        Este método es llamado cuando finaliza la época de validación. \n",
    "        Se necesitan dos argumentos: \n",
    "        trainer: entrenador del modelo\n",
    "        pl_module: módulo del modelo\n",
    "        Ambios parámetros son pasadoa autompaticamente por el trainer.\n",
    "        Al usar trainer.logger.experimental podemos usar todas las funciones disponibles por Pesos y sesgos.\n",
    "        \"\"\"\n",
    "        # Trasladar los tensors a CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Obtener la predicción del modelo\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)\n",
    "        # Pasa la imágenes al logger como  wandb Image\n",
    "        trainer.logger.experiment.log({\n",
    "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
    "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
    "                                                 preds[:self.num_samples], \n",
    "                                                 val_labels[:self.num_samples])]\n",
    "            })\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc7bd8-0cec-488f-b0f8-20eb795744c7",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Define el modelo: backbone</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919af584-f434-4df5-8fc3-a8a1c4baea9c",
   "metadata": {},
   "source": [
    "Esta clase define el modelo de red neuronal que usaremos para nuestra investigación. Aunque en ocasiones elm modelo hacer parte del sistema que definimos en la siguiente sección, desacoplar el código de esta forma lo hace más agnóstico y fácil de reutilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f6bdef-6a5c-44c7-a1e1-325837a2002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(torch.nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        Modelo neorual de clasificación paar los datos CIFAR10.\n",
    "        parámetros:\n",
    "        input_shape: tamaño de los tensores de entrada\n",
    "        num_classes: número de clases en el problema\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # log hyperparameters\n",
    "        #self.save_hyperparameters()\n",
    "        #self.learning_rate = learning_rate\n",
    "        \n",
    "        # bloque convolucional: cuerpo de la red\n",
    "        \"\"\"\n",
    "        CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, \n",
    "        padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 1)\n",
    "        \"\"\"\n",
    "        CLASS torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, \n",
    "        return_indices=False, ceil_mode=False)\n",
    "        \"\"\"\n",
    "        self.pool1 = torch.nn.MaxPool2d(2)\n",
    "        self.pool2 = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "        # Calcula el tamaño de salida del bloque convolucional\n",
    "        n_sizes = self._get_conv_output(input_shape)\n",
    "        \n",
    "        # bloque Lineal: cabeza de la red\n",
    "        self.fc1 = nn.Linear(n_sizes, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    # métodos auxiliares para calcular el tamaño de salida\n",
    "    # del bloque convolucion. Se requiere ara poder configurar \n",
    "    # totalmente la red. No requrido en Keras\n",
    "    def _get_conv_output(self, shape):\n",
    "        \"\"\"\n",
    "        devuelve el tamaño del tensor de salida del bloque conv.\n",
    "        \"\"\"\n",
    "        batch_size = 1\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self._forward_features(input) \n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "        \n",
    "    def _forward_features(self, x):\n",
    "        \"\"\"\n",
    "        retorna el tensor de características de la salida el bloque conv\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        return x\n",
    "    \n",
    "    # modelo\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Cálculo del modelo. Corre cada vez que se llama al modelo\n",
    "        \"\"\"\n",
    "        # calcula el bloque convolucional\n",
    "        x = self._forward_features(x)\n",
    "        # aplana el tensor de salida del bloque convolucional\n",
    "        x = x.view(x.size(0), -1) # x.size(0) es el tamaño del lote de datos\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1) # log softmax es más estable que softmax\n",
    "       \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3942a-b103-4171-ac33-809695545fb7",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">LightningModule - Definición del sistema</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea586c-1687-4d56-8d45-1e7057049bd3",
   "metadata": {},
   "source": [
    "`LightningModule` define un sistema y no un modelo. Aquí, un sistema agrupa todo el código de investigación en una sola clase para que sea autónomo. LightningModule organiza su código PyTorch en 5 secciones:\n",
    "\n",
    "* Bucle de entranamiento (training_step)\n",
    "* Bucle de validación (validation_step)\n",
    "* Bucle de prueba (test_step)\n",
    "* Optimizadores (configure_optimizers)\n",
    "\n",
    "\n",
    "Por lo tanto, se puede construir un modelo agnóstico del conjunto de datos que se puede compartir fácilmente. Construyamos un sistema para la clasificación Cifar-10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c8d5a6b-1c04-47e1-952a-ac6378e428dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self,  backbone, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "        # activa log para almacenar los hiperparámetros\n",
    "        self.save_hyperparameters()\n",
    "        # modelo\n",
    "        self.backbone = backbone\n",
    "        # rata  de aprendizaje para el optimizador\n",
    "        self.learning_rate = learning_rate\n",
    "        # métricas\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "        self.test_acc = torchmetrics.Accuracy()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Lightning automatiza la mayor parte del entrenamiento para nosotros, \n",
    "        la época y las iteraciones por lotes, todo lo que necesitamos mantener \n",
    "        es la lógica del paso de entrenamiento. El método training_step requiere argumentos \n",
    "        batch y batch_idx que el Entrenador pasa automáticamente. \n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y) # entropía cruzada: negative log likelihood\n",
    "        \n",
    "        # training metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.train_acc(preds, y)\n",
    "        self.log('perdida_entrenamiento', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('precision_entrenamiento', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        el ciclo de validación se puede implementar sobrescribiendo este método \n",
    "        de LightningModule\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.valid_acc(preds, y)\n",
    "        self.log('perdida_validacion', loss, prog_bar=True)\n",
    "        self.log('precision_validacion', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Este método similar al ciclo de validación. \n",
    "        La única diferencia es que en prueba solo se llama \n",
    "        cuando se usa trainer.test(). \n",
    "        Las métricas se registran automáticamente por épocas.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.test_acc(preds, y)\n",
    "        self.log('perdida_test', loss, prog_bar=True)\n",
    "        self.log('precision_test', acc, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Podemos definir nuestro optimizador y programadores \n",
    "        de tasa de aprendizaje usando el método \n",
    "        configure_optimizer. \n",
    "        Incluso se pueden definir múltiples optimizadores \n",
    "        como en el caso de las GAN.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.backbone.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff167f-641b-4454-9769-5e95be9af68a",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Entrenamiento y Evaluación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fc9a4-d3e4-48d6-968c-f111578fe4ae",
   "metadata": {},
   "source": [
    "Ahora que organizamos nuestra canalización de datos con `DataModule` y modelamos la arquitectura del modelo con `nn.Module` y el ciclo de entrenamiento con `LightningModule`, PyTorch Lightning `Trainer` automatiza todo lo demás por nosotros.\n",
    "\n",
    "El Entrenador automatiza:\n",
    "\n",
    "* Iteración de época y lote\n",
    "* Llamada de `optimizer.step()`, `backward`, `zero_grad()`\n",
    "* Llamada de `.eval()`, habilitación/deshabilitación de gradientes\n",
    "* Guardar y cargar pesos\n",
    "* Registro de pesos y sesgos\n",
    "* Soporte de entrenamiento multi-GPU\n",
    "* Soporte de TPU\n",
    "* soporte de entrenamiento de 16 bits\n",
    "\n",
    "\n",
    "Primero inicializaremos nuestra canalización de datos. El Entrenador solo necesita un  DataLoader de PyTorch para los datos de entrenamiento/val/prueba. \n",
    "\n",
    "Podemos pasar directamente el objeto `dm` que hemos creado al Entrenador. Pero dado que necesitamos algunas muestras para nuestro `ImagePredictionLogger`, llamaremos manualmente a los métodos *prepare_data* y *setup*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575df58-12a7-4c57-a0bb-99735900c002",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia los datos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0b5830-b278-4409-a04a-f0f00ff51ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializa la canalización de los datos\n",
    "dm = CIFAR10DataModule(batch_size=32)\n",
    "# Para acceder al x_dataloader necesitamos llamar a prepare_data y setup.\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "# Muestras requeridas por el callback personalizado\n",
    "# ImagePredictionLogger para registrar predicciones de imágenes.  \n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f223c4-5ad7-46b8-9f88-f984d9904502",
   "metadata": {},
   "source": [
    "Solo necesitamos inicializar el modelo y nuestro logger favorito. Tenga en cuenta que hemos pasado checkpoint_callback por separado. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e05fba-eca3-4590-a344-ffff7994da9c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "812ed2f8-fec5-4855-b01d-ec282a1c3123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Backbone(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1600, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instancia el modelo\n",
    "backbone = Backbone(dm.size(), dm.num_classes)\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05710d66-1223-453d-83b8-42b7ff49c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:244: UserWarning: Attribute 'backbone' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['backbone'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model = LitModel(backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34536afb-b003-4ed7-b866-dee50105f6b0",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia el trainer</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2670f39-1ac2-48b3-a8ee-55423dfbb05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f23d5694280>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f23d5694280>)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Inicializa el logger wandb\n",
    "#wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')\n",
    "\n",
    "# instancia el trainer\n",
    "#trainer = pl.Trainer(gpus=4, precisión=16, limit_train_batches=0.5)\n",
    "max_epochs = 10\n",
    "acelerator = 'cpu'\n",
    "gpus = 0\n",
    "progress_bar_refresh_rate=1\n",
    "\n",
    "# reproducibilidad\n",
    "seed_everything(42, workers=True)\n",
    "# Al escribir la línea anterior es necesario escribir. \n",
    "# Caso contrario deterministic=False, que se tiene por defecto\n",
    "deterministic=True\n",
    "# Cuántas gpus usar\n",
    "# logger\n",
    "# logger=wandb_logger,\n",
    "logger = True, #TensorBoardLogger\n",
    "\n",
    "# ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"../\", save_top_k=2, monitor=\"val_loss\")\n",
    "\"\"\"\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     progress_bar_refresh_rate=progress_bar_refresh_rate, \n",
    "                     gpus=gpus, \n",
    "                     accelerator=acelerator,                     \n",
    "                     #logger=logger,\n",
    "                     callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\"),\n",
    "                                ImagePredictionLogger(val_samples)],\n",
    "                     checkpoint_callback=checkpoint_callback,\n",
    "                     deterministic=deterministic)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae5d0465-8a7d-4542-860d-d9b07bdd0fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=acelerator, max_epochs= max_epochs, \n",
    "                     deterministic=deterministic, gpus=gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f850465-4a7a-4da6-b98d-8bf178293907",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrena el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "165f41ea-411f-4afb-9ccc-1b94a2e34474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | backbone  | Backbone | 952 K \n",
      "1 | train_acc | Accuracy | 0     \n",
      "2 | valid_acc | Accuracy | 0     \n",
      "3 | test_acc  | Accuracy | 0     \n",
      "---------------------------------------\n",
      "952 K     Trainable params\n",
      "0         Non-trainable params\n",
      "952 K     Total params\n",
      "3.809     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc9d6c8b95e443ab406ce5046b81223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrena el modelo\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40b98b-522c-4d6d-895c-eb65c394862c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Evalua el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6781480-fdd4-483d-adcf-4c3b01ba34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalua el modelo en el conjunto de prueba retenido\n",
    "trainer.test()\n",
    "\n",
    "\n",
    "# Cierra el logger wandb.\n",
    "#wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36cf8658-4d09-40e3-a2b1-b713815c7e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "026de646-43d5-4f20-8c2e-54c7e55d1572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "***** TensorBoard Uploader *****\n",
      "\n",
      "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
      "the following directory:\n",
      "\n",
      "lightning_logs/\n",
      "\n",
      "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
      "data.\n",
      "\n",
      "Your use of this service is subject to Google's Terms of Service\n",
      "<https://policies.google.com/terms> and Privacy Policy\n",
      "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
      "<https://tensorboard.dev/policy/terms/>.\n",
      "\n",
      "This notice will not be shown again while you are logged into the uploader.\n",
      "To log out, run `tensorboard dev auth revoke`.\n",
      "\n",
      "Continue? (yes/NO) ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/bin/tensorboard\", line 10, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/main.py\", line 46, in run_main\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/absl/app.py\", line 312, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/absl/app.py\", line 258, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/program.py\", line 276, in main\n",
      "    return runner(self.flags) or 0\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 692, in run\n",
      "    return _run(flags, self._experiment_url_callback)\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 94, in _run\n",
      "    _prompt_for_user_ack(intent)\n",
      "  File \"/home/alvaro/anaconda3/envs/ligthning/lib/python3.9/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 67, in _prompt_for_user_ack\n",
      "    response = input(\"Continue? (yes/NO) \")\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir \\\n",
    "    'lightning_logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928952fe-f9b5-4952-8d6a-2a28c00d386f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df420482-7230-4ffd-a9a3-12c9209d9eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
