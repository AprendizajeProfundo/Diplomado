{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"><center>Probabilidad Conjunta y Entropía Cruzada</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Alejandria/main/Archivos_Generales/Imagenes/Dardo.jpg\" width=\"600\" height=\"400\" align=\"center\" /> \n",
    "</center>   \n",
    "</figure>\n",
    "<center>\n",
    "\n",
    "Fuente: [Pexels](https://www.pexels.com/es-es/foto/dardo-rojo-y-blanco-en-tablero-de-dardos-262438/)\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "1. Camilo José Torres Jiménez, Msc, cjtorresj@unal.edu.co\n",
    "1. Daniel  Montenegro, Msc, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Asesora Medios y Marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com\n",
    "5. Jessica López Mejía, jelopezme@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Jefe Jurídica</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Paula Andrea Guzmán, guzmancruz.paula@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Coordinador Jurídico</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. David Fuentes, fuentesd065@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Desarrolladores Principales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Dairo Moreno, damoralesj@unal.edu.co\n",
    "9. Joan Castro, jocastroc@unal.edu.co\n",
    "10. Bryan Riveros, briveros@unal.edu.co\n",
    "11. Rosmer Vargas, rovargasc@unal.edu.co\n",
    "12. Venus Puertas, vpuertasg@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Expertos en Bases de Datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Giovvani Barrera, udgiovanni@gmail.com\n",
    "14. Camilo Chitivo, cchitivo@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [El ejemplo de la moneda cargada](#El-ejemplo-de-la-moneda-cargada)\n",
    "* [Función de probabilidad conjunta](#Función-de-probabilidad-conjunta)\n",
    "* [Distribución marginal](#Distribución-marginal)\n",
    "* [Correlación](#Correlación)\n",
    "* [Información mutua](#Información-mutua)\n",
    "* [Entropía cruzada](#Entropía-cruzada)\n",
    "* [Entropía cruzada en aprendizaje de máquinas](#Entropía-cruzada-en-aprendizaje-de-máquinas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección se introduce el concepto de función de probabilidad conjunta. Además se introducen los conceptos de correlación, información mutua y entropía cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">El ejemplo de la moneda cargada</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el ejemplo de la Variable Bernoulli de la lección de variables-aleatorias. En realidad el ejemplo puede reescribirse usando como experimento el lanzamiento de una moneda cargada. Suponemos dos posibles resultados cara $(g=1)$ y sello $(g=0)$. Suponemos además que $\\text{Prob}[g=1]= 0.6$ y por tanto $\\text{Prob}[g=0]= 0.4$. El experimento consiste en lanzar tres veces la moneda cargada y anotar el resultado: cara (1) o sello (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definimos dos variables aleatorias. La primera  que llamaremos $X$, corresponde a contar el número de caras que salen. De acuerdo con los resultados de la lección de variables-aleatorias, la función de probabilidad de $X$, denotada $p_X$ es dada por extensión de  la siguiente forma:\n",
    "\n",
    "|Valor |Experimentos| probabilidad cada experimento| probabilidad para este valor de $X$| total|\n",
    "|---|---|---| ---|---|\n",
    "|0| 000| $0.4\\times 0.4 \\times 0.4$|0.064|0.064|\n",
    "|1| 100| $0.6\\times 0.4 \\times 0.4$|0.096||\n",
    "|1| 010| $0.4 \\times 0.6\\times 0.4$|0.096||\n",
    "|1| 001| $0.4 \\times 0.4\\times 0.6$|0.096|0.288|\n",
    "|2| 110| $0.6\\times 0.6 \\times 0.4$|0.144||\n",
    "|2| 011| $0.4 \\times 0.6\\times 0.6$|0.144||\n",
    "|2| 101| $0.6 \\times 0.4 \\times 0.6$|0.144|0.432|\n",
    "|3| 111| $0.6 \\times 0.6\\times 0.6$|0.216|0.216 |\n",
    "\n",
    "Recuerde que obtuvimos que $\\mathbb{E}[X]=1.8$.  Además se tiene que $\\text{Var}[X]=0.72$ y $\\sigma_X = 0.849$. Efectivamente tenemos que\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "X &= \\{0, 1, 2, 3\\},\\\\\n",
    "p &= \\{0.064, 0.288, 0.432, 0.216\\},\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "y\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[X] &= 0 \\times 0.064 + 1\\times 0.288 + 2\\times 0.432 + 3 \\times 0.216 = 1.8,\\\\\n",
    "\\text{Var}[X] & = (0-1.8)^2 \\times 0.064 + (1-1.8)^2 \\times 0.288 + (2-1.8)^2 \\times 0.432 + (3-1.8)^2 \\times 0.216 = 0.72\\\\\n",
    "\\sigma_X &=  \\sqrt{\\text{Var}[X]} = 0.849\n",
    "\\end{align*}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Ejercicio</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por favor verifique que si $X\\sim \\text{Binom}(N,\\pi)$, entonces:\n",
    "\n",
    "1. $\\mathbb{E}[X]=N\\pi$ \n",
    "2. $\\text{Var}[X]=N\\pi(1-\\pi)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda variable que llamaremos $Y$ se define\n",
    "como sigue:\n",
    "\n",
    "$$\n",
    "Y = \\begin{cases}  0, &\\text{ si no sale ninguna cara}, \\\\\n",
    "1, &\\text{ si salen una o dos caras},\\\\\n",
    "-1, &\\text{ si salen tres caras}.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de probabilidad de $Y$ , denotada  $p_Y$  es dada por extensión de la siguiente forma:\n",
    "\n",
    "|Valor |Experimentos| probabilidad cada experimento| probabilidad para este valor de $Y$| total|\n",
    "|---|---|---| ---|---|\n",
    "|0| 000| $0.4\\times 0.4 \\times 0.4$|0.064|0.064|\n",
    "|1| 100| $0.6\\times 0.4 \\times 0.4$|0.096||\n",
    "|1| 010| $0.4 \\times 0.6\\times 0.4$|0.096||\n",
    "|1| 001| $0.4 \\times 0.4\\times 0.6$|0.096||\n",
    "|1| 110| $0.6\\times 0.6 \\times 0.4$|0.144||\n",
    "|1| 011| $0.4 \\times 0.6\\times 0.6$|0.144||\n",
    "|1| 101| $0.6 \\times 0.4 \\times 0.6$|0.144|0.720|\n",
    "|-1| 111| $0.6 \\times 0.6\\times 0.6$|0.216|0.216 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerde que :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[Y] &= 0\\times 0.064 +  1\\times 0.72 +(-1)\\times 0.216 = 0.504\\\\\n",
    "\\text{Var}[Y] &=  (0-0.504)^2\\times 0.064 + (1-0.504)^2\\times 0.720 + (-1-0.504)^2\\times 0.216 = 0.682\\\\\n",
    "\\sigma_Y &= 0.826\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Función de probabilidad conjunta</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abordemos el problema de determinar como está relacionadas (asociadas) estas dos variables. Para empezar observe la siguiente tabla que muestra como coocurren los valores de las dos variables aleatorias:\n",
    "\n",
    "\n",
    "|X/Y|0|1|-1|\n",
    "|---|---|---|---|\n",
    "|0|000|---------|---|\n",
    "|1|---|100 010 001|---|\n",
    "|2|---|101 110 011|---|\n",
    "|3|---|---------|111|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celdas vacias indican parejas de valores $(x,y)$ que no pueden ocurrir. La función de probabilidad conjunta de la variables $X$ y $Y$ se define como la función de dos variables dada por:\n",
    "\n",
    "$$\n",
    "p_{XY}(x,y) = \\text{Prob}(X=x, Y=y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro ejemplo, la función de probabilidad conjunta es definida por extensión de la siguiente forma\n",
    "\n",
    "|X/Y|0|1|-1|$P_X$|\n",
    "|---|---|---|---|---|\n",
    "|0|0.064|0.000|0.000|0.064|\n",
    "|1|0.000|0.288|0.000|0.288|\n",
    "|2|0.000|0.432|0.000|0.432|\n",
    "|3|0.000|0.000| 0.216|0.216|\n",
    "|$P_Y$|0.064|0.720| 0.216|1.000|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Distribución marginal</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que en la última fila de la tabla se recupera la función de probabilidad de $Y$. De la misma forma, en la última columna  se recupera la función de probabilidad de $X$. En este contexto de funciones de probabilidad conjunta, las funciones $P_X$ y $P_Y$ se llaman funciones de probabilidad marginales. En este caso, cada valor corresponde a la suma de la fila o columna correspondiente. La celda inferior derecha muestra la suma total de probabilidades, que claro debe ser 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Correlación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El concepto de correlación está completamente asociado a la función de distribución conjunta de dos variables aleatorias. Esencialmente, la correlación mide como cambian simultáneamente las dos variables aleatorias. Supongamos que $X$ y $Y$ son variables aleatorias definidas sobre el mismo espacio muestral como en el ejemplo anterior.\n",
    "\n",
    "Además supongamos que la media y la desviación estándar de cada variable se denotan como $\\mu_X$, $\\sigma_X$ y $\\mu_Y$ y $\\sigma_Y$ respectivamente. Entonces se tiene que la correlación entre las dos variables aleatorias es dada por:\n",
    "\n",
    "$$\n",
    "Cor(X,Y) = \\mathbb{E}\\left[\\frac{(X-\\mu_X)}{\\sigma_X}\\frac{(Y-\\mu_Y)}{\\sigma_Y} \\right]= \\frac{\\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)}{\\sigma_X \\sigma_Y}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Ejercicio</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular la correlación de las variables del ejemplo anterior. Usaremos la segunda ecuación. La igualdad puede ser verificada sin mucha dificutad.\n",
    "\n",
    "La única cantidad que no tenemos aún es $\\mathbb{E}(XY)$, la cual puede calcularse como sigue:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(XY) = \\sum_i \\sum_j x_iy_j P_{XY}(x_i,y_j)\n",
    "$$\n",
    "\n",
    "En nuestro ejemplo tenemos que:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(XY) =  1 \\times 1 \\times P_{XY}(1,1) + 2 \\times 1 \\times P_{XY}(2,1) + 3\\times (-1)\\times P_{XY}(3,-1) = 0.504\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En consecuencia se tiene que:\n",
    "\n",
    "$$\n",
    "Cor(X,Y) = \\frac{0.504 - 1.8\\times 0.504}{0.849\\times 0.826} = -0.575\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Información mutua</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este concepto es el análogo a la correlación, pero en este caso desde la\n",
    "teoría de la información de Shannon.\n",
    "\n",
    "Para dos distribuciones (variables aleatorias $X$ y $Y$) discretas conjuntamente distribuidas,\n",
    "la información conjunta se define por:\n",
    "\n",
    "$$\n",
    "\\mathfrak{m}(X,Y)=\\sum_{y\\in Y}\\sum_{x\\in X}P_{XY}(x,y) \\log \\left(\\frac {P_{XY}(x,y)}{P_X(x)P_{Y}(y)}\\right) = \\mathbb{E}_{XY}[\\log P_{XY} - \\log P_X\\log P_Y]\n",
    "$$\n",
    "\n",
    "Observe que si las variables aleatorias son independientes, entonces $\\mathfrak{m}(X,Y)=0$, porque $\\log P_{XY} = \\log P_X\\log P_Y$.\n",
    "\n",
    "Por otro lado, Si $X=Y$, se tiene que $\\mathfrak{m}(X,X) =  H(X)$, es decir, la entropía de $X$.\n",
    "\n",
    "La información mutua se puede calcular siempre, teniendo en cuenta el convenio $0 \\log 0 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos la tabla de probabilidad conjunta del ejemplo:\n",
    "\n",
    "|X/Y|0|1|-1|$P_X$|\n",
    "|---|---|---|---|---|\n",
    "|0|0.064|0.000|0.000|0.064|\n",
    "|1|0.000|0.288|0.000|0.288|\n",
    "|2|0.000|0.432|0.000|0.432|\n",
    "|3|0.000|0.000| 0.216|0.216|\n",
    "|$P_Y$|0.064|0.720| 0.216|1.000|\n",
    "\n",
    "\n",
    "Entonces en  este caso tenemos que:\n",
    "\n",
    "$$\\mathfrak{m}(X,Y) = 0.064 \\log\\tfrac{0.064}{0.064\\times 0.064} +0.288 \\log \\tfrac{ 0.288}{0.288\\times 0.72} +0.432\\log\\tfrac{0.432}{0.432\\times 0.72} + 0.216 \\log \\tfrac{0.216}{0.216*0.216} = 0.5032.\n",
    "$$\n",
    "\n",
    "La información mutua siempre es positiva e indica la cantidad de información que las dos variables cargan conjuntamente, la una de la otra.\n",
    "\n",
    "La siguiente línea ilustra el cálculo usando Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5032013743418469"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(0.064)*np.log(0.064/(0.064*.064)) +(0.288)*np.log(0.288/(0.288*0.724)) \\\n",
    "+(0.432)*np.log(0.432/(0.432*0.72) + 0.216*np.log(0.216/(0.216*0.216)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Entropía cruzada</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección vamos a suponer que tenemos dos distribuciones de probabilidad discretas $P$ y $Q$. De momento solamente nos intersan las probabilidades de cada distribución, tomadas en el mismo orden. Así, supondremos que $P=\\{p_1, \\ldots, p_N\\}$ y $Q=\\{q_1\\ldots, q_N\\}$.\n",
    "\n",
    "\n",
    "En teoría de la información, la entropía cruzada entre dos distribuciones de probabilidad  $P$ y $Q$ definidas sobre el mismo espacio muestral (el mismo conjunto de eventos) mide el número promedio de bits (o nats) necesarios para identificar una distribución con la otra. \n",
    "\n",
    "En la práctica, si se considera la distribución $P$ como la distribución verdadera o de referencia  y a $Q$ como una distribución aproximante, entonces la entropía cruzada se define mediante:\n",
    "\n",
    "\n",
    "$$\n",
    "H(P,Q) = - E_P[ \\log Q]  = - (p_1\\log q_1 + p_2\\log q_2+ \\cdots + p_n\\log q_n)\n",
    "$$\n",
    "\n",
    "Observe que la definición no es simétrica, es decir $H(P,Q) \\ne H(Q,P)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Interpretación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la interpretación, esta es una medida de que tanto difiere $Q$ de $P$, medido en bits o nats. Entonces entre menor es este valor, mejor es la aproximación. Observe que si $P=Q$, entonces se tiene que\n",
    "\n",
    "$$\n",
    "H(P,P) = - (p_1\\log p_1 + p_2\\log p_2+ \\cdots + p_n\\log p_n) = H(P)= \\text{entropía}(P).\n",
    "$$\n",
    "\n",
    "Esto significa que el menor valor que puede tomar la entropia cruzada es exáctamente igual al valor de la entropía de la distribución de referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Ejercicio</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar el concepto, calculemos la entropía cruzada entre las distribuciones binomiales $ P=Bin(3, 0.3)$, $Q_1=Bin(3, 0.4)$ y $Q_2=Bin(3,0.7)$.\n",
    "\n",
    "Vamos considerar a la distribución $P$ como la verdadera y a $Q_1$ y $Q_2$ como aproximantes. Usted debe sospechar que $Q_1$ es mejor aproximante que $Q_2$.\n",
    "\n",
    "Veámos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.343 0.441 0.189 0.027]\n",
      "[0.216 0.432 0.288 0.064]\n",
      "[0.027 0.189 0.441 0.343]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N, p, q1, q2  = 3, 0.3, 0.4, 0.7\n",
    "\n",
    "P = [binom.pmf(k,N,p) for k in range(N+1)]\n",
    "Q1 = [binom.pmf(k,N,q1) for k in range(N+1)]\n",
    "Q2 = [binom.pmf(k,N,q2) for k in range(N+1)]\n",
    "\n",
    "print(np.round(P,3))\n",
    "print(np.round(Q1,3))\n",
    "print(np.round(Q2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(P,Q1)=  1.2052697267344104\n",
      "H(P,Q2)=  2.157224596768415\n"
     ]
    }
   ],
   "source": [
    "H_P_Q1 = -np.sum(P*np.log(Q1))\n",
    "H_P_Q2 = -np.sum(P*np.log(Q2))\n",
    "\n",
    "print('H(P,Q1)= ', H_P_Q1 )\n",
    "print('H(P,Q2)= ', H_P_Q2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente un gráfico de las tres distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax = axes.ravel()\n",
    "label = ['0','1','2','3']\n",
    "\n",
    "ax[0].bar(label, P, color = 'orange', edgecolor='blue',width=1)\n",
    "ax[0].set_title(\"Distribución P\")\n",
    "\n",
    "ax[1].bar(label, Q1, color = 'blue', edgecolor='red',width=1)\n",
    "ax[1].set_title(\"Distribución Q1\")\n",
    "\n",
    "ax[2].bar(label, Q2, color = 'red', edgecolor='blue',width=1)\n",
    "ax[2].set_title(\"Distribución Q2\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Entropía cruzada en aprendizaje de máquinas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que una red neuronal de clasificación transforma un tensor de entrada en  una distribución. Tal distribución indica las probabilidades de que el tensor de entrada pertenezca a cada una de las clases.\n",
    "\n",
    "En el entrenamiento se busca encontrar los pesos sinápticos que minimizan conjuntamente la entropía cruzada entre la distribución de salida de los tensores calculada por la red neuronal y la distribución verdadera asociada a cada tensor.\n",
    "\n",
    "Por ejemplo, supongamos que se tienen tres clases y que para un determinado tensor la clase asociada es la 1 (las posibles clases son 0,1,2).\n",
    "\n",
    "Entonces, la distribución verdadera en este caso es $P=(0,1,0)$. Por otro lado, supongamos que la distribución que calcula la red neuronal para este tensor es $Q= (0.2, 0.7, 0.1)$. Entonces, la entropía cruzada entre estos doe vectores de probabilidad es dada por:\n",
    "\n",
    "$$\n",
    "H(P,Q) = -(0\\times \\log 0.2 + 1 \\times \\log 0.7+0 \\times \\log 0.1) = \\log 0.7 = 0.357\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Entropía cruzada en el caso general</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, si $x$ es la entrada de la red que da origen al vector de probabilidad $(0.2, 0.7, 0.1)$, $y = 1$ es la clase a la cual pertenece $x$,  $\\text{net}_{\\theta}(\\cdot)$, representa  a la función red neuronal correspondiente con parámetros $\\theta$, en un paso del algortimo de entrenamiento o en un checkpoint en inferencia (predicción) de la red, se tendría que $\\hat{y}=\\text{net}_{\\theta}(x) = (0.2, 0.7, 0.1)$ y la entropía es dada por\n",
    "\n",
    "$$\n",
    "H(y,\\hat{y}) = - y\\log \\hat{y} = - \\log (\\text{net}_{\\theta}(x))= - 1 \\log 0.7 = 0.357\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general si $x$ es una entrada a la red neuronal $\\text{net}_{\\theta}(\\cdot)$, con vector de parámetros $\\theta$; $\\hat{y}= \\text{net}_{\\theta}(x)$, $y$ es la codificación `one-hot` de la categoría a la cual pertenece $x$, entonces vamos a escribir $y=(y_1, \\ldots, y_n)$; $\\hat{y}=(\\hat{y}_1, \\ldots, \\hat{y}_n)$ y tenemos que la entropía cruzada entre $y$ y $\\hat{y}$ es dada por\n",
    "\n",
    "$$\n",
    "H(y, \\hat{y}) = -\\sum_{i=1}^n y_i\\log \\hat{y}i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota Aclaratoria**\n",
    "Debido a que en la codificación *one-hot*, solamente una componente del vector es uno  y el recto cero, en la expresión anterior solamente un sumando es diferente de cero. Lo hemos escrito de esta forma, para mantener sencilla la notación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Entropía cruzada en conjunto de entrenamiento</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que  se tiene un conjunto de entradas a la red $X=\\{x_1,\\ldots, x_N\\}$ y etiquetas $Y =\\{y_1, \\ldots, y_N\\}$ en codificación `one-hot`. Si hay digamos $K$ categorías, cada etiqueta $y_j$ es en realidad un vector de probabilidad de la forma $y_i =(y_{i1}, \\ldots, y_{iK})$. Supongamos adicionalmente que $\\hat{y}_i = \\text{net}_{\\theta}(x_i)$, de nuevo en codificación *one-hot* y denotemos $\\hat{Y}=(\\hat{y}_1, \\dots, \\hat{y}_N)$. Es costumbre definir la entropia cruzada entre los conjuntos de etiquetas $Y$ y $\\hat{Y}$ en la forma:\n",
    "\n",
    "\n",
    "$$\n",
    "H(Y, \\hat{Y}) = -\\frac{1}{N} \\sum_{i=1}^N H(y_i,  \\hat{y}_i) = -\\frac{1}{N} \\sum_{i=1}^N  \\sum_{j=1}^K y_{ij}   \\log \\hat{y}_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota Aclaratoria**\n",
    "En las API's para resde neurononales la entropía cruzada es el método preferido en modelos de clasificación. En esas API's como `Keras` es posible definir la entropía cruzada sin reducir al promedio, sino a la suma de las entropías de cada muestra. Sin embargo  para efectos de comparación es mejor tomar el promedio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Entropía cruzada log verosimilitud</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La entropía cruzada ha sido usada desde siempre por los estadísticos pero, por lo general de manera inadvertida. Dejamos como ejercicio verficar que\n",
    "\n",
    "$$\n",
    "\\log \\mathfrak{L}(Y|X,\\theta) = -H(Y, \\hat{Y}),\n",
    "$$\n",
    "corresponde a la log verosimilutud de un modelo de clasificación clásico con $\\hat{y}_i = \\text{net}_{\\theta}(x_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"right\"/> \n",
    "</figure>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
