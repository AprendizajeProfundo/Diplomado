{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center>Introducción a Redes Neuronales Recurrentes</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/Parlamento Budapest.jpg\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Parlamento Budapest</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: <a href=\"https://commons.wikimedia.org/wiki/File:Parlamenti_sz%C3%ADnek.jpg\">Dwight79</a>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\">CC BY-SA 3.0</a>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Coordinador</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "1. Camilo José Torres Jiménez, Msc, cjtorresj@unal.edu.co\n",
    "1. Daniel  Montenegro, Msc, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Asesora Medios y Marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com\n",
    "5. Jessica López Mejía, jelopezme@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Jefe Jurídica</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Paula Andrea Guzmán, guzmancruz.paula@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Coordinador Jurídico</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. David Fuentes, fuentesd065@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Desarrolladores Principales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Dairo Moreno, damoralesj@unal.edu.co\n",
    "9. Joan Castro, jocastroc@unal.edu.co\n",
    "10. Bryan Riveros, briveros@unal.edu.co\n",
    "11. Rosmer Vargas, rovargasc@unal.edu.co\n",
    "12. Venus Puertas, vpuertasg@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Expertos en Bases de Datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Giovvani Barrera, udgiovanni@gmail.com\n",
    "14. Camilo Chitivo, cchitivo@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Alvaro Montenegro y Daniel Montenegro, Inteligencia Artificial y Aprendizaje Profundo, 2021](https://github.com/AprendizajeProfundo/Diplomado)\n",
    "1. [Alvaro Montenegro, Daniel Montenegro y Oleg Jarma, Inteligencia Artificial y Aprendizaje Profundo Avanzado, 2022](https://github.com/AprendizajeProfundo/Diplomado-Avanzado)\n",
    "1. [Introducción a Redes LSTM](Intro_LSTM.ipynb)\n",
    "1. [Time Series Forecasting with LSTMs using TensorFlow 2 and Keras in Python](https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651/)\n",
    "1. [Dive into Deep Learnig](https://d2l.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Redes Neuronales con una capa oculta](#Redes-Neuronales-con-una-capa-oculta)\n",
    "* [Redes Neuronales con estados ocultoss](#Redes-Neuronales-con-estados-ocultos)\n",
    "* [Redes Neuronales basados en Modelos de lenguaje caracter-etiqueta](#Redes-Neuronales-basados-en-Modelos-de-lenguaje-caracter-etiqueta)\n",
    "* [Perplexity](#Perplexity)\n",
    "* [Resumen](#Resumen)\n",
    "* [Ejercicios](#Ejercicios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "En el procesamiento de lenguaje natural se introducen los modelos recurrentes. En tales modelos la probabilidad condicional de la palabra $ x_t $ en el paso de tiempo $ t $ solo depende de las $ n-1 $ las palabras anteriores.\n",
    "\n",
    "\n",
    "Si queremos incorporar el posible efecto de todas las palabras anteriores al paso de tiempo $ t-(n-1) $ en $ x_t $,\n",
    "necesitamos aumentar $ n $.\n",
    "\n",
    "Sin embargo, el número de parámetros del modelo también aumentaría exponencialmente con él, ya que necesitamos almacenar $ | \\mathcal{V} |^n $ números para un conjunto de vocabulario $ \\mathcal{V} $.\n",
    "Lo que haremnos, en lugar de modelar $ P (x_t \\mid x_ {t-1}, \\ldots, x_{t-n + 1}) $, es usar un modelo de variable latente:\n",
    "\n",
    "$$ \n",
    "P(x_t \\mid x_ {t-1}, \\ldots, x_1) \\approx P (x_t \\mid h_ {t-1}), \n",
    "$$\n",
    "\n",
    "en donde $ h_{t-1} $ es un `estado oculto` (también conocido como variable oculta) que almacena en forma sintética la información de la secuencia hasta el paso de tiempo $ t-1 $.\n",
    "\n",
    "En general, el estado oculto en cualquier paso de tiempo $ t $ podría calcularse basándose tanto en la entrada actual $ x_{t} $ como en el estado oculto anterior $ h_{t-1} $:\n",
    "\n",
    "$$\n",
    "h_t = f (x_{t}, h_{t-1}).\n",
    "$$\n",
    "\n",
    "\n",
    "Para una función suficientemente poderosa $ f $, el modelo de variable latente no es una aproximación. Después de todo, $ h_t $ simplemente puede almacenar todos los datos que ha observado hasta ahora.\n",
    "Sin embargo, potencialmente podría encarecer tanto la computación como el almacenamiento.\n",
    "\n",
    "Recuerde que hemos hablado de capas ocultas con unidades ocultas cuando introducimos los  perceptrones multicapa.\n",
    "\n",
    "Cabe destacar que capas ocultas y estados ocultos se refieren a dos conceptos muy diferentes.\n",
    "\n",
    "+ Las capas ocultas son, como se explicó, capas que están ocultas a la vista en la ruta desde la entrada hasta la salida.\n",
    "+ Los estados ocultos son técnicamente hablando `entradas` a todo lo que hacemos en un paso dado, y solo se pueden calcular observando los datos de los pasos de tiempo anteriores.\n",
    "\n",
    "Las `redes neuronales recurrentes` (RNR) son redes neuronales con estados ocultos. Antes de presentar el modelo RNR, revisitemos el modelo perceptron multicapa (PMC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## <span style=\"color:blue\">Redes Neuronales con una capa oculta</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "Damos un vistazo a un PMC con una sola capa oculta. Dado un mini lote de ejemplos $\\mathbf{X} \\in \\mathbb{R}^{d \\times N}$ con tamaño de lote $N$ y $d$ entradas. La salida de la capa oculta, denotada por  $\\mathbf{Y} \\in \\mathbb{R}^{h \\times N}$ se calcula como\n",
    "\n",
    "$$\\mathbf{Y} = g( \\mathbf{W}_{hd} \\mathbf{X}+ \\mathbf{B})$$\n",
    "\n",
    "\n",
    "En esta ecuación tenemos que la matriz(parámetro) de pesos de la capa oculta es $\\mathbf{W}_{hd} \\in \\mathbb{R}^{d \\times h}$, el vector sesgo (bias) de la capa oculta es  $\\mathbf{b}_h \\in \\mathbb{R}^{h\\times 1}$, $B = [\\mathbf{b}_h, \\ldots, \\mathbf{b}_h ]_{h \\times N}$, $h$  es el número de unidades ocultas de la capa oculta y $g$ la función de activación de la capa oculta.\n",
    "\n",
    "\n",
    "Ahora, la variable oculta $\\mathbf{Y}$ se utiliza como entrada de la capa de salida. La capa de salida está dada por \n",
    "\n",
    "$$\\mathbf{Z} = f(\\mathbf{V}_{qh}\\mathbf{Y} + \\mathbf{C}),$$\n",
    "\n",
    "en donde $\\mathbf{Z} \\in \\mathbf{R}^{q \\times N}$ es la variable de salida, $\\mathbf{V}_{q \\times h} \\in \\mathbb{R}^{q \\times h}$ es la matriz (parámetro) de pesos de la capa de salida, $\\mathbf{C} \\in \\mathbb{R}^{q \\times N}$, con \n",
    "$\\mathbf{C} = [\\mathbf{c}_q, \\ldots, \\mathbf{c}_q ]_{q \\times N}$,  $\\mathbf{c}_q \\in \\mathbb{R}^{q \\times 1}$ el parámetro de sesgo de la capa de salida y $f$ la función de activación de la capa de salida.  Si se trata de un problema de clasificación, podemos utilizar $\\text{softmax}(\\mathbf{Z})$ para calcular la distribución de probabilidad de las categorías de salida.\n",
    "\n",
    "Esto es completamente análogo a un problema de regresión no lineal usando redes neuronales, por lo que omitimos detalles.\n",
    "Baste decir que podemos elegir aleatoriamente pares de características y etiquetas  y `aprender` (estimar) los parámetros de nuestra red a través de la `diferenciación automática` y el `descenso de gradiente estocástico`.\n",
    "\n",
    "La siguiente imagen ilustra el caso cuando se tiene $d=3$, $h=2$, $q=1$ y $N=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/ANN_Capa_Oculta.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "**<center >Red Neuronal con una capa oculta.</center>**\n",
    "Fuente: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## <span style=\"color:blue\">Redes Neuronales con estados ocultos</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "Las cosas son completamente diferentes cuando tenemos estados ocultos. Veamos la estructura con más detalle.\n",
    "\n",
    "Supongamos que tenemos un minilote de entradas $ \\mathbf{X}^{(t)} \\in \\mathbb{R} ^ {d \\times N} $ en el paso de tiempo $ t $. En otras palabras, para un minilote de $ N $ ejemplos de secuencia, \n",
    "cada columna de $ \\mathbf{X}^{(t)} $ corresponde a una característica (feature) en el paso de tiempo $ t $ de la secuencia.\n",
    "\n",
    "En adelante  $\\mathbf{H}^{(t)} \\in \\mathbb{R}^{h \\times N} $ denotará la variable oculta en el  paso de tiempo $ t $.\n",
    "\n",
    "A diferencia del PMC, aquí guardamos la variable oculta $ \\mathbf {H}^{(t-1)} $ del paso de tiempo anterior e introducimos una nueva matriz (parámetro) de peso $ \\mathbf{W}_{hh} \\in \\mathbb{R }^{h \\times h}$ para transformar  la variable oculta del paso de tiempo anterior en el paso de tiempo actual.  En adelante $ \\mathbf{W}_{hd} \\in \\mathbb{R }^{h \\times d}$  denotará a la matriz de pesos aplicada a la siguiente nueva entrada $ \\mathbf {X}^{(t)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Cálculo del estado oculto</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "Específicamente, el cálculo de la variable oculta del paso de tiempo actual está determinado por la entrada del paso de tiempo actual junto con la variable oculta del paso de tiempo anterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\mathbf{H}^{(t)} = f( \\mathbf{W}_{h d} \\mathbf{X}^{(t)} + \\mathbf{W}_{hh} \\mathbf{H}^{(t-1)}  + \\mathbf{B}). \n",
    "$$\n",
    "\n",
    "\n",
    "En donde $\\mathbf{b}_h \\in \\mathbb{R}^{h\\times 1}$, $B = [\\mathbf{b}_h, \\ldots, \\mathbf{b}_h ]_{h \\times N}$ \n",
    "\n",
    "En comparación con la ecuación de la salida de la capa oculta arriba, esta ecuación   agrega el término $ \\mathbf {W}_{hh}\\mathbf{H}^{(t-1)} $.\n",
    "\n",
    "\n",
    "De la relación entre las variables ocultas $ \\mathbf{H}^{(t)} $ y $ \\mathbf{H}^{(t-1)}$ de pasos de tiempo adyacentes, se desprende que estas variables capturan y retienen la información histórica de la secuencia hasta su paso de tiempo actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable oculta se denomina `estado oculto`. Dado que el estado oculto usa la misma definición del paso de tiempo anterior en el paso de tiempo actual, el cálculo de $ \\mathbf {H}^{(t)}$ es recurrente.  Por esta razón las redes neuronales con estados ocultos basados en cálculos recurrentes se denominan `redes neuronales recurrentes`.\n",
    "\n",
    "\n",
    "Capas que ejecutan el cálculo de esta última ecuación se llaman *capas recurrentes*.\n",
    "\n",
    "\n",
    "Hay muchas formas diferentes de construir RNR. Las RNR con un estado oculto definido arriba  son muy comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Cálculo del valor  en capa de salida para el tiempo $t$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el paso de tiempo $ t $, el valor de la capa de salida es similar al cálculo en el PMC:\n",
    "\n",
    "$$\\mathbf{Z}^{(t)} =  g(\\mathbf {W}_{qh} \\mathbf {H}^{(t)}+ \\mathbf {b}_q)$$.\n",
    "\n",
    "Los parámetros de la RNR incluyen los pesos $ \\mathbf{W}_{dh} \\in \\mathbb{R}^{d \\times h}, \\mathbf{W}_{hh} \\in \\mathbb{R}^{h \\times q}$ y el sesgo $ \\mathbf{b}_h \\in \\mathbb{R}^{1 \\times h} $\n",
    "de la capa oculta, junto con los pesos $ \\mathbf {W} _ {hq} \\in \\mathbb {R} ^ {h \\times q} $\n",
    "y el sesgo $ \\mathbf{b}_q \\in \\mathbb{R}^{1 \\times q} $ de la capa de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Predicciones  en la capa de salida</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la capa de salida de un modelo recurrente para cada valor de tiempo $t$ se tiene una predicción que hemos denotado $\\mathbf{Z}^{(t)}$. El tamaño de esa predicción depende del problema. Por ejemplo en un modelo generador de texto, el tamaño de  $\\mathbf{Z}^{(t)}$ corresponde al tamaño del vocabulario $ \\mathcal{V} $ y la función de activación $g$ es softmax, debido a que en tal caso $\\mathbf{Z}^{(t)}$ es el vector de probabilidades de la siguiente palabra a generar, dadas las anteriores palabras. \n",
    "\n",
    "En el caso de series de tiempo $\\mathbf{Z}^{(t)}$ puede ser una matriz correspondiente a la predicción en un horizonte de tiempo, considerando posiblemente varias series a predecir simultáneamente. En tal caso, la función de activación podría ser la identiddad, ReLU o alguna otra, dependiendo del tipo de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale la pena mencionar que incluso en diferentes pasos de tiempo, Los RNR siempre usan estos parámetros de modelo. Por tanto, el costo de parametrización de un RNR no crece a medida que aumenta el número de pasos de tiempo.\n",
    "\n",
    "La siguiente figura ilustra la lógica computacional de un RNR en tres pasos de tiempo adyacentes.\n",
    "En cualquier momento paso $ t $, el cálculo del estado oculto se puede entender como:\n",
    "\n",
    "1. concatenando la entrada $ \\mathbf {X}^{(t)} $ en el paso de tiempo actual $ t $ y el estado oculto $ \\mathbf {H}^{(t-1)} $ en el paso de tiempo anterior $ t-1 $;\n",
    "1. pasar el resultado de la concatenación a una capa completamente conectada con función de activación $ f $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8,
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">El proceso de entrenamiento y de inferencia</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "La imagen abajo muestra el funcionamiento general de una fred recurrente:\n",
    "\n",
    "En el proceso de entrenamiento ocurre lo siguiente:\n",
    "\n",
    "* El estado oculto incial es $\\mathbf{H}^{(0)}=\\boldsymbol{0}$. \n",
    "* En cado paso entra una nueva observación $ \\mathbf {X}^{(t)} $, la cual usualmente está representado por un vector numérico.  Se calcula el nuevo estado oculto  mediante $ \\mathbf{H}^{(t)} = f( \\mathbf{W}_{h d} \\mathbf{X}^{(t)} + \\mathbf{W}_{hh} \\mathbf{H}^{(t-1)}  + \\mathbf{B})$.  \n",
    "* Se  realiza la predicción $\\mathbf{Z}^{(t)} =  g(\\mathbf {W}_{qh} \\mathbf {H}^{(t)}+ \\mathbf {b}_q)$. Es un vector de predicción, cuyo tamaño es determinado por la matriz de pesos $\\mathbf {W}_{qh}$. Observe que el el vector de predicción tiene tamaño $q$. Por ejemplo en un modelo de lenguaje natural, $q$ es el tamaño del vocabulario y  $\\mathbf{Z}^{(t)}$ es el vector de logits, el cual se pasa por la función softmax, para tener el vector de probabilidad del siguiente caracter o la siguiente palabra a ser generada.\n",
    "* Se calcula la pérdida. `ECM `  para datos numéricos como las series de tiempo numéricas o  `entropía cruzada` para predicciones categóricas, como es el caso de los modelos de  lenguaje natrual.\n",
    "\n",
    "En el proceso de inferencia \n",
    "\n",
    "* El estado oculto incial es $\\mathbf{H}^{(0)}=\\boldsymbol{0}$. \n",
    "* En cado paso entra una nueva observación $ \\mathbf {X}^{(t)} $, la cual usualmente está representado por un vector numérico.  Se calcula el nuevo estado oculto  mediante $ \\mathbf{H}^{(t)} = f( \\mathbf{W}_{h d} \\mathbf{X}^{(t)} + \\mathbf{W}_{hh} \\mathbf{H}^{(t-1)}  + \\mathbf{B})$.  \n",
    "* Se  realiza la predicción $\\mathbf{Z}^{(t)} =  g(\\mathbf {W}_{qh} \\mathbf {H}^{(t)}+ \\mathbf {b}_q)$. Es un vector de predicción, cuyo tamaño es determinado por la matriz de pesos $\\mathbf {W}_{qh}$. Observe que el el vector de predicción tiene tamaño $q$. Por ejemplo en un modelo de lenguaje natural, $q$ es el tamaño del vocabulario y  $\\mathbf{Z}^{(t)}$ es el vector de logits, el cual se pasa por la función softmax, para tener el vector de probabilidad del siguiente caracter o la siguiente palabra a ser generada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/red_recurrente.png\" width=\"800\" height=\"800\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "**<center >Red Neuronal recurrente con un estado oculto.</center>**\n",
    "\n",
    "Fuente: Alvaro Montenegro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Parámetros del modelo recurrente general</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con lo expuesto arriba, los pesos y sesgos del modelo recurrente son:\n",
    "\n",
    "+ Entrada: $ \\mathbf{W}_{hd}$\n",
    "+ Estado oculto: $ \\mathbf{W}_{hh}$, $ \\mathbf{b}_{h}$\n",
    "+ Salida: $ \\mathbf{W}_{qh}$, $ \\mathbf{b}_{q}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Ejercicio</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcule el número total de parámetros del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## <span style=\"color:blue\">Redes Neuronales basados en Modelos de lenguaje basados en caracteres</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "Recuerde que para el modelado de idiomas nuestro objetivo es predecir el siguiente token basado en\n",
    "los tokens actuales y anteriores. [Bengio et al](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf). fueron los primeros en proponer usar una red neuronal recurrente para el modelado de idiomas.\n",
    "\n",
    "A continuación ilustramos cómo se pueden usar RNN para predecir el siguiente caracter en un modelo de idioma basado en caracteres. Dejaremos que el tamaño del minilote sea uno, y la secuencia del texto sea \"machine\".\n",
    "\n",
    "Para simplificar, tokenizamos el texto en caracteres en lugar de las palabras y consideramos un `modelo de lenguaje de nivel de carácter`.\n",
    "La siguiente figura muestra cómo predecir el siguiente carácter en función de los caracteres actuales y anteriores a través de una RNR para el modelado de lenguaje de nivel de carácter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/recurrente_char.png\" width=\"850\" height=\"850\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "**<center >Modelo PLN generador de texto a nivel de caracter</center>**\n",
    "\n",
    "Fuente: Alvaro Montenegro\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido al cálculo recurrente del estado oculto, la salida del tiempo en el paso 3 en la figura, es $ \\mathbf{H}^{(3)}$, y está determinado por la secuencia de texto \"h\", \"o\", y \"l\" .  Para determinar el siguiente carácter de la secuencia en los datos se obtiene la salida $ \\mathbf{Z}^{(3)}$, que es un vector de logits del tamaño del vocabulario, digamos 27 (caracteres). Al calcular  $\\text{softmax}( \\mathbf{Z}^{(3)})$ se obtiene la distribución de probabilidad para el siguiente caracter, que en el ejemplo se esperaría que fuera el caracter 'a'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## <span style=\"color:blue\">Evaluación de modelo recurrentes de lenguaje natural: Perplexity</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "\n",
    "Por último, analicemos cómo medir la calidad del modelo de lenguaje, que se utilizará para evaluar nuestros modelos basados en RNR en las secciones siguientes.\n",
    "\n",
    "Una forma de evaluar la calidad del modelo de lenguaje es calcular lo sorprendente que resulta el texto. Un buen modelo de lenguaje puede predecir con tokens de alta precisión como revisamos a continuación. Considere las siguientes continuaciones de la frase \"Está lloviendo\", según lo propuesto por diferentes modelos de lenguaje:\n",
    "\n",
    "1. \"Está lloviendo afuera\"\n",
    "1. \"Está lloviendo banano\"\n",
    "1. \"Está lloviendo piouw; kcj pwepoiut\"\n",
    "\n",
    "En términos de calidad, el ejemplo 1 es claramente el mejor. Las palabras son sensatas y lógicamente coherentes. Si bien es posible que no refleje con precisión qué palabra sigue semánticamente (\"en San Francisco\" y \"en invierno\" habrían sido extensiones perfectamente razonables), el modelo es capaz de capturar qué tipo de palabra sigue.\n",
    "\n",
    "El ejemplo 2 es considerablemente peor al producir una extensión sin sentido. No obstante, al menos el modelo ha aprendido a deletrear palabras y cierto grado de correlación entre las palabras. Por último, el ejemplo 3 indica un modelo mal entrenado que no se ajusta a los datos correctamente.\n",
    "\n",
    "Podríamos medir la calidad del modelo calculando la probabilidad de la secuencia.\n",
    "Desafortunadamente, este es un número difícil de entender y de comparar.\n",
    "Después de todo, es mucho más probable que ocurran secuencias más cortas que las más largas, de ahí la evaluación del modelo de la obra magna de Tolstoi\n",
    "*La guerra y paz* producirá inevitablemente una probabilidad mucho menor que, por ejemplo, en la novela de Saint-Exupery *El Principito*. Lo que falta es el equivalente a un promedio.\n",
    "\n",
    "Como sabemos de antes, La  *entropía mide el grado de sorpresa* de un resultado en una distribución discreta y *entropía cruzada mide el grado de sorpesa de un resultado de una distribución en relación con una distribución de referencia*.\n",
    "\n",
    "\n",
    "Si queremos comprimir texto, podemos preguntar sobre el siguiente token dado el conjunto actual de tokens. Un mejor modelo de lenguaje debería permitirnos predecir el próximo token con mayor precisión. Por lo tanto, debería permitirnos gastar menos bits en comprimir la secuencia.\n",
    "\n",
    "\n",
    "Entonces podemos medirlo por la pérdida de la entropía cruzada promediada sobre todos los $ n $ tokens de una secuencia:\n",
    "\n",
    "$$\\frac{1}{n} \\sum_{t=1}^n -\\log P(x_t \\mid x_{t-1}, \\ldots, x_1),$$\n",
    "\n",
    "donde $ P $ viene dado por un modelo de lenguaje y $ x_t $ es el token real observado en el paso de tiempo $ t $ de la secuencia. Observe que para este cálculo se usa la entropía cruzada. La distribución de referencia es la codificación one-hot de la etiqueta correspondiente, en cada salida. Además $P(x_t \\mid x_{t-1}, \\ldots, x_1)$ se calcula a partir de $\\text{Softmax}(h_t)$.\n",
    "\n",
    "Esto hace que el rendimiento en documentos de diferentes longitudes sea comparable. Por razones históricas, los científicos en el procesamiento del lenguaje natural prefieren usar una cantidad llamada *perplexity*. En pocas palabras, es el exponencial de la anterior ecuacion:\n",
    "\n",
    "$$\\exp\\left(-\\frac{1}{n} \\sum_{t=1}^n \\log P(x_t \\mid x_{t-1}, \\ldots, x_1)\\right).$$\n",
    "\n",
    "La perplejidad (perplexity) puede entenderse mejor como la media armónica del número de opciones reales que tenemos al decidir qué token elegir a continuación. \n",
    "\n",
    "Veamos algunos casos:\n",
    "\n",
    "* En el mejor de los casos, el modelo siempre estima perfectamente la probabilidad del token de etiqueta como 1. En este caso, la perplejidad del modelo es 1.\n",
    "* En el peor de los casos, el modelo siempre predice la probabilidad del token de etiqueta como 0. En esta situación, la perplejidad es infinito positivo.\n",
    "* En la línea de base, el modelo predice una distribución uniforme sobre todos los tokens disponibles del vocabulario. En este caso, la perplejidad (perplexity) es igual al número de tokens únicos del vocabulario. De hecho, si tuviéramos que almacenar la secuencia sin ninguna compresión, esto sería lo mejor que podríamos hacer para codificarla. Por lo tanto, esto proporciona un límite superior no trivial que cualquier modelo útil debe superar.\n",
    "\n",
    "En la práctica, con los modelos de lenguaje natural la perplejidad (perplexity) es calculada como la exponencial de la funcipon de pérdida del modelo.\n",
    "\n",
    "Comparemos la perplejidad de dos oraciones con GPT2 y veamos cuán perpleja es. Primero cargamos un tokenizador y una cabeza causal para el modelo GPT2 de HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"ABC is a startup based in New York City and Paris\", return_tensors = \"pt\")\n",
    "loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "ppl = torch.exp(loss)\n",
    "print(ppl)\n",
    "\n",
    "#Output: 29.48\n",
    "\n",
    "inputs_wiki_text = tokenizer(\"Generative Pretrained Transformer is an opensource artificial intelligence created by OpenAI in February 2019\", return_tensors = \"pt\")\n",
    "loss = model(input_ids = inputs_wiki_text[\"input_ids\"], labels = inputs_wiki_text[\"input_ids\"]).loss\n",
    "ppl = torch.exp(loss)\n",
    "print(ppl)\n",
    "\n",
    "# Output: 211.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede ver, la primera oración es una de las secuencias en las que se entrenó el modelo y, por lo tanto, la perplejidad es mucho menor en comparación con la segunda oración. El modelo no ha visto la segunda oración antes y, por lo tanto, el modelo GPT2 está más perplejo.\n",
    "\n",
    "La perplejidad generalmente se usa solo para determinar qué tan bien un modelo ha aprendido el conjunto de entrenamiento. Otras métricas como BLEU, ROUGE, etc., se utilizan en el conjunto de prueba para medir el rendimiento de la prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## <span style=\"color:blue\">Resumen</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "* Una red neuronal que utiliza computación recurrente para estados ocultos se denomina red neuronal recurrente (RNN).\n",
    "* El estado oculto de un RNN puede capturar información histórica de la secuencia hasta el paso de tiempo actual.\n",
    "* El número de parámetros del modelo RNN no aumenta a medida que aumenta el número de pasos de tiempo.\n",
    "* Podemos crear modelos de lenguaje a nivel de personaje usando un RNN.\n",
    "* Podemos utilizar la perplejidad para evaluar la calidad de los modelos lingüísticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "## <span style=\"color:blue\">Ejercicios</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "1. Si usamos un RNN para predecir el siguiente carácter en una secuencia de texto, ¿cuál es la dimensión requerida para cualquier resultado?\n",
    "1. ¿Por qué los RNN pueden expresar la probabilidad condicional de un token en algún paso de tiempo basándose en todos los tokens anteriores en la secuencia de texto?\n",
    "1. ¿Qué le sucede al gradiente si se propaga hacia atrás a través de una secuencia larga?\n",
    "1. ¿Cuáles son algunos de los problemas asociados con el modelo de lenguaje descrito en esta sección?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
