{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure> \n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Redes LSTM (Long Short Term Memory Networks)</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "1. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "1. Campo Elías Pardo Turriago, cepardot@unal.edu.co \n",
    "1. Oleg Jarma, ojarmam@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introducción a Redes LSTM](Intro_LSTM.ipynb)\n",
    "1. [Time Series Forecasting with LSTMs using TensorFlow 2 and Keras in Python](https://towardsdatascience.com/time-series-forecasting-with-lstms-using-tensorflow-2-and-keras-in-python-6ceee9c6c651/)\n",
    "1. [Dive into Deep Learnig](https://d2l.ai/)\n",
    "1. [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "1. [Ralf C. Staudemeyer and Eric Rothstein Morris,*Understanding LSTM a tutorial into Long Short-Term Memory Recurrent Neural Networks*, arxiv, September 2019](https://arxiv.org/pdf/1909.09586.pdf)\n",
    "1. [Karpathy, *The Unreasonable Effectiveness of Recurrent Neural Networks*](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Breve historia ](#Breve-historia )\n",
    "* [¿Qué son las redes LSTM?](#¿Qué-son-las-redes-LSTM?)\n",
    "* [El problema de las dependencias a largo plazo](El-problema-de-las-dependencias-a-largo-plazo)\n",
    "* [Redes LSTM](#Redes-LSTM)\n",
    "* [La idea central detras de las redes LSTM](#La-idea-central-detras-de-las-redes-LSTM)\n",
    "* [Caminando a lo largo de una red LSTM. Paso a paso](#Caminando-a-lo-largo-de-una-red-LSTM.-Paso-a-paso)\n",
    "* [Estructura Matemática de una red LSTM](#Estructura-Matemática-de-una-red-LSTM)\n",
    "* [Cálculo del número de neuronas de una capa LSTM](#Cálculo-del-número-de-neuronas-de-una-capa-LSTM)\n",
    "* [Computación en una capa LSTM de Keras](#Computación-en-una-capa-LSTM-de-Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los humanos no comienzan a pensar desde cero cada segundo. A medida que usted lee este documento, comprende cada palabra en función de su comprensión de las palabras anteriores. No lee todo y empieza a pensar desde cero de nuevo. Sus pensamientos tienen persistencia.\n",
    "\n",
    "Las redes neuronales tradicionales no pueden hacer esto, lo parece una gran deficiencia. Por ejemplo, imagine que desea clasificar qué tipo de evento está ocurriendo en cada punto de una película. No está claro cómo una red neuronal tradicional podría usar su razonamiento sobre eventos anteriores en la película para informar a los posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Breve historia </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomado de [Wikipedia](https://en.wikipedia.org/wiki/Recurrent_neural_network). \n",
    "\n",
    "Las redes neuronales recurrentes se basaron en el trabajo de [Rumelhart, Hinton y Williams en 1986](https://www.nature.com/articles/323533a0).  Las redes de Hopfield, un tipo especial de RNN, fueron (re)descubiertas por John Hopfield en 1982. En 1993, un sistema de compresión del historial neuronal resolvió una tarea de \"aprendizaje muy profundo\" que requería más de 1000 capas posteriores en un RNN desarrollado en el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes de memoria a largo y corto plazo (LSTM) fueron inventadas por [Hochreiter y Schmidhuber en 1997](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory) y establecieron récords de precisión en múltiples dominios de aplicaciones.\n",
    "\n",
    "Alrededor de 2007, LSTM comenzó a revolucionar el reconocimiento de voz, superando a los modelos tradicionales en ciertas aplicaciones de voz, [Fernández,Graves, Schmidhuber](https://www.researchgate.net/publication/221080087_An_Application_of_Recurrent_Neural_Networks_to_Discriminative_Keyword_Spotting). En 2009, una red LSTM entrenada en clasificación temporal conexionista (CTC) fue la primera RNN en ganar concursos de reconocimiento de patrones cuando ganó varias competencias en reconocimiento de escritura conectada. En 2014, la empresa china Baidu utilizó RNN entrenadas  por CTC para superar el punto de referencia del conjunto de datos de reconocimiento de voz [2S09 Switchboard Hub5'00](https://catalog.ldc.upenn.edu/LDC2002S09) sin utilizar ningún método de procesamiento de voz tradicional.\n",
    "\n",
    "LSTM también mejoró el reconocimiento de voz de vocabulario amplio y la síntesis de texto a voz y se usó en Google Android. En 2015, el reconocimiento de voz de Google supuestamente experimentó un aumento espectacular del rendimiento del 49 % a través de LSTM entrenada con CTC, [Google AI blog](https://ai.googleblog.com/2015/09/google-voice-search-faster-and-more.html).\n",
    "\n",
    "LSTM batió récords de traducción automática mejorada,  modelado de idiomas  y procesamiento de idiomas multilingües.  LSTM combinado con redes neuronales convolucionales (CNN) mejoró los subtítulos automáticos de imágenes, [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/pdf/1411.4555.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">¿Qué son las redes LSTM?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales recurrentes (RNR) abordan el problema de `recordar lo que han visto antes`. Estas son redes con bucles que permiten que la información sea persistente. La siguiente imagen es una abstracción de una red recurrente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/RNN-rolled-sm.png\" width=\"200\" height=\"100\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Diagrama enrrollado de un trozo de una red neuronal recurrente</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imagen muestra lo que se conoce como un diagrama *enrollado* de un trozo de una red neuronal recurrente. En la imagen la capa $A$, recibe en el tiempo $t$ dos entradas: un valor $x_t$ y un valor $h_{t-1}$ y como salida genera un valor actualizado $h_t$. El bucle indica que la información transita de un paso en la capa hacia el siguiente paso.\n",
    "\n",
    "Estos bucles hacen que las redes neuronales recurrentes parezcan misteriosas. Sin embargo, si piensa un poco más, resulta que no son tan diferentes de una red neuronal normal. \n",
    "\n",
    "Una red neuronal recurrente puede imaginarse como compuesta de múltiples copias de la misma capa, cada una de las cuales pasa un mensaje a un sucesor. Observe como se ve la red recurrente si desenrollamos el bucle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/RNN-unrolled.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Diagrama desenrrollado  de un trozo de una red neuronal recurrente </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Esta naturaleza en cadena revela que las redes neuronales recurrentes están íntimamente relacionadas con secuencias. \n",
    "\n",
    "Son la arquitectura natural de  red neuronal para usar con datos de naturaleza secuencial. Desde el punto de vista estadístico son procesos estocásticos. Específicamente, Son modelos autoregresivos.\n",
    "\n",
    "Los modelos lineales autoregresivos como ARMA o ARCH se han utilizado en estadística, econometría y modelos financieros durante mucho tiempo. La diferencia fundamental de las RNR con los modelos lineales autoregresivos clásicos es que `las RNR utilizan un estado oculto para resumir y transportar la información previamente recibida`.\n",
    "\n",
    "En los últimos años, ha habido un éxito increíble aplicando RNR a una variedad de problemas: \n",
    "\n",
    "1. reconocimiento de voz,\n",
    "2. modelación de idiomas, \n",
    "3. traducción, \n",
    "4. subtitulado de imágenes\n",
    "5. ... La lista continúa. \n",
    "\n",
    "\n",
    "Dejaremos la discusión de las increíbles hazañas que uno puede lograr con los RNN en la excelente publicación de blog de Andrej Karpathy, [La irrazonable efectividad de las redes neuronales recurrentes](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). Pero realmente son bastante asombrosos.\n",
    "\n",
    "\n",
    "Esencial para estos éxitos es el uso de redes de tipo **LSTM**, un tipo muy especial de red neuronal recurrente que funciona, para muchas tareas, mucho mejor que la versión estándar. Casi todos los resultados emocionantes basados en redes neuronales recurrentes se logran con ellas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">El problema de las dependencias a largo plazo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencias a corto plazo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los atractivos de las RNR es la idea de que podrían ser capaces de conectar información previa a la tarea actual, como el uso de fotogramas de video anteriores que podrían informar la comprensión del presente cuadro. \n",
    "\n",
    "\n",
    "Si las RNR pudieran hacer esto, serían extremadamente útiles. ¿Pero pueden hacerlo? \n",
    "\n",
    "¡Eso depende de la situación!\n",
    "\n",
    "A veces, solo necesitamos mirar información reciente para realizar la tarea actual. Por ejemplo, considere un modelo de lenguaje que intenta predecir la siguiente palabra en función de las anteriores. \n",
    "\n",
    "\n",
    "Si estamos tratando de predecir la última palabra en \n",
    "\n",
    "**las nubes están en el...**, \n",
    "\n",
    "no necesitamos más contexto; es bastante obvio que la siguiente palabra será \n",
    "\n",
    "**cielo**. \n",
    "\n",
    "\n",
    "En tales casos, en donde la brecha entre la información relevante y el lugar que se necesita es pequeña, las RNR pueden aprender a usar la información pasada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/RNN-shorttermdepdencies.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">RNR: dependencias de corto plazo. $h_3$ depende de $x_0, x_1,x_3,x_4$ </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero también hay casos en los que necesitamos más contexto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto a más largo plazo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos el problema de  tratar de predecir la última palabra en el texto \n",
    "\n",
    "**\"Crecí en Francia ... hablo [francés] con fluidez\"**.\n",
    "\n",
    "\n",
    "La información reciente sugiere que la siguiente palabra a  *hablo* es probablemente el nombre de un idioma, pero si queremos limitar qué idioma, necesitamos el contexto de Francia, desde más atrás. \n",
    "\n",
    "\n",
    "Es completamente posible que la brecha entre la información relevante y el punto donde se necesita sea muy grande.\n",
    "\n",
    "Desafortunadamente, a medida que crece esa brecha, los RNN no pueden aprender a conectar la información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/RNN-longtermdependencies.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">RNR: dependencias de largo plazo. $h_{t+1}$ depende de $x_0, x_1$ </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Imagen tomada de [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales luchan con dependencias a largo plazo. En teoría, los RNR son absolutamente capaces de manejar tales \"dependencias a largo plazo\". Un humano podría elegir cuidadosamente los parámetros para resolver problemas de juguetes de esta forma.\n",
    "\n",
    "Lamentablemente, en la práctica, los RNR clásicas no parecen poder aprenderlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema del gradiente que se desvanece o explota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El problema fue explorado en profundidad por [Hochreiter, 1991](https://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf) y [Bengio, et al., 1994](https://www.researchgate.net/publication/5583935_Learning_long-term_dependencies_with_gradient_descent_is_difficult), quienes encontraron algunas razones fundamentales por las cuales podría ser difícil.\n",
    "\n",
    "El problema fundamental mostrado por Hochreiter es que el **gradiente tiende a desaparecer o explotar** cuando en la RNR se calcula las transformaciones afines y se aplica la función de activación `sigmoide` sobre las mismas matrices y vectores. Ver el blog [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) para más detalles.\n",
    "\n",
    "\n",
    "\n",
    "¡Afortunadamente, los LSTM no tienen este problema!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Redes LSTM </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes de memoria a corto y largo plazo, generalmente llamadas \"LSTM\", son un tipo especial de RNR, capaces de aprender dependencias a largo plazo. Fueron introducidas por [Hochreiter y Schmidhuber (1997)](https://www.bioinf.jku.at/publications/older/2604.pdf), y fueron refinadas y popularizadas por muchas personas en trabajos posteriores. \n",
    "\n",
    "Funcionan tremendamente bien en una gran variedad de problemas, y ahora son ampliamente utilizadas. \n",
    "Las redes LSTM están diseñadas explícitamente para resolver el problema de dependencia a largo plazo.\n",
    "\n",
    "\n",
    "- **Recordar información durante largos períodos de tiempo es prácticamente su comportamiento predeterminado, ¡no es algo que les cuesta aprender!**\n",
    "\n",
    "Todas las redes neuronales recurrentes tienen la forma de una cadena de módulos repetitivos de red neuronal. En los RNR estándar, este módulo repetitivo tendrá una estructura muy simple, como una sola capa con activación $\\tanh$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM3-SimpleRNN.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "El módulo de repetición en una RNR estándar con una sola capa. </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes LSTM también tienen esta estructura tipo cadena, pero el módulo de repetición tiene una estructura diferente. En lugar de tener una sola capa de red neuronal, hay cuatro que interactúan de una manera muy especial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM3-chain.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "Módulo de repetición en una red LSTM  con cuatro capas interactuando. </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Imagen tomada de [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se preocupe de momento por los detalles de lo que está sucediendo. Recorreremos el diagrama LSTM paso a paso más adelante. Por ahora, intentemos sentirnos cómodos con la notación que usaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM2-notation_1.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "Nomenclatura de los objetos en las redes LSTM </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el diagrama anterior, cada línea transporta un vector completo, desde la salida de un nodo hasta las entradas de otros. Los círculos de color rosa representan operaciones puntuales, como la suma de vectores, mientras que los cuadros amarillos son capas de redes neuronales aprendidas. La fusión de líneas denota concatenación, mientras que una bifurcación de línea denota que su contenido se copia y las copias van a diferentes ubicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">La idea central detras de las redes LSTM</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clave de las redes LSTM es el `estado de la celda`, que representamos con la línea horizontal que pasa por la parte superior del siguiente diagrama.\n",
    "\n",
    "El estado de la celda es como una `cinta transportadora`. Corre directamente por toda la cadena, con solo algunas interacciones lineales menores. Es muy fácil que la información fluya sin cambios.\n",
    "\n",
    "La idea del concepto de memoria es manejada por el estado de la celda. EL funcionamiento de esta especie de cinta transportadora puede pensarlo de la siguiente manera informal.\n",
    "\n",
    "* Al inicio el estado de la celda se coloca en un valor inicial, digamos $C_0$ = `<BOS>`, que en el caso del tratamiento del lenguaje natural podría ser el vector que representa al símbolo de inicio de una oración, o por ejemplo un vector numérico con el cual iniciamos una serie de tiempo multivariada.\n",
    "* Con el paso del tiempo en el estado de la celda se intenta mantener de forma `borrosa` lo que ha recibido previamente. Para ello en cada paso los valores son deflactados con números en el intervalo $(0,1)$. Si por ejemplo un número es 0.95 y multiplica ($\\times$) el correspondiente valor en la banda transportadora $C$ por ese valor, con lo cual se mantiene el 95% del valor anterior.\n",
    "* En cada paso se sube nueva información a la celda de estado. Esto se hace sumando ($+$) al contenido actual, lo que se desea subir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM3-C-line.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "Banda transportadora  en las redes LSTM </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compuertas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red LSTM tiene la capacidad de eliminar o agregar 'cuidadosamente' información al estado de la celda, regulada por estructuras llamadas puertas. Las puertas son una forma opcional de dejar pasar la información. Se componen de una capa de red neuronal con activación  sigmoide y una operación de multiplicación puntual. La imagen muestra como representamos compuertas en un modelo LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM3-gate.png\" width=\"200\" height=\"200\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "compuerta  en una red LSTM </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La activación sigmoide genera números entre cero y uno, que describe la cantidad de cada componente que debe dejarse pasar. \n",
    "\n",
    "- Un valor de cero significa **no dejar pasar nada**, \n",
    "- mientras que un valor de uno significa **dejar pasar todo**.\n",
    "\n",
    "Un red LSTM tiene tres de estas compuertas, para proteger y controlar el estado de la neurona, llamadas formalmente\n",
    "\n",
    "- compuerta de olvido,\n",
    "- compuerta de entrada y\n",
    "- compuerta de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Caminando a lo largo de una red LSTM. Paso a paso</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compuerta de olvido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso en nuestra red LSTM es decidir qué información vamos a tirar del estado de la celda. Esta decisión la toma un módulo neuronal con activación sigmoide llamado **compuerta de olvido**. \n",
    "\n",
    "La compuerta recibe $ h_{t − 1} $ y $ x_t $, y se genera un número entre 0 y 1 para cada número en el estado de celda $ C_{t − 1} $. Un 1 representa **mantener completamente esto** mientras que un 0 representa **deshacerse completamente de esto**.\n",
    "\n",
    "Volvamos a nuestro ejemplo de un modelo de lenguaje que intenta predecir la siguiente palabra en función de todas las anteriores. \n",
    "\n",
    "\n",
    "En tal problema, el estado de la celda puede incluir el género del sujeto presente, de modo que se puedan usar los pronombres correctos. Cuando vemos un tema nuevo, queremos olvidar el género del tema anterior. \n",
    "\n",
    "En la siguiente imagen se muestra el diagrama y la formulación matemática de la compuerta de olvido. Observe que realmente la compuerta del olvido es realmente un módulo neuronal clásico, con los siguientes elementos:\n",
    "\n",
    "* A la entrada en el tiempo $t$, el valor del `estado oculto` $h_{t-1}$ se concatena con el nuevo valor que el módulo neuronal LSTM recibe. Recuerde que $h_{t-1}$ corresponde a la predicción de la capa LSTM en el paso anterior ($t-1$). $W_f$ es la matriz de pesos y $b_f$ el vector de sesgo de la compuerta del olvido. Por lo tanto, los valores de $W_f$ y $b_f$ forman parte de los parámetros que la red neuronal debe aprender. Además $\\sigma$ representa la activación sigmoide. Si el tamaño del estado oculto $h$ es $p$ y el tamaño de la observaciones $x$ es $n$, entonces, la matriz $W_f$ es un tensor que tiene forma $(n+p,p)$ y el vector se sesgo es un tensor con forma $(p,)$.\n",
    "* A la salida la compuerta de olvido entrega un tensor de tamaño $p$ con valores en $(0,1)$. Cada valor de estos multiplica respectivamente a las componentes actuales de la celda de estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM3-focus-f.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "Compuerta  de olvido </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Imagen tomada de [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compuerta de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es decidir qué nueva información vamos a almacenar en el estado de la celda. Para hacerlo posible se incluye un módulo neuronal que llamaremos **compuerta de entrada**.\n",
    "\n",
    "La compuerta de entrada tiene dos componentes: \n",
    "\n",
    "- Primero, un módulo neuronal con activación sigmoide  que decide como se se subirán  `los nuevos valores` al estado de la celda. Puede pensar en este módulo como un selector de variables a subir al estado de la celda. La salida de este componente neuronal será denotada como $i_t$.\n",
    "- Segundo, un módulo neuronal con activación  $\\tanh$ que crea el vector de `nuevos valores candidatos` a ser subidos a la banda transportadora en el tiempo $t$. A tales valores candidatos los denotaremos como $\\tilde{C}_t$.\n",
    "\n",
    "Los dos módulos neuronales de esta compuerta tiene asociados cada uno una matriz de pesos y un vector de sesgos con los mismos tamaños que en el caso de la compuerta de olvido. \n",
    "\n",
    "Para el primer módulo la matriz de pesos y el sesgo se denotan como $W_i$ y $b_i$ respectivamente, con activación sigmoide. Este módulo cumple con el rol de seleccionar lo que sube al estado de la celda.\n",
    "\n",
    "El segundo módulo neuronal  está compuesto por la matriz de pesos $W_C$, el vector de sesgo $b_C$ y activación $\\tanh$. Este módulo cumple con el rol de proponer lo que puede subirse al estado de  la celda.\n",
    "\n",
    "La salida de los dos componente de la compuerta de entrada se combinan multiplicándolos componente a componente, para obtener el tensor con la información que debe subir al estado de la celda. Así la entrada neta a la banda transportadora será $i_t \\ast \\tilde{C}_t$. Aquí, el símbolo $\\ast$ indica multiplicación componente a componente de los correspondientes tensores.\n",
    "\n",
    "En el ejemplo de nuestro modelo de lenguaje, queremos agregar el género del nuevo sujeto al estado de la celda, para reemplazar el antiguo que estamos olvidando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM3-focus-i.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "Puerta  de entrada</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Imagen tomada de [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actualización del estado de la celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de actualizar el estado de la celda anterior, $ C_{t − 1} $, en el nuevo estado de la celda $ C_t $. Los pasos anteriores ya decidieron qué hacer, solo tenemos que hacerlo.\n",
    "\n",
    "\n",
    "Multiplicamos el estado anterior por $ f_t $ para obtener $f_t \\ast C_{t-1}$, olvidando las cosas que decidimos olvidar antes. Luego agregamos $ i_t \\ast \\tilde{C}_t $. Estos son los nuevos valores candidatos, escalados según cuánto decidimos actualizar cada valor de estado.\n",
    "\n",
    "En el caso del modelo de lenguaje, aquí es donde realmente soltaríamos la información sobre el género del sujeto anterior y agreguemos la nueva información, como decidimos en los pasos anteriores.\n",
    "\n",
    "La imagen ilustra la actualización completa del estado de la celda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM3-focus-C.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "Actualización del estado de la celda</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Imagen tomada de [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compuerta de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, la capa LSTM debe decidir qué va a `generar` cada caso, es decir, definir cual será la predicción de la capa en el paso $t$. La predicción es implementada con una nueva compuerta que llamaremos **compuerta de salida**.\n",
    "\n",
    "Esta salida se basa en el estado actual de la celda, luego de haber sido actualizada,  pero será una versión filtrada. La compuerta de salida tiene dos componentes:\n",
    "\n",
    "* Un módulo neuronal, que como antes se encargará de seleccionar el contenido de la predicción. Este es un módulos con matriz de pesos y sesgo dados por $W_o$ y $b_o$ respectivamente. La activación es sigmoide en este caso. la salida de este módulo neuronal erá denotada como $o_t$.\n",
    "* El segundo componente es el estado actual de la banda transportadora. Ese estado es filtrado con una activación $\\tanh$. La predicción neta es entonces $h_t = o_t \\ast C_t$.\n",
    "\n",
    "Para el ejemplo del modelo de lenguaje, dado que acaba de ver un tema, es posible que desee generar información relevante para un verbo, en caso de que eso sea lo que viene a continuación. Por ejemplo, podría generar si el sujeto es singular o plural, de modo que sepamos en qué forma se debe conjugar un verbo si eso es lo que sigue a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/LSTM3-focus-o.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">\n",
    "Salida</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Imagen tomada de [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Estructura Matemática de una red LSTM </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con lo descrito arriba, una capa LSTM opera de la siguiente forma.\n",
    "\n",
    "* En el paso $t$ el estado de la celda $ C_t $ se actualiza de la siguiente manera\n",
    "$$\n",
    "\\begin{align}\n",
    "f_t &= \\sigma(W_f\\cdot [h_{t-1}, x_t] + b_f)\\\\\n",
    "i_t &= \\sigma(W_i\\cdot [h_{t-1}, x_t] + b_i)\\\\\n",
    "\\tilde{C}_t &= \\tanh(W_c\\cdot [h_{t-1}, x_t] + b_c)\\\\\n",
    "C_t &= f_t \\ast C_{t-1} + i_t\\ast  \\tilde{C}_t,\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "en donde $ \\ast$ es el producto de Hadamard o producto componente a componente  de tensores.\n",
    "* Al final de cada paso, al red LSTM genera un predicción, el estado oculto $ h_t $, el cual se actualiza después de que $ C_t $ se haya actualizado de la siguiente manera\n",
    "$$\n",
    "\\begin{align}\n",
    "o_t &= \\sigma(W_o\\cdot [h_{t-1}, x_t] + b_o)\\\\\n",
    "h_t &=  o_t \\ast \\tanh(C_t).\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Estas son las ecuaciones requeridas para calcular el gradiente de los parámetros de una capa LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Cálculo del número de parámetros de una capa LSTM</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que el tamaño de entrada es $n$ y que el tamaño de salida de la capa LSTM es *p*.\n",
    "\n",
    "Entonces $h$ que es la salida tiene tamaño *p* y $x$ tiene tamaño *n*. Por lo tanto para que los operaciones indicadas puedan hacerse se requiere que\n",
    "\n",
    "1. $W_f$, $W_c$, $W_i$ y $W_o$ tienen tamaño $p\\times (p+n)$. Osea en total $4(p*p  + p*n)$.\n",
    "2. Si se incluyen bias (que es lo común), son $4p$ parámetros adicionales, y en total se tiene que\n",
    "\n",
    "$$\n",
    "\\text{Número de parámetros capa LSTM } = 4(p^2+ pn +p)\n",
    "$$\n",
    "\n",
    "La siguiente imagen muestra la estructura típica de una compuerta en el modelo LSTM. Se ilustra la activación *sigmoide* y *tanh*, porque téngase en cuenta que en la compuerta de actualización la activación es *tanh*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/compuerta_LSTM.jpg\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Fuente: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, la siguiente imagen revela el plano de una capa neuronal de tipo LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/plano_lstm.jpg\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Imagen: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Computación  en una capa LSTM de Keras</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cualquier capa de Keras siempre espera un batch de datos. En el caso de una capa LSTM Keras espera tensores 3D de la siguiente forma\n",
    "\n",
    "+ [batch_size, window_len, _num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo un tensor de entrada de tamaño [32, 10, 8], la capa Keras lo interpreta como\n",
    "- batch_size = 32, es decir 32 ejemplos.\n",
    "- window_len = 10, es decir secuencias de entrada de tamaño 10. Por ejemplo en una serie de tiempo este es el tamaño de la ventana de entrada.\n",
    "- num_features = 8, es decir la variable de entrada es de tamaño 8. Por ejemplo, en series de tiempo univariadas, feature = 1. En una serie multivariada con 8 variables, features = 8. En modelos de lenguaje natural feature = tamaño de representación de a cada token. Usualmente correspondería al tamaño del sumergimiento(embedding).\n",
    "\n",
    "La salida de la capa corresponde al tamaño del estado oculto. Por ejemplo, si el estado oculto tiene tamaño 4, la salida de la capa es de tamaño [batch_size, 4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputs = tf.random.normal([32,10,8])\n",
    "lstm = tf.keras.layers.LSTM(4) # lstm es una capa de tamaño de salidad 4.\n",
    "output = lstm(inputs)\n",
    "print (output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recibiendo toda la secuencia del valor del estado oculto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos es necesario disponer del valor del estado oculto para cada valor en la secuencia de entrada. Esta secuencia tiene tamaño [batch_size, time_step, output_size]\n",
    "En el siguiente ejemplo se tiene que\n",
    "\n",
    "- `return_sequences` son todos lo estados del estado oculto\n",
    "- `return_state` es el último valor del estado oculto\n",
    "- `final_carry_state` es el último valor de la banda transportadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.layers.LSTM(4, return_sequences = True, return_state=True)\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 4)\n",
      "(32, 4)\n",
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "print(whole_seq_output.shape)\n",
    "print(final_memory_state.shape)\n",
    "print(final_carry_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_seq_output[:,-1,:] == final_memory_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de los pesos de la capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = lstm.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que los pesos de la capa LSTM Están organizados de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 4 # tamaño del estado oculto\n",
    "W = lstm.get_weights()[0]\n",
    "W_x_f = W[:,:units]\n",
    "W_x_i = W[:, units:units*2]\n",
    "W_x_c = W[:, units*2:units*3]\n",
    "W_x_o = W[:,units*3:]\n",
    "\n",
    "U = lstm.get_weights()[1]\n",
    "U_x_f = W[:,:units]\n",
    "U_x_i = W[:, units:units*2]\n",
    "U_x_c = W[:, units*2:units*3]\n",
    "U_x_o = W[:,units*3:]\n",
    "\n",
    "b = lstm.get_weights()[2] \n",
    "b_x_f = b[:units]\n",
    "b_x_i = b[ units:units*2]\n",
    "b_x_c = b[units*2:units*3]\n",
    "b_x_o = b[units*3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Regresar al inicio](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
