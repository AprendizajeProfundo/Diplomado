{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850d8c65-cf49-4c62-8d3e-7991a941f2d4",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45bbdf-1e03-452a-9518-832bfb7d2c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center>Pytorch-lightning</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a5d93-2fd1-4f5c-b7d3-d37508e35d94",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/Large_lightning_bolt.jpg\" width=\"800\" height=\"800\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: <a href=\"https://commons.wikimedia.org/wiki/File:Large_lightning_bolt.jpg\">Guilerms</a>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\">CC BY-SA 4.0</a>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9470be15-7c36-49e1-9ec2-b8650e584f05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Coordinador</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c1e2f-b3b4-46d2-af72-72771bc310a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- Campo Elías Pardo, PhD, cepardot@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afdaea4-8930-4dc0-9cc3-dc3d31f1542d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc098b33-843d-4f75-98d7-f70610004198",
   "metadata": {},
   "source": [
    "1. Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "1. Camilo José Torres Jiménez, Msc, cjtorresj@unal.edu.co\n",
    "1. Daniel  Montenegro, Msc, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1029c8-1e06-4ef5-b992-f36cae9d4caa",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Asesora Medios y Marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8339d77-9304-4388-9a8c-ae264360c301",
   "metadata": {},
   "source": [
    "1. Maria del Pilar Montenegro, pmontenegro88@gmail.com\n",
    "1. Jessica López Mejía, jelopezme@unal.edu.co\n",
    "1. Venus Celeste Puertas Gualtero, vpuertasg@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd96f054-2fc2-4f85-b62c-c03d2c204b10",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Jefe Jurídica</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6222dad-4270-466b-bfa5-c31e4a0f9006",
   "metadata": {},
   "source": [
    "6. Paula Andrea Guzmán, guzmancruz.paula@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714da2ce-e7ba-42e4-8925-434229ec3c1a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Coordinador Jurídico</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83341e02-6fd3-449e-8495-aeacd223bc3d",
   "metadata": {},
   "source": [
    "7. David Fuentes, fuentesd065@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f8b6f-193a-49dc-a08b-2f0c6abf7e47",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Desarrolladores Principales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c999d7-ec87-435d-812c-df5e05ac882f",
   "metadata": {},
   "source": [
    "8. Dairo Moreno, damoralesj@unal.edu.co\n",
    "9. Joan Castro, jocastroc@unal.edu.co\n",
    "10. Bryan Riveros, briveros@unal.edu.co\n",
    "11. Rosmer Vargas, rovargasc@unal.edu.co\n",
    "12. Venus Puertas, vpuertasg@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bcf746-2063-499d-a4a5-87064001247b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Expertos en Bases de Datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ac84c-d227-4b6f-9efa-6de06723f473",
   "metadata": {
    "tags": []
   },
   "source": [
    "13. Giovvani Barrera, udgiovanni@gmail.com\n",
    "14. Camilo Chitivo, cchitivo@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95dcf83-89c8-41a2-95d2-d359876a745d",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f1544-61e0-41a9-bae4-480dd4fbe088",
   "metadata": {},
   "source": [
    "1. [Alvaro Montenegro y Daniel Montenegro, Inteligencia Artificial y Aprendizaje Profundo, 2023](https://github.com/AprendizajeProfundo/Diplomado)\n",
    "1. [Alvaro Montenegro, Daniel Montenegro y Oleg Jarma,  Inteligencia Artificial y Aprendizaje Profundo Avanzado, 2023](https://github.com/AprendizajeProfundo/Diplomado-Avanzado)\n",
    "1. [Tutoriales de Pytorch](https://pytorch.org/tutorials/)\n",
    "1. [Pytorchlightning.ai](https://www.pytorchlightning.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0961e2-f9a2-4a22-a215-15441aa3f0df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e76b5f-dfa0-4ef0-8298-7537151772b5",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Instalar Pytorch-lightning](#Instalar-Pytorch-lightning)\n",
    "* [Ejemplo de un módulo Lightning](#Ejemplo-de-un-módulo-Lightning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8e8fd-b4d2-4d44-8511-718af854d4bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d026e31-2c95-4a27-9da0-45331b02c810",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/trainer.png\" width=\"800\" height=\"800\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab698e08-33bf-45c2-8b16-306084b6bf78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02e2c2-0e22-4f37-8e7d-021c3bad1b04",
   "metadata": {},
   "source": [
    "En esta lección aprendemos como construir una modelo de clasificación de imágenes a color. Usaremos el framework [Pytorch-lightning](https://www.pytorchlightning.ai/) para construir el modelo y el conjunto de datos [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). La siguiente figura los tipos de datos que se usarán en esta lección. El contenido es una adaptación libre del tutorial [Image Classification using PyTorch Lightning](https://wandb.ai/wandb/wandb-lightning/reports/Image-Classification-using-PyTorch-Lightning--VmlldzoyODk1NzY) de [WandB](https://wandb.ai/site)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bcd09b-7e30-47ed-b57d-d232193cb03f",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/cifar10.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: [Universidad de Toronto-Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21048ee9-8cbe-49f6-b8f6-03261e092621",
   "metadata": {},
   "source": [
    "Para esta lección usaremos los datos CIFAR10 disponibles en los datasets de la librería [Torchvision](https://pytorch.org/vision/stable/index.html). Adicionalmente usaremos [Weights and bias-Wandb](https://wandb.ai/site), una plataforma moderna que puede apoyar para crear mejores modelos, más rápido con el seguimiento de experimentos, el control de versiones de conjuntos de datos y la gestión de modelos. WandB debe instalarse por separado, pero se incorpora a la librería `pytorch_lightning.loggers`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14327a65-1c99-4832-b575-49ae84437201",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Preparación de los datos</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962b5c6-b5b5-49fb-b7da-2ab6656c1ac0",
   "metadata": {},
   "source": [
    "Los `DataModule` son una forma de desacoplar enlaces relacionados con datos del LightningModule para que pueda desarrollar modelos agnósticos de conjuntos de datos. En otra palabras, con DataModule puede preparar los datos por fuera del módulo de entrenamiento, de tal manera que peude cambiar sus datos sin tocar el módulo de entrenamiento.\n",
    "\n",
    "Con `DataModule` podemos organiza la canalización de datos en una clase compartible y reutilizable. Un módulo de datos encapsula los cinco pasos involucrados en el procesamiento de datos en PyTorch:\n",
    "\n",
    "* Descargar/tokenizar/procesar.\n",
    "* Limpiar y (tal vez) guardar en el disco.\n",
    "* Cargar dentro del conjunto de datos.\n",
    "* Aplicar transformaciones (rotar, tokenizar, etc.).\n",
    "* Envolver dentro de un DataLoader.\n",
    "\n",
    "\n",
    "Obtenga más información sobre los módulos de datos [aquí](https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html). Construyamos un módulo de datos para el conjunto de datos Cifar-10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de02b2c-3da4-429e-bd12-7b20b0640afd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Carga las librerías requeridas</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6fa436-86f2-4db4-92a2-60250534ce69",
   "metadata": {},
   "source": [
    "Instale la libreria wandb con el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c02d38-9fcb-49d6-ad2a-1d5d66c1f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea02acc2-4c38-4778-9914-f27a297fdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Carga DataLoader para crear los dataloaders\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Librería Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# métricas\n",
    "import torchmetrics \n",
    "\n",
    "# Carga WandBLogger para hacer seguimiento (tracking) del entrenamiento\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# carga el dataset CIFAR10\n",
    "import torchvision.datasets as datasets\n",
    "CIFAR10 = datasets.CIFAR10\n",
    "\n",
    "# callbacks\n",
    "from pytorch_lightning.callbacks import Callback \n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3c9bc5-bf5d-41bc-a8b6-7d15ee9c1e24",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Canalización (pipeline) de los datos con DataModule</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d42586-b397-470c-8ccb-41a58581ba35",
   "metadata": {},
   "source": [
    "Construimos una clase derivada de `LightningDataModule` específica para CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78e554bb-eeb6-47b2-9820-883b2751fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.datasets as datasets\n",
    "CIFAR10 = datasets.CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, batch_size, data_dir: str = './', num_workers=4):\n",
    "        \"\"\"\n",
    "        Pasaremos los hiperparámetros necesarios para nuestra canalización de datos\n",
    "        También definiremos la canalización de transformación de datos aquí.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        self.dims = (3, 32, 32)\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Aquí es donde definiremos la lógica para descargar nuestro conjunto de datos. \n",
    "        Estamos utilizando la clase de conjunto de datos CIFAR10 de torchvision para descargar.\n",
    "        Use este método para hacer cosas que podrían escribirse en el disco \n",
    "        o que deben hacerse solo desde una única GPU en configuraciones distribuidas. \n",
    "        No haga ninguna asignación de estado en esta función \n",
    "        (es decir, self.alguna_cosa = ...).\n",
    "        \"\"\"\n",
    "        # descarga\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"\n",
    "        Aquí es donde cargaremos los datos del archivo y prepararemos \n",
    "        los conjuntos de datos del tensor PyTorch para cada división de los datos. \n",
    "        La división de datos es por lo tanto reproducible. \n",
    "        Este método espera un argumento de etapa (stage) que se utiliza para separar \n",
    "        la lógica de 'entrenamiento' y de 'prueba'. \n",
    "        Esto es útil si no queremos cargar todo el conjunto de datos a la vez. \n",
    "        Las operaciones de datos que queremos realizar en cada GPU se definen aquí. \n",
    "        Esto incluye aplicar la transformación al conjunto de datos del tensor de PyTorch.\n",
    "        \"\"\"        \n",
    "        # Asigna datos a los datasets de entrenamiento/validación  \n",
    "        # para uso en los dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Asigna dataset de prueba para uso en los  dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    # Métodos para crear los dataloaders        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=self.batch_size, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ded3e1-3cf2-4f1e-88a4-def6bbf41d45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Devolución de llamadas (Callbacks)</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfeab5-2add-46f5-913e-e56b3c479883",
   "metadata": {},
   "source": [
    "Una devolución de llamada o `callback` es un programa autónomo que se puede reutilizar en todos los proyectos. PyTorch Lightning viene con algunos callbacks integrados que se usan regularmente.\n",
    "Obtenga más información sobre callbacks en PyTorch Lightning [aquí](https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a454fe0c-98d7-4d59-b0ab-b590c20b6344",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Devoluciones  de llamada integrados</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a219f-6c4d-457e-b826-304cb432d4c1",
   "metadata": {},
   "source": [
    "En este tutorial, utilizaremos las devoluciones de llamada integradas de parada anticipada `Early Stopping` y punto de control `checkpoint` de modelo. Estos callback se pueden pasar al entrenador (`Trainer`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c264f-39f7-4c9e-bdfb-4c5054d4b5b4",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Devoluciones de llamada personalizados</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d48f6-0cce-4817-b1d4-d2a79bf88936",
   "metadata": {},
   "source": [
    "Si está familiarizado con la devolución de llamada personalizada de `Keras`, la capacidad de hacer lo mismo en su canalización de PyTorch es solo una cereza del pastel.\n",
    "\n",
    "Dado que estamos realizando una clasificación de imágenes, la capacidad de visualizar las predicciones del modelo en algunas muestras de imágenes puede resultar útil. Esto en forma de callback puede ayudar a depurar el modelo en una etapa temprana. Así que vamos a implementar un callback personalizado para tal fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dab2ec98-0a0c-4601-bbd0-b4bd0478f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePredictionLogger(Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        \"\"\"\n",
    "        ImagePredictionLogger es una subclase de la clase Callback de PyTorch Lightning. \n",
    "        params:\n",
    "        val_samples: es una tupla de imágenes y etiquetas. \n",
    "        num_samples: es el número de imágenes que se registrarán en el panel de control de W&B.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        \"\"\"\n",
    "        Este método es llamado cuando finaliza la época de validación. \n",
    "        Se necesitan dos argumentos: \n",
    "        trainer: entrenador del modelo\n",
    "        pl_module: módulo del modelo\n",
    "        Ambos parámetros son pasados automáticamente por el trainer.\n",
    "        Al usar trainer.logger.experimental podemos usar todas las funciones disponibles por Pesos y sesgos.\n",
    "        \"\"\"\n",
    "        # Trasladar los tensors a CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Obtener la predicción del modelo\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)\n",
    "        # Pasa las imágenes al logger como  wandb Image\n",
    "        trainer.logger.experiment.log({\n",
    "            \"ejemplos\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
    "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
    "                                                 preds[:self.num_samples], \n",
    "                                                 val_labels[:self.num_samples])]\n",
    "            })\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3942a-b103-4171-ac33-809695545fb7",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">LightningModule - Definición del sistema</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea586c-1687-4d56-8d45-1e7057049bd3",
   "metadata": {},
   "source": [
    "`LightningModule` define un sistema y no un modelo. Aquí, un sistema agrupa todo el código de investigación en una sola clase para que sea autónomo. LightningModule organiza su código PyTorch en 5 secciones:\n",
    "\n",
    "* Bucle de entranamiento (training_step)\n",
    "* Bucle de validación (validation_step)\n",
    "* Bucle de prueba (test_step)\n",
    "* Optimizadores (configure_optimizers)\n",
    "\n",
    "\n",
    "Por lo tanto, se puede construir un modelo agnóstico del conjunto de datos que se puede compartir fácilmente. Construyamos un sistema para la clasificación Cifar-10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8d5a6b-1c04-47e1-952a-ac6378e428dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self,  backbone,  learning_rate=2e-4, ):\n",
    "        super().__init__()\n",
    "        # activa log para almacenar los hiperparámetros\n",
    "        self.save_hyperparameters()\n",
    "        # modelo\n",
    "        self.backbone = backbone\n",
    "        # rata  de aprendizaje para el optimizador\n",
    "        self.learning_rate = learning_rate\n",
    "        # métricas\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.valid_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "            \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Lightning automatiza la mayor parte del entrenamiento para nosotros, \n",
    "        la época y las iteraciones por lotes, todo lo que necesitamos mantener \n",
    "        es la lógica del paso de entrenamiento. El método training_step requiere argumentos \n",
    "        batch y batch_idx que el Entrenador pasa automáticamente. \n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y) # entropía cruzada: negative log likelihood\n",
    "        \n",
    "        # training metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.train_acc(preds, y)\n",
    "        #self.log('perdida_entrenamiento', loss )\n",
    "        #self.log('precision_entrenamiento', acc)\n",
    "        wandb.log({\"acc_train\": acc, \"loss_train\": loss})\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        el ciclo de validación se puede implementar sobrescribiendo este método \n",
    "        de LightningModule\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.valid_acc(preds, y)\n",
    "        #self.log('perdida_validacion', loss, prog_bar=True)\n",
    "        #self.log('precision_validacion', acc, prog_bar=True)\n",
    "        wandb.log({\"acc_test\": acc, \"loss_test\": loss})\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Este método similar al ciclo de validación. \n",
    "        La única diferencia es que en prueba solo se llama \n",
    "        cuando se usa trainer.test(). \n",
    "        Las métricas se registran automáticamente por épocas.\n",
    "        \"\"\"\n",
    "        x, y = batch\n",
    "        logits = self.backbone(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.test_acc(preds, y)\n",
    "        #self.log('perdida_test', loss, prog_bar=True)\n",
    "        #self.log('precision_test', acc, prog_bar=True)\n",
    "        wandb.log({\"acc_test\": acc, \"loss_test\": loss})\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Podemos definir nuestro optimizador y programadores \n",
    "        de tasa de aprendizaje usando el método \n",
    "        configure_optimizer. \n",
    "        Incluso se pueden definir múltiples optimizadores \n",
    "        como en el caso de las GAN.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.backbone.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418c3ed0-d909-42b6-8e71-73e094ef4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, input_shape, num_classes, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_shape = input_shape\n",
    "        self.num_clases = num_classes\n",
    "        \n",
    "         # bloque convolucional: cuerpo de la red\n",
    "        \"\"\"\n",
    "        CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, \n",
    "        padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "        \"\"\"\n",
    "        CLASS torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, \n",
    "        return_indices=False, ceil_mode=False)\n",
    "        \"\"\"\n",
    "        self.pool1 = torch.nn.MaxPool2d(2)\n",
    "        self.pool2 = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "        n_sizes = self._get_conv_output(input_shape)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(n_sizes, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "\n",
    "        self.accuracy = torchmetrics.Accuracy(task ='multiclass', num_classes=self.num_clases)\n",
    "\n",
    "\n",
    "    # Calcula el tamaño de salida del bloque convolucional\n",
    "    # métodos auxiliares para calcular el tamaño de salida\n",
    "    # del bloque convolucion. Se requiere ara poder configurar \n",
    "    # totalmente la red. No requrido en Keras\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "\n",
    "        output_feat = self._forward_features(input) \n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "        \n",
    "    # devuelve el tensor de características del bloque conv\n",
    "    def _forward_features(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool2(F.relu(self.conv4(x)))\n",
    "        return x\n",
    "    \n",
    "    # forward\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "       \n",
    "        return x\n",
    "\n",
    "    # paso de entrenamiento\n",
    "    def training_step(self, batch, batch_idx):\n",
    "            x, y = batch\n",
    "            logits = self(x)\n",
    "            loss = F.nll_loss(logits, y)\n",
    "\n",
    "            # training metrics\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc = self.accuracy(preds, y)\n",
    "            self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "            self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "            return loss\n",
    "\n",
    "    # paso de validación\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "            x, y = batch\n",
    "            logits = self(x)\n",
    "            loss = F.nll_loss(logits, y)\n",
    "\n",
    "\n",
    "            # validation metrics\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc = self.accuracy(preds, y)\n",
    "            self.log('val_loss', loss, prog_bar=True)\n",
    "            self.log('val_acc', acc, prog_bar=True)\n",
    "            return loss\n",
    "\n",
    "    # paso de prueba\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # optimizador\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff167f-641b-4454-9769-5e95be9af68a",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Entrenamiento y Evaluación</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16fc9a4-d3e4-48d6-968c-f111578fe4ae",
   "metadata": {},
   "source": [
    "Ahora que organizamos nuestra canalización de datos con `DataModule` y modelamos la arquitectura del modelo con `nn.Module` y el ciclo de entrenamiento con `LightningModule`, PyTorch Lightning `Trainer` automatiza todo lo demás por nosotros.\n",
    "\n",
    "El Entrenador automatiza:\n",
    "\n",
    "* Iteración de época y lote\n",
    "* Llamada de `optimizer.step()`, `backward`, `zero_grad()`\n",
    "* Llamada de `.eval()`, habilitación/deshabilitación de gradientes\n",
    "* Guardar y cargar pesos\n",
    "* Registro de pesos y sesgos\n",
    "* Soporte de entrenamiento multi-GPU\n",
    "* Soporte de TPU\n",
    "* soporte de entrenamiento de 16 bits\n",
    "\n",
    "\n",
    "Primero inicializaremos nuestra canalización de datos. El Entrenador solo necesita un  DataLoader de PyTorch para los datos de entrenamiento/val/prueba. \n",
    "\n",
    "Podemos pasar directamente el objeto `dm` que hemos creado al Entrenador. Pero dado que necesitamos algunas muestras para nuestro `ImagePredictionLogger`, llamaremos manualmente a los métodos *prepare_data* y *setup*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575df58-12a7-4c57-a0bb-99735900c002",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia los datos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af0b5830-b278-4409-a04a-f0f00ff51ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializa la canalización de los datos\n",
    "dm = CIFAR10DataModule(batch_size=32)\n",
    "# Para acceder a los  x_dataloader prepara los datos y configurar\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "\n",
    "# Muestras requeridas por la devolución de llamada personalizada de ImagePredictionLogger \n",
    "# para registrar predicciones de imágenes.\n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f223c4-5ad7-46b8-9f88-f984d9904502",
   "metadata": {},
   "source": [
    "Solo necesitamos inicializar el modelo y nuestro logger favorito. Tenga en cuenta que hemos pasado checkpoint_callback por separado. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e05fba-eca3-4590-a344-ffff7994da9c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "812ed2f8-fec5-4855-b01d-ec282a1c3123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitModel(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=108, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (accuracy): MulticlassAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instnacia el modelo\n",
    "inputshape = (3,32, 32)\n",
    "numclases = 10\n",
    "\n",
    "model = LitModel(inputshape, numclases)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34536afb-b003-4ed7-b866-dee50105f6b0",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Instancia el trainer</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dea1c5b-27be-4b2a-ad23-034b165815d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa wandb logger\n",
    "wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf378de5-c068-4100-abcb-746edcd0d6b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a parent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize a trainer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mImagePredictionLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/argparse.py:69\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:421\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate_grad_batches \u001b[38;5;241m=\u001b[39m accumulate_grad_batches\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# init callbacks\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Declare attributes to be set in _callback_connector on_trainer_init\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trainer_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_checkpointing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_root_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_model_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# init data flags\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_val_every_n_epoch: Optional[\u001b[38;5;28mint\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:79\u001b[0m, in \u001b[0;36m_CallbackConnector.on_trainer_init\u001b[0;34m(self, callbacks, enable_checkpointing, enable_progress_bar, default_root_dir, enable_model_summary, max_time)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_model_summary_callback(enable_model_summary)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mextend(_configure_external_callbacks())\n\u001b[0;32m---> 79\u001b[0m \u001b[43m_validate_callbacks_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# push all model checkpoint callbacks to the end\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# it is important that these are the last callbacks to run\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reorder_callbacks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallbacks)\n",
      "File \u001b[0;32m~/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:252\u001b[0m, in \u001b[0;36m_validate_callbacks_list\u001b[0;34m(callbacks)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_callbacks_list\u001b[39m(callbacks: List[Callback]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m     stateful_callbacks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_overridden\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    253\u001b[0m     seen_callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m stateful_callbacks:\n",
      "File \u001b[0;32m~/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:252\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_callbacks_list\u001b[39m(callbacks: List[Callback]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m     stateful_callbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_overridden\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    253\u001b[0m     seen_callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m stateful_callbacks:\n",
      "File \u001b[0;32m~/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/model_helpers.py:34\u001b[0m, in \u001b[0;36mis_overridden\u001b[0;34m(method_name, instance, parent)\u001b[0m\n\u001b[1;32m     32\u001b[0m         parent \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mCallback\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a parent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_overridden \u001b[38;5;28;01mas\u001b[39;00m _is_overridden\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _is_overridden(method_name, instance, parent)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a parent"
     ]
    }
   ],
   "source": [
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(max_epochs=50,\n",
    "                     logger=wandb_logger,\n",
    "                     callbacks=[EarlyStopping,\n",
    "                                ImagePredictionLogger(val_samples)]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f73c8d7-5fb4-405c-86c3-d8913cc8c8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mammontenegrod\u001b[0m (\u001b[33maprendizaje-profundo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/alvaro/Documents/AprendizajeProfundo/Diplomado_UNAL/Diplomado-master_sep_2022/Temas/Módulo 15- Pytorch/Cuadernos/wandb/run-20230512_161104-wdv7ffmq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aprendizaje-profundo/CIFAR10/runs/wdv7ffmq' target=\"_blank\">dauntless-wind-3</a></strong> to <a href='https://wandb.ai/aprendizaje-profundo/CIFAR10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aprendizaje-profundo/CIFAR10' target=\"_blank\">https://wandb.ai/aprendizaje-profundo/CIFAR10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aprendizaje-profundo/CIFAR10/runs/wdv7ffmq' target=\"_blank\">https://wandb.ai/aprendizaje-profundo/CIFAR10/runs/wdv7ffmq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/aprendizaje-profundo/CIFAR10/runs/wdv7ffmq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7b8f60f410>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configura el logger wandb\n",
    "import wandb\n",
    "\n",
    "wandb.init(project='CIFAR10', \n",
    "           config={\n",
    "           \"learning_rate\": 0.02,\n",
    "           \"architecture\": \"CNN\",\n",
    "           \"dataset\": \"CIFAR-100\",\n",
    "           \"epochs\": 2,\n",
    "            }\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f850465-4a7a-4da6-b98d-8bf178293907",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrena el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f41ea-411f-4afb-9ccc-1b94a2e34474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena el modelo\n",
    "trainer.fit(model, dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40b98b-522c-4d6d-895c-eb65c394862c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Evalua el modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6781480-fdd4-483d-adcf-4c3b01ba34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalua el modelo en el conjunto de prueba retenido\n",
    "trainer.test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28055c6-1523-4252-949e-6d6b506ecf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
