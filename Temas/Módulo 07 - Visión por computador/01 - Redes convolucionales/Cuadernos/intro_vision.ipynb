{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343a0bcb-f750-483e-a3c4-8f38b2e6e96c",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde52a1-3f13-444a-aad0-117f56d85efd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e02a4-a38a-458c-b86f-b5b01a63f55b",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"><center>Introducción a visión artificial</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5d8f3-a996-4164-8a36-9023366fc775",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/Laser_Vision.jpg\" width=\"300\" height=\"200\" align=\"center\"/>\n",
    "<figcaption>Convoluciones</figcaption>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: <a href=\"https://commons.wikimedia.org/wiki/File:Convolutional_Neural_Network_with_Color_Image_Filter.gif\">Cecbur</a>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\">CC BY-SA 4.0</a>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30203e7-476b-4aac-9d65-1556c2910224",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa067e-3e65-49e1-ad9c-0974cea1a907",
   "metadata": {},
   "source": [
    "1. Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "1. Camilo José Torres Jiménez, Msc, cjtorresj@unal.edu.co\n",
    "1. Daniel  Montenegro, Msc, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418856f2-eded-40a7-b4ba-8e9b39a00340",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Asesora Medios y Marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f1ab3-c420-400a-a2b0-5362bfec18b5",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com\n",
    "5. Jessica López Mejía, jelopezme@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41229c4-384e-48b6-b712-273737123a7e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Jefe Jurídica</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd853666-538d-4ad5-8fc8-f465f3d2cbae",
   "metadata": {},
   "source": [
    "6. Paula Andrea Guzmán, guzmancruz.paula@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c860dc9-762d-480d-8b3f-da8125322500",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Coordinador Jurídico</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b5ba1-f2c0-4988-9906-e65b89638f37",
   "metadata": {},
   "source": [
    "7. David Fuentes, fuentesd065@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f945408-35ce-4632-b5e4-d0050b562452",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Desarrolladores Principales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a0ec7-d2a5-4cfe-a7de-5f7e0db5fb46",
   "metadata": {},
   "source": [
    "8. Dairo Moreno, damoralesj@unal.edu.co\n",
    "9. Joan Castro, jocastroc@unal.edu.co\n",
    "10. Bryan Riveros, briveros@unal.edu.co\n",
    "11. Rosmer Vargas, rovargasc@unal.edu.co\n",
    "12. Venus Puertas, vpuertasg@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f1a80-0985-438e-8882-9d28ac1c4d0e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Expertos en Bases de Datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63666039-a88a-45f5-9aa8-e7d872021b3b",
   "metadata": {},
   "source": [
    "13. Giovvani Barrera, udgiovanni@gmail.com\n",
    "14. Camilo Chitivo, cchitivo@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92573390-3e81-4a3b-a6cb-1f09fff86131",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Referencias</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab42cb6-f0f7-4d8f-b8af-aef693d18c94",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc0d5d-44ab-4065-98d4-2268680bf304",
   "metadata": {},
   "source": [
    "* [¿Qué es la Visión por Computadora](#Qué-es-la-Visión-por-Computadora)\n",
    "* [Un poco de historia](#Un-poco-de-historia)\n",
    "* [El estado del arte](#El-estado-del-arte)\n",
    "* [Paquetes a utilizar](#Paquetes-a-utilizar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f25870-1ed0-4086-a26f-dbdfe05de80a",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Qué es la Visión por Computadora</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac7f50-3332-47f0-b8f6-1e1c2f3594a4",
   "metadata": {},
   "source": [
    "La mente humana es impresionante.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/geranium-iberian_1.jpg\" width=\"400\" height=\"400\" align=\"center\"/> \n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Solo observando esta imagen, somos capaces de discernir muchas cosas sobre esta: Las sombras, lejanías, enfoques, y más, con relativa facilidad.\n",
    "\n",
    "Los computadores, por supuesto, no tienen esa capacidad.\n",
    "\n",
    "en los inicios del desarrollo de la Inteligencia artificial, se pensaba que la obtención de información en el medio visual iba a ser una tarea sencilla. Algo muy alejado de la verdad\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/tasks.png\" width=\"200\" height=\"400\" align=\"center\"/> \n",
    "<figcaption>Fuente: xkcd.com</figcaption>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "¿Por qué es tan difícil esta tarea? Porque estamos haciendo lo inverso a lo usual.\n",
    "\n",
    "El campo de los gráficos de computador, en muchos casos, trata de simular el mundo y sus propiedades, y lo proyecta en una pantalla.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/aloy-horizon-forbidden-west.gif\" width=\"600\" height=\"400\" align=\"center\"/> \n",
    "<figcaption>Fuente: Horizon Forbidden West</figcaption>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "En la Visión por computadora estamos haciendo lo contrario. A partir de una pantalla o una imagen en 2D, queremos recuperar la información, y describir el mundo a nuestro alrededor. Algo que los humanos logramos de forma natural.\n",
    "\n",
    "A pesar de que aún no es posible que la inteligencia artificial logre los mismo resultados que los seres vivos, no signfica que no han habido grandes investigaciones y desarrollos en este campo. Las últimas dos décadas han visto increible crecimiento en el desarrollo visual, y mucho de esto es debido al poder de los datos y el desarrollo logrado por estos: Machine Learning y Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cda94c-8680-4a0f-ab9d-168dd74f01fc",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Un poco de historia</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b14c5-a5ef-4763-83c1-a36fe02e88c6",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/CV_timeline.png\" align=\"center\"/> \n",
    "<figcaption>Fuente: Richard Szeliski</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e8262-ef9e-4b6d-9bc5-260008d958e7",
   "metadata": {},
   "source": [
    "- 1970\n",
    "    - Inicios en la detección de bordes\n",
    "    - Etiquetado de lineas\n",
    "    - cilíndros generalizados para modelación 3D\n",
    "- 1980\n",
    "    - Representación de pirámide\n",
    "    - Estereo, textura y foco\n",
    "    - Procesamiento de datos tridimensionales\n",
    "- 1990\n",
    "    - Invariantes proyectivas\n",
    "    - Vectores propios para reconocimiento facial\n",
    "    - Integración con técnicas de gráficos de computador\n",
    "- 2000\n",
    "    - Fotografía computacional\n",
    "    - Aprendizaje para reconocimiento de objetos\n",
    "    - Primeras aplicaciones de Machine Learning\n",
    "- 2010\n",
    "    - Uso de Bases de datos etiquetados\n",
    "    - Uso de GPUs\n",
    "    - Deep Learning y grandes arquitecturas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da85808-9c93-4fd5-8b29-1167afc0929e",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">El estado del arte</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff67cc-f1a5-4cfe-a921-99084314af79",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Detección Avanzada de Objetos</span>\n",
    "\n",
    "Ya se ha pasado de simples reconocimientos de rostros u objetos específicos a una detección completa, de diferentes asuntos en una misma foto y con altos detalles dentro de la detección\n",
    "\n",
    "<figure>\n",
    "<img src=\"../Imagenes/R-CNN.png\" width=\"600\" height=\"300\" align=\"center\"/> \n",
    "<figcaption>Fuente: towardsdatascience.com</figcaption>\n",
    "</figure>\n",
    "\n",
    "### <span style=\"color:blue\">Redes generativas adversarias</span>\n",
    "\n",
    "Se trabaja con dos modelos. uno que genera nuevas imágenes, y otro que detecta si esta son reales o creadas artificialmente. Se pone a estos dos modelos a \"Competir\", y gradualmente ambos irán mejorando en sus tareas.\n",
    "\n",
    "<figure>\n",
    "<img src=\"../Imagenes/gan1.png\" width=\"400\" height=\"300\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "<img src=\"../Imagenes/gan2.png\" width=\"400\" height=\"300\" align=\"center\"/> \n",
    "<figcaption>Fuente: tensorflow.com</figcaption>\n",
    "</figure>\n",
    "\n",
    "Entre otras aplicaciones se encuentra la generación de contenido de alta definición a base de simples garabatos\n",
    "\n",
    "[![GauGAN](https://img.youtube.com/vi/mlZYRwJ2oJg/0.jpg)](https://www.youtube.com/watch?v=mlZYRwJ2oJg)\n",
    "\n",
    "\n",
    "### <span style=\"color:blue\">Deep Learning Super Sampling</span>\n",
    "\n",
    "Los videojuegos pueden implicar mucho poder en la tarjeta gráfica, en especial cuando se están llegando a resoluciones como 4K y más allá. Además encuentran problemas como el Aliasing.\n",
    "\n",
    "<figure>\n",
    "<img src=\"../Imagenes/aliasing.jpg\" width=\"300\" height=\"300\" align=\"center\"/> \n",
    "<figcaption>Fuente: fotonostra.com</figcaption>\n",
    "</figure>\n",
    "\n",
    "Nvidia para solucionar esto, entrenaron su propia red neuronal con una base de datos de múltiples capturas de juegos en múltiples resoluciones. Con esto el modelo aprende cómo las imágenes se deben ver\n",
    "\n",
    "[![DLSS](https://img.youtube.com/vi/SBjL0M25t04/0.jpg)](https://www.youtube.com/watch?v=SBjL0M25t04)\n",
    "\n",
    "### <span style=\"color:blue\">Estimación de poses</span>\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/body_pose.gif\" width=\"200\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Se entrenan redes cuya intención es detectar cuerpos y a la vez definir dónde están las articulaciones clave. En una imagen es sencillo, pero mezclamos todo esto en video y se vuelve más complicado\n",
    "\n",
    "### <span style=\"color:blue\">Modelos de difusión</span>\n",
    "\n",
    "Estos son modelos generativos que aprenden a \"reconstruir\" la imagen. Se aplicam capas y capas de ruido sobre los datos de entrenamiento y el modelo aprende a recuperar las imagenes a partir de la reversión del ruido. Luego se pasa cualquier tipo de ruido a la imagen y esta puede generar sus propias versiones de las imagenes. \n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/diffusion-model.png\" width=\"700\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Es posible crear fotos de alta calidad a partir de varios tipos de entrada, por ejemplo texto u otras imagenes en otros dominios.\n",
    "\n",
    "Hay varios modelos de este tipo, como lo son [DALL-E](https://openai.com/dall-e-2/), [Midjourney](https://www.midjourney.com/home/), [craiyon](https://www.craiyon.com/) y [Stable Diffusion](https://huggingface.co/spaces/stabilityai/stable-diffusion)\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/stable-diffusion-example.png\" width=\"450\" height=\"450\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51064896-6306-4466-9241-c8a9d714f8e6",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Paquetes a utilizar</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4309eec-6a59-457d-abf5-c3357d67256f",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/OpenCV_Logo.png\" width=\"200\" height=\"200\" align=\"right\"/> \n",
    "</figure>\n",
    "\n",
    "### OpenCV \n",
    "libreria de software libre que contiene los algoritmos necesarios para el desarrollo de Visión artificial. Entre sus capacidades está el procesamiento de imágenes, análisis de video, calibración de cámaras y detección de objetos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c147c30-6d14-4a6b-a242-4adcd1c469b4",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/Librosa_Logo.png\" width=\"200\" height=\"200\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "### Librosa\n",
    "libreria para procesamiento y análisis de música y audio. Cuenta con extracción de características, decomposición, filtros, entre otras cosas. Se usa a la par con Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab38efd",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/torchvision_logo.png\" width=\"200\" height=\"200\" align=\"right\"/> \n",
    "</figure>\n",
    "\n",
    "### Torchvision\n",
    "libreria de pytorch que contiene datasets, modelos y arquitecturas prediseñadas y tranformaciones básicas de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf6720-c872-4db9-be8d-400e466b9555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
