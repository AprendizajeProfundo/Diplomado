{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diplomado en Inteligencia Artificial y Aprendizaje Profundo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Logístico de Clasificación  con Tensorflow 2.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Oleg Jarma, ojarmam@unal.edu.co\n",
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [El modelo lineal de clasificación](#El-modelo-lineal-de-clasificación)\n",
    "* [Importar los módulos requeridos](#Importar-los-módulos-requeridos)\n",
    "* [Carga del conjunto de datos Iris](#Carga-del-conjunto-de-datos-Iris)\n",
    "* [Acercamiento descriptivo a los datos](#Acercamiento-descriptivo-a-los-datos)\n",
    "* [Separa features y targets](#Separa-features-y-targets)\n",
    "* [Divide los datos: entrenamiento y validación](#Divide-los-datos:-entrenamiento-y-validación)\n",
    "* [Normaliza los datos](#Normaliza-los-datos)\n",
    "* [Construye la tuberia (pipeline) para la alimentación de datos de Tensorflow](#Construye-la-tuberia-(pipeline)-para-la-alimentación-de-datos-de-Tensorflow)\n",
    "* [Entrenamiento del Modelo](#Entrenamiento-del-Modelo)\n",
    "* [Predicciones](#Predicciones)\n",
    "* [Validación](#Validación)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código fue tomado y  adaptado de [Google Colab](https://colab.research.google.com/drive/1qNxKmi0QpkunqTDdpXfVLlneG-NFDN9c). En este ejercicio usaremos el famoso conjunto de datos *iris*. Sin embargo no se usaran todos los datos, porque en este ejercicio vamos a introducir el modelo logístico clasico que permite separar en dos clases. Los datos de la primera clase son omitidos y los datos se recodifican para tener solamente dos clases. Próximamente usaremos todos los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El modelo lineal de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este  modelo se tienen varias variables regresoras o explicativas de entrada y una variable dicotómica de salida.\n",
    "\n",
    "El propósito central es construir un modelo para predecir la probabilidad de que los elementos del espacio de entrada pertenezcan a una de dos clases, las cuales denotaremos como 0 y 1 respectivamente.\n",
    "\n",
    "Supongamos que tenemos dos variables $X_1$ y $X_2$ que se espera permitan predecir si un elemento del conjunto de entrada pertenence a una clase: clase 1 ($Y=1$) o clase 0 ($Y=0$).\n",
    "\n",
    "El modelo desde el punto de vista estadístico se escribe como\n",
    "\n",
    "$$\n",
    "[Y_i|X_1=x_{i1},X_2=x_{i2}] \\sim \\text{Bernoulli}(\\pi_i),\n",
    "$$\n",
    "\n",
    "en donde \n",
    "\n",
    "$$\n",
    "\\pi_i = \\frac{1}{1 + exp(-[b +w_1x_{i1} + w_2x_{i2})]}, i =i,\\cdots,N\n",
    "$$\n",
    "\n",
    "En el entrenamiento se encontraran los pesos $w_1,w_2,$ y el intercepto $b$ que minimizan una determinada función de pérdida, a partir de un conjunto de datos de entrenamiento. \n",
    "\n",
    "\n",
    "Una vez garantizado que la máquina generaliza bien, probando con los datos de validación, la expresión anterior se utiliza para predecir la probabilidad que un nuevo valor no observado en el espacio de entrada, digamos $(x_1,x_2)$ pertenezca a a una clase. \n",
    "\n",
    "Por construcción $\\pi$ es la probabilidad que el elemento $x$ pertenezca a la clase 1. Por lo tanto si por ejemplo $\\pi = 0.8$ para un elemento, entonces lo clasificamos en la clase 1. \n",
    "\n",
    "\n",
    "La idea central que está detrás de este tipo de modelos se puede apreciar en la siguete imagen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/clasificador_lineal.png\" width=\"600\" height=\"500\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Clasificador Lineal</p>\n",
    "</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trata de un clasificador lineal simple. Vamos a suponer que la máquina de aprendizaje ya está entrenada, por lo que los parámetros $w,b$ están fijos.\n",
    "\n",
    "Observe que la línea roja divide el espacio $\\mathcal{R}^2$ en  tres regiones. La primera es justamente la recta, que corresponde a un modelo de regresión como se estuio en la lección de [regresión lineal](am_intro_regresion.ipynb). Sobre la línea se cumple la ecuación \n",
    "\n",
    "$$\n",
    "wx+b =0.\n",
    "$$\n",
    "\n",
    "Por otro lado se tiene que si $wx+b=0$, entonces la probabilidad $\\pi$ es dada en este caso por\n",
    "\n",
    "$$\n",
    "\\pi = \\frac{1}{1+exp(-(wx+b))} = \\frac{1}{2}.\n",
    "$$\n",
    "\n",
    "La segunda región está a la derecha. Usted puede verificar que en este caso, para todos los valores de $x$ se tiene que  $wx+b>0$. Como consecuencia, se tiene que $\\pi>\\tfrac{1}{2}$. en el caso extremo para valores $x$ muy alejados hacia la derecha, se tiene que $wx+b\\to \\infty$ y en consecuencia $\\pi\\to 1$.\n",
    "\n",
    "\n",
    "En la tercera región (a la izquierda) ocurre el comportamiento simétrico pero en el otro sentido. Ahora $wx+b<0$, para todos los valores de $x$.  Se tiene que $\\pi<\\tfrac{1}{2}$. En el caso extremo para valores $x$ muy alejados hacia la izquierda, se tiene que $wx+b\\to -\\infty$ y en consecuencia $\\pi\\to 0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El separador lineal funciona de la siguiente forma en este caso.\n",
    "\n",
    "1. Si $\\pi(x)$ es mayor que 0.5, la clase que debe asigna es 1. Entre mayor es $\\pi(x)$ mayor tranquilidad para asignar la clase 1 al elemento $x$ en el espacio se entrada.\n",
    "2. Si $\\pi(x)$ es menor que 0.5, la clase que debe asigna es 0. Entre mayor es $\\pi(x)$ mayor tranquilidad para asignar la clase 0 al elemento $x$ en el espacio se entrada.\n",
    "3. Si $\\pi(x)=0.5$, no se puede asignar una clase. Para valores muy cercanos a 0.5, no se debe asignar una clase directamente. Si fuera necesario tomar una decisión, lo mejor es seleccionar la clase de forma aleatoria. Como regla de combate, si $0.48 \\le \\pi(x)\\le 0.52$, seleccionar aleatoriamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los módulos requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.estimator import LinearClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del conjunto de datos Iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombres de las columnas de los datos\n",
    "col_names = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "target_dimensions = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "# lee los datos\n",
    "training_data_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_data_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "training = pd.read_csv(training_data_path, names=col_names, header=0)\n",
    "test = pd.read_csv(test_data_path, names=col_names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esta sección es para omitir la clase 0: \"Setosa\" y recodificar loa datos  de entrenamiento\n",
    "training = training[training['Species'] >= 1]\n",
    "training['Species'] = training['Species'].replace([1,2], [0,1])\n",
    "\n",
    "# esta sección es para omitir la clase 0: \"Setosa\" y recodificar los datos  de validación\n",
    "test = test[test['Species'] >= 1]\n",
    "test['Species'] = test['Species'].replace([1,2], [0,1])\n",
    "\n",
    "# omite los índices de los dos dataframes para poderlos concadenar\n",
    "training.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# concadena los dataframes\n",
    "iris_dataset = pd.concat([training, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acercamiento descriptivo a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(iris_dataset, diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_data = iris_dataset.corr()\n",
    "correlation_data.style.background_gradient(cmap='coolwarm', axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa features y targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = iris_dataset[[m for m in iris_dataset.columns if m not in ['Species']]]\n",
    "Y_data = iris_dataset[['Species']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide los datos: entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features , test_features ,training_labels, test_labels = train_test_split(X_data , Y_data , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. of rows in Training Features: ', training_features.shape[0])\n",
    "print('No. of rows in Test Features: ', test_features.shape[0])\n",
    "print('No. of columns in Training Features: ', training_features.shape[1])\n",
    "print('No. of columns in Test Features: ', test_features.shape[1])\n",
    "\n",
    "print('No. of rows in Training Label: ', training_labels.shape[0])\n",
    "print('No. of rows in Test Label: ', test_labels.shape[0])\n",
    "print('No. of columns in Training Label: ', training_labels.shape[1])\n",
    "print('No. of columns in Test Label: ', test_labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = training_features.describe()\n",
    "stats = stats.transpose()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = test_features.describe()\n",
    "stats = stats.transpose()\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normaliza los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  stats = x.describe()\n",
    "  stats = stats.transpose()\n",
    "  return (x - stats['mean']) / stats['std']\n",
    "\n",
    "normed_train_features = norm(training_features)\n",
    "normed_test_features = norm(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construye la tuberia (pipeline) para la alimentación de datos de Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_input(features_dataframe, target_dataframe, num_of_epochs=10, shuffle=True, batch_size=32):\n",
    "  def input_feed_function():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features_dataframe), target_dataframe))\n",
    "    if shuffle:\n",
    "      dataset = dataset.shuffle(2000)\n",
    "    dataset = dataset.batch(batch_size).repeat(num_of_epochs)\n",
    "    return dataset\n",
    "  return input_feed_function\n",
    "\n",
    "train_feed_input = feed_input(normed_train_features, training_labels)\n",
    "train_feed_input_testing = feed_input(normed_train_features, training_labels, num_of_epochs=1, shuffle=False)\n",
    "test_feed_input = feed_input(normed_test_features, test_labels, num_of_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_numeric = [tf.feature_column.numeric_column(m) for m in training_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LinearClassifier(feature_columns=feature_columns_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.train(train_feed_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = logistic_model.predict(train_feed_input_testing)\n",
    "test_predictions = logistic_model.predict(test_feed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_series = pd.Series([p['classes'][0].decode(\"utf-8\")   for p in train_predictions])\n",
    "test_predictions_series = pd.Series([p['classes'][0].decode(\"utf-8\")   for p in test_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_df = pd.DataFrame(train_predictions_series, columns=['predictions'])\n",
    "test_predictions_df = pd.DataFrame(test_predictions_series, columns=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels.reset_index(drop=True, inplace=True)\n",
    "train_predictions_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_labels.reset_index(drop=True, inplace=True)\n",
    "test_predictions_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_with_predictions_df = pd.concat([training_labels, train_predictions_df], axis=1)\n",
    "test_labels_with_predictions_df = pd.concat([test_labels, test_predictions_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_binary_class_scores(y_true, y_pred):\n",
    "  accuracy = accuracy_score(y_true, y_pred.astype('int64'))\n",
    "  precision = precision_score(y_true, y_pred.astype('int64'))\n",
    "  recall = recall_score(y_true, y_pred.astype('int64'))\n",
    "  return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **accuracy_score**: En la clasificación con múltiples etiquetas, esta función calcula la precisión del subconjunto: el conjunto de etiquetas predichas para una muestra que coincide exactamente con el conjunto de etiquetas correspondiente en y_true.\n",
    "- **precision_score**: es la razón $\\frac{tp }{tp + fp}$ en donde $tp$ es el número de positivos verdadero y $fp$ el número de falsos positivos. El mejor valor es 1 y el peor valor es 0.\n",
    "- **recall_score**:  es la relación $\\frac{tp }{tp + fn}$ donde $tp$ es el número de verdaderos positivos y $fn$ el número de falsos negativos. El recuerdo es intuitivamente la capacidad del clasificador para encontrar todas las muestras positivas. El mejor valor es 1 y el peor valor es 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_score, train_precision_score, train_recall_score = calculate_binary_class_scores(training_labels, train_predictions_series)\n",
    "test_accuracy_score, test_precision_score, test_recall_score = calculate_binary_class_scores(test_labels, test_predictions_series)\n",
    "\n",
    "print('Training Data Accuracy (%) = ', round(train_accuracy_score*100,2))\n",
    "print('Training Data Precision (%) = ', round(train_precision_score*100,2))\n",
    "print('Training Data Recall (%) = ', round(train_recall_score*100,2))\n",
    "print('-'*50)\n",
    "print('Test Data Accuracy (%) = ', round(test_accuracy_score*100,2))\n",
    "print('Test Data Precision (%) = ', round(test_precision_score*100,2))\n",
    "print('Test Data Recall (%) = ', round(test_recall_score*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-[Regresar al inicio](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
