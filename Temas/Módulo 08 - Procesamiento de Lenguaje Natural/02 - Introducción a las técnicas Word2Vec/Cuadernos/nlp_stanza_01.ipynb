{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Diplomado en Inteligencia Artificial y Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center> Introducción a Stanza para NLP</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Introducción para dummies </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Oleg Jarma, ojarmam@unal.edu.co \n",
    "6. Laura Lizarazo, ljlizarazore@unal.edu.co "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Repo oficial de [stanza](https://github.com/stanfordnlp/stanza)\n",
    "2. [Stanza](https://stanfordnlp.github.io/stanza/index.html) in Stanford \n",
    "3. [Speech and Language Processing (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Fuente</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este cuaderno es una adaptación y traducción libre de los cuadernos disponibles en el repo oficial de [stanza](https://github.com/stanfordnlp/stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Instalación de Stanza](#Instalación-de-Stanza)\n",
    "* [Descarga de modelos](#Descarga-de-modelos)\n",
    "* [Descarga de modelos](#Descarga-de-modelos)\n",
    "* [Procesamiento de texto](#Procesamiento-de-texto)\n",
    "* [Acceso a las anotaciones](#Acceso-a-las-anotaciones)\n",
    "* [Recursos](#Recursos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56LiYCkPM7V_"
   },
   "source": [
    "\n",
    "Stanza es un conjunto de herramientas Python NLP que admite más de 60 lenguajes humanos. Está construido con componentes de red neuronal de alta precisión que permiten un entrenamiento y una evaluación eficientes con sus propios datos anotados, y ofrece modelos previamente entrenados en 100 bancos de árboles. \n",
    "\n",
    "Además, Stanza proporciona una interfaz Python estable y mantenida oficialmente para Java Stanford CoreNLP Toolkit.\n",
    "\n",
    "En este tutorial, demostraremos cómo configurar Stanza y anotar texto con sus modelos nativos de PNL de red neuronal. Para el uso de la interfaz Python CoreNLP, consulte otros tutoriales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQff4Di5Nnq0"
   },
   "source": [
    "## <span style=\"color:blue\">Instalación de Stanza</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQff4Di5Nnq0"
   },
   "source": [
    "Stanza  supporta Python 3.6 y 3.7. Esta anunciada la version en 3.8, pero hoy (abril 24 de 2021) no funciona con conda. Instale stanza como sigue. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owSj1UtdEvSU"
   },
   "source": [
    "# Install; note that the prefix \"!\" is not needed if you are running in a terminal\n",
    "\n",
    "!pip install stanza\n",
    "\n",
    "! anaconda install -c stanfordnlp stanza\n",
    "# Import the package\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ixllwEKeCJg"
   },
   "source": [
    "Si tiene problemas consulte esta \n",
    " [página de ayuda](https://stanfordnlp.github.io/stanfordnlp/installation_usage.html#troubleshooting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeyPs5ARO79d"
   },
   "source": [
    "## <span style=\"color:blue\">Descarga de modelos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeyPs5ARO79d"
   },
   "source": [
    "Puede descargar modelos con el comando `stanza.download`. El idioma se puede especificar con un nombre de idioma completo (por ejemplo, \"english\") o un código corto (por ejemplo, \"en\"). Aqui instalaremos español \"spanish\": \"es\" (556 MB) e inglés: \"en\" (411 MB).\n",
    "\n",
    "Por defecto, los modelos se guardarán en su directorio `~ / stanza_resources`. Si desea especificar su propia ruta para guardar los archivos del modelo, puede pasar un argumento `dir = your_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDwRm-KXGcYo"
   },
   "outputs": [],
   "source": [
    "# importa stanza\n",
    "\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDwRm-KXGcYo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 27.5MB/s]                    \n",
      "2021-04-24 17:35:24 INFO: Downloading default packages for language: en (English)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading English model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/en/default.zip: 100%|██████████| 411M/411M [02:14<00:00, 3.05MB/s] \n",
      "2021-04-24 17:37:47 INFO: Finished downloading models and saved to /home/alvaro/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "# Download an Spanish model into the default directory\n",
    "print(\"Downloading English model...\")\n",
    "stanza.download('en')\n",
    "print(\"Descargando modelo Español...\")\n",
    "stanza.download('es')\n",
    "\n",
    "# Similarly, download a (simplified) Chinese model\n",
    "# Note that you can use verbose=False to turn off all printed messages\n",
    "#print(\"Downloading Chinese model...\")\n",
    "#stanza.download('zh', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HCfQ0SfdmsU"
   },
   "source": [
    "### Más información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HCfQ0SfdmsU"
   },
   "source": [
    "Se proporcionan modelos previamente entrenados para más de 60 idiomas diferentes. Para todos los idiomas, modelos disponibles y los códigos breves de idioma correspondientes, consulte la [página de modelos](https://stanfordnlp.github.io/stanza/models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3-WZJrzWD2o"
   },
   "source": [
    "## <span style=\"color:blue\">Procesamiento de texto</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrnKl2m3fq2f"
   },
   "source": [
    "### Construcción de canalizaciones (tuberías)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrnKl2m3fq2f"
   },
   "source": [
    "\n",
    "Para procesar un fragmento de texto, primero deberá construir una tubería  o canalización `Pipeline` con diferentes unidades de procesamiento `Processor`. La canalización es específica del idioma, por lo que nuevamente deberá especificar el idioma (ver ejemplos).\n",
    "\n",
    "- De forma predeterminada, la canalización incluirá todos los procesadores, incluida la tokenización, la expansión de token de varias palabras, el etiquetado de parte de la voz, la lematización, el análisis de dependencias y el reconocimiento de entidades con nombre (para idiomas admitidos). Sin embargo, siempre puede especificar qué procesadores desea incluir con el argumento `processors`.\n",
    "\n",
    "- La canalización de Stanza es compatible con CUDA, lo que significa que se usará un dispositivo CUDA siempre que esté disponible; de lo contrario, se usarán CPU cuando no se encuentre una GPU. Puede obligar a la canalización a utilizar la CPU independientemente de si establece `use_gpu = False`.\n",
    "\n",
    "- Puede suprimir todos los mensajes impresos configurando `verbose = False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbiTSBDPG53o"
   },
   "outputs": [],
   "source": [
    "# Build an English pipeline, with all processors by default\n",
    "#print(\"Building an English pipeline...\")\n",
    "#en_nlp = stanza.Pipeline('en')\n",
    "\n",
    "# Build a Chinese pipeline, with customized processor list and no logging, and force it to use CPU\n",
    "#print(\"Building a Chinese pipeline...\")\n",
    "#zh_nlp = stanza.Pipeline('zh', processors='tokenize,lemma,pos,depparse', verbose=False, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-24 17:51:56 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2021-04-24 17:51:56 INFO: Use device: cpu\n",
      "2021-04-24 17:51:56 INFO: Loading: tokenize\n",
      "2021-04-24 17:51:56 INFO: Loading: mwt\n",
      "2021-04-24 17:51:56 INFO: Loading: pos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosntruyendo una canalización de Español...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-24 17:51:57 INFO: Loading: lemma\n",
      "2021-04-24 17:51:57 INFO: Loading: depparse\n",
      "2021-04-24 17:51:58 INFO: Loading: ner\n",
      "2021-04-24 17:52:00 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Cree una canalización en Español, con todos los procesadores de forma predeterminada\n",
    "print(\"Cosntruyendo una canalización de Español...\")\n",
    "es_nlp = stanza.Pipeline('es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Go123Bx8e1wt"
   },
   "source": [
    "### Marcación o Anotación  de texto (Annotating text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Go123Bx8e1wt"
   },
   "source": [
    "Una vez que se ha construido correctamente una canalización, puede obtener anotaciones de un fragmento de texto simplemente pasando la cadena al objeto de canalización. La canalización devolverá un objeto `Documento`, que se puede utilizar para acceder a anotaciones detalladas. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_p0h1UTHDMm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stanza.models.common.doc.Document'>\n",
      "<class 'stanza.models.common.doc.Document'>\n"
     ]
    }
   ],
   "source": [
    "# Processing texto en Español\n",
    "es_doc = en_nlp(\"Alvaro Montenegro nació en Bogotá.  El es profesor en la Universidad Nacionsal en 1990.\")\n",
    "print(type(en_doc))\n",
    "\n",
    "\n",
    "# Processing English text\n",
    "en_doc = en_nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")\n",
    "print(type(en_doc))\n",
    "\n",
    "# Processing Chinese text\n",
    "#zh_doc = zh_nlp(\"达沃斯世界经济论坛是每年全球政商界领袖聚在一起的年度盛事。\")\n",
    "#print(type(zh_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DavwCP9egzNZ"
   },
   "source": [
    "### Más información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DavwCP9egzNZ"
   },
   "source": [
    "Para obtener más información sobre cómo construir una canalización e información sobre diferentes procesadores, visite [pipeline page](https://stanfordnlp.github.io/stanfordnlp/pipeline.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_PYLEGziQWR"
   },
   "source": [
    "## <span style=\"color:blue\">Acceso a las anotaciones</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_PYLEGziQWR"
   },
   "source": [
    "Se puede acceder a las anotaciones desde el objeto Documento devuelto.\n",
    "\n",
    "Un `documento` contiene una lista de `oraciones` y una oración contiene una lista de tokens (`símbolos`) y `palabras`. En su mayor parte, los tokens y las palabras se superponen, pero algunos tokens se pueden dividir en varias palabras, por ejemplo, el token francés aux se divide en las palabras à y les, mientras que en inglés una palabra y un token son equivalentes. Tenga en cuenta que los análisis de dependencia se derivan de Words.\n",
    "\n",
    "Además, un objeto `Span` se usa para representar anotaciones que son parte de un documento, como menciones de entidades nombradas.\n",
    "\n",
    "El siguiente ejemplo itera sobre todas las oraciones y palabras en inglés y en español e imprime la información de la palabra una por una: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Oración 1]\n",
      "Alvaro      \tAlvaro      \tPROPN \t0\troot        \n",
      "Montenegro  \tMontenegro  \tPROPN \t1\tflat        \n",
      "nació       \tnació       \tPROPN \t1\tflat        \n",
      "en          \ten          \tPROPN \t1\tflat        \n",
      "Bogotá      \tBogotá      \tPROPN \t3\tflat        \n",
      ".           \t.           \tPUNCT \t1\tpunct       \n",
      "\n",
      "[Oración 2]\n",
      "El          \tEl          \tPROPN \t0\troot        \n",
      "es          \tes          \tX     \t1\tflat        \n",
      "profesor    \tprofesor    \tX     \t1\tflat        \n",
      "en          \ten          \tX     \t1\tflat        \n",
      "la          \tla          \tPROPN \t1\tflat        \n",
      "Universidad \tUniversidad \tPROPN \t1\tflat        \n",
      "Nacionsal   \tNacionsal   \tPROPN \t1\tflat        \n",
      "en          \ten          \tX     \t9\tcase        \n",
      "1990        \t1990        \tNUM   \t1\tnmod:tmod   \n",
      ".           \t.           \tPUNCT \t1\tpunct       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(es_doc.sentences):\n",
    "    print(\"[Oración {}]\".format(i+1))\n",
    "    for word in sent.words:\n",
    "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
    "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5691SpFHFZ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence 1]\n",
      "Barack      \tBarack      \tPROPN \t4\tnsubj:pass  \n",
      "Obama       \tObama       \tPROPN \t1\tflat        \n",
      "was         \tbe          \tAUX   \t4\taux:pass    \n",
      "born        \tbear        \tVERB  \t0\troot        \n",
      "in          \tin          \tADP   \t6\tcase        \n",
      "Hawaii      \tHawaii      \tPROPN \t4\tobl         \n",
      ".           \t.           \tPUNCT \t4\tpunct       \n",
      "\n",
      "[Sentence 2]\n",
      "He          \the          \tPRON  \t3\tnsubj:pass  \n",
      "was         \tbe          \tAUX   \t3\taux:pass    \n",
      "elected     \telect       \tVERB  \t0\troot        \n",
      "president   \tpresident   \tNOUN  \t3\txcomp       \n",
      "in          \tin          \tADP   \t6\tcase        \n",
      "2008        \t2008        \tNUM   \t3\tobl         \n",
      ".           \t.           \tPUNCT \t3\tpunct       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(en_doc.sentences):\n",
    "    print(\"[Sentence {}]\".format(i+1))\n",
    "    for word in sent.words:\n",
    "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
    "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AUkCkNIrusq"
   },
   "source": [
    "El siguiente ejemplo itera sobre todas las menciones de entidades nombradas extraídas e imprime sus intervalos y tipos de caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Uu0-WmvsnlK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mention text\tType\tStart-End\n",
      "Barack Obama\tPERSON\t0-12\n",
      "Hawaii\tGPE\t25-31\n",
      "2008\tDATE\t62-66\n"
     ]
    }
   ],
   "source": [
    "print(\"Mention text\\tType\\tStart-End\")\n",
    "for ent in en_doc.ents:\n",
    "    print(\"{}\\t{}\\t{}-{}\".format(ent.text, ent.type, ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mention text\tType\tStart-End\n",
      "Alvaro Montenegro nació\tPERSON\t0-23\n",
      "Bogotá\tGPE\t27-33\n",
      "El es\tORG\t36-41\n",
      "1990\tDATE\t82-86\n"
     ]
    }
   ],
   "source": [
    "print(\"Mention text\\tType\\tStart-End\")\n",
    "for ent in es_doc.ents:\n",
    "    print(\"{}\\t{}\\t{}-{}\".format(ent.text, ent.type, ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ql1SZlZOnMLo"
   },
   "source": [
    "Similar para el texto chino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsVcEO9tHKPG"
   },
   "outputs": [],
   "source": [
    "for i, sent in enumerate(zh_doc.sentences):\n",
    "    print(\"[Sentence {}]\".format(i+1))\n",
    "    for word in sent.words:\n",
    "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{:d}\\t{:12s}\".format(\\\n",
    "              word.text, word.lemma, word.pos, word.head, word.deprel))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUhWAs8pnnHT"
   },
   "source": [
    "Alternativamente, puede imprimir directamente un objeto `Word` para ver todas sus anotaciones como un diccionario de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_UafNb7HHIg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 1,\n",
      "  \"text\": \"Barack\",\n",
      "  \"lemma\": \"Barack\",\n",
      "  \"upos\": \"PROPN\",\n",
      "  \"xpos\": \"NNP\",\n",
      "  \"feats\": \"Number=Sing\",\n",
      "  \"head\": 4,\n",
      "  \"deprel\": \"nsubj:pass\",\n",
      "  \"misc\": \"start_char=0|end_char=6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "word = en_doc.sentences[0].words[0]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 1,\n",
      "  \"text\": \"Alvaro\",\n",
      "  \"lemma\": \"Alvaro\",\n",
      "  \"upos\": \"PROPN\",\n",
      "  \"xpos\": \"NNP\",\n",
      "  \"feats\": \"Number=Sing\",\n",
      "  \"head\": 0,\n",
      "  \"deprel\": \"root\",\n",
      "  \"misc\": \"start_char=0|end_char=6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "word = es_doc.sentences[0].words[0]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TAQlOsuRoq2V"
   },
   "source": [
    "### Más información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TAQlOsuRoq2V"
   },
   "source": [
    "For all information on different data objects, please visit our [data objects page](https://stanfordnlp.github.io/stanza/data_objects.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiiWHxYPpmhd"
   },
   "source": [
    "## <span style=\"color:blue\">Recursos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiiWHxYPpmhd"
   },
   "source": [
    "Además de este tutorial interactivo, también proporcionamos tutoriales en nuestro sitio web que cubren una variedad de casos de uso, como cómo usar diferentes \"paquetes\" de modelos para un idioma, cómo usar spaCy como tokenizador, cómo procesar texto pretokenizado sin ejecutar el tokenizer, etc. Para estos tutoriales, visite [Tutorials page](https://stanfordnlp.github.io/stanza/tutorials.html).\n",
    "\n",
    "Otros recursos que pueden resultar útiles incluyen:\n",
    "\n",
    "- [Stanza Homepage](https://stanfordnlp.github.io/stanza/index.html)\n",
    "- [FAQs](https://stanfordnlp.github.io/stanza/faq.html)\n",
    "- [GitHub Repo](https://github.com/stanfordnlp/stanza)\n",
    "- [Reporting Issues](https://github.com/stanfordnlp/stanza/issues)\n",
    "- [Stanza System Description Paper](http://arxiv.org/abs/2003.07082)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
