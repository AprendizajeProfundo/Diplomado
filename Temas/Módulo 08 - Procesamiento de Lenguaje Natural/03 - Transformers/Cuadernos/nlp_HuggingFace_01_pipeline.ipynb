{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fdf1c6-20c1-4695-92c3-1a30d118da9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\"><center>Aprendizaje Profundo</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2d584-a384-4517-96c0-b085f6adfe24",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center>Transformers- Procesamiento de Lenguaje Natural </center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d5c0f-edf4-4e0a-8260-4f6a251eedd3",
   "metadata": {},
   "source": [
    "<center>HuggingFace pipeline</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814b837-8220-4f6c-8d62-4f76d8652736",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Autores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f2eeab-4acc-4a4f-bb79-9e2d45a810d0",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002dc78-cb0a-47d5-a17f-c6df384b96f8",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Diseño gráfico y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05789c43-41b3-494d-afaa-a370002d9ccf",
   "metadata": {},
   "source": [
    "1. Maria del Pilar Montenegro Reyes, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda43ed-5f98-4ffa-b3d6-dd268a5fdc0e",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a21b86-13b2-4c1b-824f-96dce45f3e4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4447d4d-a448-40d6-98cd-cbaebf381d7c",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23caca7-9f44-4ca3-a8c9-2c4cfd44ee39",
   "metadata": {},
   "source": [
    "1. [HuggingFace. Transformers ](https://huggingface.co/transformers/)\n",
    "1. [HuggingFace. Intro pipeline](https://huggingface.co/course/chapter1/3?fw=pt)\n",
    "1. [Tutorial Transformer de Google](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "1. [Transformer-chatbot-tutorial-with-tensorflow-2](https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html) \n",
    "1. [Transformer Architecture: The positional encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)\n",
    "1. [Illustrated Auto-attención](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)\n",
    "1. [Illustrated Attention](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3#0458)\n",
    "1. [Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau et. al, 2015)](https://arxiv.org/pdf/1409.0473.pdf)\n",
    "1. [Effective Approaches to Attention-based Neural Machine Translation (Luong et. al, 2015)](https://arxiv.org/pdf/1508.04025.pdf)\n",
    "1. [Attention Is All You Need (Vaswani et. al, 2017)](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "1. [Self-Attention GAN (Zhang et. al, 2018)](https://arxiv.org/pdf/1805.08318.pdf)\n",
    "1. [Sequence to Sequence Learning with Neural Networks (Sutskever et. al, 2014)](https://arxiv.org/pdf/1409.3215.pdf)\n",
    "1. [TensorFlow’s seq2seq Tutorial with Attention (Tutorial on seq2seq+attention)](https://github.com/tensorflow/nmt)\n",
    "1. [Lilian Weng’s Blog on Attention (Great start to attention)](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms)\n",
    "1. [Jay Alammar’s Blog on Seq2Seq with Attention (Great illustrations and worked example on seq2seq+attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\n",
    "1. [Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (Wu et. al, 2016)](https://arxiv.org/pdf/1609.08144.pdf)\n",
    "1. [Adam: A method for stochastic optimization](https://arxiv.org/pdf/1412.6980.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0da79b-44dc-460c-ac1e-b71ade087a9c",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15195d1b-1dfc-4e35-a28d-5c6dad544252",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Pipeline de HuggingFace](#Pipeline-de-HuggingFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe895d3-c25d-49d7-9b47-ff4835ba2b95",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ba28d-5780-4438-9084-be9c17530b1b",
   "metadata": {},
   "source": [
    "Las tareas del procesamiento del lenguaje natural moderno se dividen escencialmente en:\n",
    "\n",
    "1. Clasificación de textos. Por ejemplo, análisis de sentimiento.\n",
    "1. Generación automática de textos, basados en una frase inicial.\n",
    "1. Generación de texto en contexto, llenando espacios vacios enmascarados con máscaras `masked text`.\n",
    "1. Clasificación de cada una de las palabras en una frase:  Por ejemplo: sustantivo, verbo adjetivo, o por ejemplo `ner`: named entity recognition. ciudad, nombre de persona, localización, organización. Este proceso se denomina inferencia textual.\n",
    "1. Generación de una respuesta a partir de una pregunta.\n",
    "1. Traducción de un lenguaje a otro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47815890-5b20-446c-95a4-af3eac8bc5a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Pipeline de HuggingFace</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda461a6-bc48-498c-8949-eb525b84b403",
   "metadata": {},
   "source": [
    "En esta lección se introduce `pipeline`, que es una función de HuggingFace que permite hacer uso directamente de modelos pre-entrenados quer (básicanete en inglés). Esto implica no es necesario pre-procesamiento no post-procesamiento para obtener resultados directamente usando los modelos pre-entrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ef327-6d72-4b13-9606-aeb0c3baa893",
   "metadata": {},
   "source": [
    "Para correr el cuaderno original  de HuggingFace en Colab vaya a  [HuggingFace notebook](https://huggingface.co/course/chapter1/3?fw=tf). Versión Torch [aquí](https://huggingface.co/course/chapter1/3?fw=pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791a8ca-c0ed-4e60-bcf8-eabb7c29b3ce",
   "metadata": {},
   "source": [
    "### Clasificación de textos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e76fd28f-ef5a-452b-b562-ffd48a9fb361",
   "metadata": {},
   "source": [
    "!conda install -c huggingface transformers\n",
    "!conda install -c conda-forge sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2ae66c-ff6e-473c-9050-c26bb8c7b394",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1b32091f5ce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment-analysis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I've been waiting for a HuggingFace course my hole life\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/huggingface/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mtokenizer_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             tokenizer = AutoTokenizer.from_pretrained(\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mtokenizer_identifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/huggingface/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/huggingface/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1670\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m                     resolved_vocab_files[file_id] = cached_path(\n\u001b[0m\u001b[1;32m   1673\u001b[0m                         \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/huggingface/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/huggingface/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                     )\n\u001b[1;32m   1551\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1553\u001b[0m                         \u001b[0;34m\"Connection error, and we cannot find the requested files in the cached path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m                         \u001b[0;34m\" Please try again or make sure your Internet connection is on.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my hole life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7b84b-3d4e-409a-8cba-9f2b621c12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bfdbf-2876-4f2d-ae2e-8f5aaca652b5",
   "metadata": {},
   "source": [
    "### Generación de texto a partir de una frase inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b142db-7bab-49ed-a8f3-40da2f642028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course we will teach you how to make the best choices in life and how to learn from your mistakes.\\n\\nLearning from those mistakes means you have the tools to be successful in your life or your business.\\n\\nLearning from the mistakes'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator('In this course we will teach you how to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a364c9e-01e2-42bf-84fc-86540104f064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course we will teach you how to use the Internet for self-care applications, how to install and run self-help packages on your PC'},\n",
       " {'generated_text': 'In this course we will teach you how to use the MCP2215 on your iPhone and the C920.\\n\\nYou are going to learn'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator('In this course we will teach you how to',\n",
    "          max_length=30,\n",
    "          num_return_sequences=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a19a5-b469-4a5b-9bef-36b5c5c7992b",
   "metadata": {},
   "source": [
    "### Generación de texto en contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8679c9d3-2c03-414d-a9a1-0c06117076c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This course teach you about mathematical models.',\n",
       "  'score': 0.1940864473581314,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical'},\n",
       " {'sequence': 'This course teach you about computational models.',\n",
       "  'score': 0.049340978264808655,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask')\n",
    "unmasker('This course teach you about <mask> models.', top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2be52-8799-4592-9a6a-6f0b682707d9",
   "metadata": {},
   "source": [
    "### Reconocimiento de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c82615-02f0-4206-89c5-bcd220539f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9978796,\n",
       "  'word': 'Alice',\n",
       "  'start': 11,\n",
       "  'end': 16},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99638355,\n",
       "  'word': 'HuggingFace',\n",
       "  'start': 31,\n",
       "  'end': 42},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9905594,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 46,\n",
       "  'end': 54}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline('ner', grouped_entities=True)\n",
    "ner(\"My name is Alice and I work at HuggingFace in Brooklyn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8657299-6c4e-4f46-80c9-5d06e92b6849",
   "metadata": {},
   "source": [
    "### Respuesta a preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9c2fe36-c8ba-44b4-ac77-4945587e360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.8432626128196716, 'start': 30, 'end': 41, 'answer': 'HuggingFace'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answer = pipeline(\"question-answering\")\n",
    "question_answer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is John and I work at HuggingFace in Brooklyn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c792392-f72f-43b5-aff5-320ab14dc892",
   "metadata": {},
   "source": [
    "### Resumen de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63047f7c-c9eb-429f-88c3-55027d38b525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55782f32d334d268c15f3a0b55bba50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819f3fb12e9c4cad846e85abd6156352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb4aa9937e24cfabe19a54cfc91f623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f968438bff4717aac19fcb0e72cc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca9fee66d1f44b08a4709652b42cb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/anaconda3/envs/huggingface/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8c903-9d1a-49b5-ba27-2f4aef16e8b6",
   "metadata": {},
   "source": [
    "### Traducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6bf8fd6-c627-4fc5-9ee3-cff33a405dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Los Estados Unidos han cambiado drásticamente en los últimos años. No sólo ha disminuido el número de graduados en disciplinas tradicionales de ingeniería, como la ingeniería mecánica, civil, eléctrica, química y aeronáutica, sino que en la mayoría de los programas de ingeniería de las principales universidades estadounidenses se concentra y fomenta en gran medida el estudio de las ciencias de la ingeniería. Como resultado, hay una disminución de la oferta en temas de ingeniería relacionados con la infraestructura, el medio ambiente y cuestiones conexas, y una mayor concentración en temas de alta tecnología, apoyando en gran medida desarrollos científicos cada vez más complejos. Si bien este último es importante, no debe ser a expensas de la ingeniería más tradicional. Las economías en rápido desarrollo, como China y la India, así como otros países industriales de Europa y Asia, siguen fomentando y promoviendo la enseñanza de la ingeniería. Tanto China como la India, respectivamente, se gradúan seis y ocho veces más ingenieros tradicionales que los Estados Unidos. Otros países industriales mantienen como mínimo su producción, mientras que los Estados Unidos sufren una disminución cada vez más grave del número de graduados en ingeniería y una falta de ingenieros bien educados.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "translator(\"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "570cfe7f-8497-4204-be4b-c738aef4791a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'América ha cambiado dramáticamente durante los últimos años. El número de graduados de ingeniería en los EE.UU. ha disminuido en las disciplinas tradicionales de ingeniería, como la ingeniería mecánica, civil, eléctrica, química y aeronáutica. Economías en rápido desarrollo como China e India siguen alentando y promoviendo la enseñanza de la ingeniería.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "translator(\"\"\"America has changed dramatically during recent years . \n",
    "           The number of engineering graduates in the U.S. \n",
    "           has declined in traditional engineering disciplines such as mechanical, civil,    \n",
    "           electrical, chemical, and aeronautical engineering . \n",
    "           Rapidly developing economies such as China and India continue to \n",
    "           encourage and advance the teaching of engineering .\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bac083-01c8-40cd-90c0-cf82325c5fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddefd4de-3567-4eb3-a4ab-bd0714b4fff3",
   "metadata": {},
   "source": [
    "### Clasificación de cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0de32-db9b-406a-8bea-68ce31e61106",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clasificación de textos que no han sido clasificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e132cd99-eb28-47ce-af78-e5f4a9cefce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d8e4ca48674219a330e5eab2d95c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af16e904320f414a83c38992f58d65de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58bdc2cb8774887a22bae90aa910074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef563fd86f484cb48d68c994d0bd9d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e488b8f360254ce3934ece9214860d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5429cc2a13647ce8e027e3f8f442358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformer library',\n",
       " 'labels': ['education', 'bussines', 'politics'],\n",
       " 'scores': [0.9465058445930481, 0.04198963940143585, 0.011504470370709896]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('zero-shot-classification')\n",
    "classifier(\n",
    "          \"This is a course about the Transformer library\",\n",
    "          candidate_labels=['education', 'politics', 'bussines']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c12371-f8c2-4f7f-90d1-8bb26dbe06ad",
   "metadata": {},
   "source": [
    "### Uso de cualquier modelo del hub en una tubería (pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90ce51-8043-499a-a89d-a9cf71cbfdba",
   "metadata": {},
   "source": [
    "Para cada tarea específica se puede especificar un modelo en particular. En este ejemplo vamos a seleccionar el modelo *distilgpt2* para generar texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52a944c2-8c0d-4370-951d-ac2f8db4b800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041d2034ce134abeb319793129aa33f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c332f9c93a6c42e1959b3bd1b73e2877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcda52e2cf7d4ccf8fb8ccd181f5b01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79c5daeba3f4dee904cb4032680ea7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d481f17d3cc14798b299d3252acd1e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to successfully read and write online and how to write real time content for educational purposes.'},\n",
       " {'generated_text': 'In this course, we will teach you how to build and use the open source compiler to build a fully functional, flexible, highly open and easy to'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "generator(\n",
    "    'In this course, we will teach you how to',\n",
    "    max_length=30,\n",
    "num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4ff98-b73f-481d-b906-4717d85dd198",
   "metadata": {},
   "source": [
    "### Modelos en Español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10b39ad9-ae1c-423f-9312-8f6dc8e8cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Su casa es un asco.- ¡Y que lo digas!¡Con las sábanas de la abuela en la lavadora!Y ahora tengo que limpiarla'},\n",
       " {'generated_text': 'Su casa es un asco.Y además, se ve así.Con un sombrero de copa y todos esos libros...Y en la cocina me llaman de'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='mrm8488/spanish-gpt2')\n",
    "generator(\n",
    "    'Su casa es un asco',\n",
    "    max_length=30,\n",
    "num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d2c18-31dc-4b73-bd4d-98e32ef7e529",
   "metadata": {},
   "source": [
    "### Traductores Español-Inglés, Inglés-Español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9882fde-1012-4562-ab61-d60f706165f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3556d742774fd28c3217460e88425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/826k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60106380840d4e5da6287dfadcd05b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030a91c6f6c04459850c6552b19a302d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'I hate this very much.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator_sp_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "translator_sp_en(\"Odio mucho esto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e26358-300f-489b-ba37-545c206266d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Odio mucho esto.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "translator(\"I hate this very much\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b881338-f69c-4172-bb48-a30221091271",
   "metadata": {},
   "source": [
    "### Combinando modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cd34f5b-662f-4222-a2e7-043f6b55a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "translator_es_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "translator_en_es = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36a3b9c9-f897-49f4-a15a-3fb1d8fe1ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995800852775574}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase_espanol = 'odio mucho esto'\n",
    "frase_ingles = translator_es_en(frase_espanol)[0]['translation_text']\n",
    "\n",
    "classifier(frase_ingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71f2eef2-7f2c-4549-8a46-891ff7f3068c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998371601104736}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase_espanol = 'eso está muy bien'\n",
    "frase_ingles = translator_es_en(frase_espanol)[0]['translation_text']\n",
    "\n",
    "classifier(frase_ingles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
