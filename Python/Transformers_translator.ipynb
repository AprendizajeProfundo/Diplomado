{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers translator.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dunkel13/Diplomado/blob/master/Python/Transformers_translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V4rH-vZKO9k"
      },
      "source": [
        "## Instala librería transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrJj37_HJqp4"
      },
      "source": [
        "!pip install datasets transformers[sentencepiece]\n",
        "!pip install stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9PpVedDKFP7"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na5xTTAvKcKH"
      },
      "source": [
        "text = \"Now that we can find all the skipgram windows, we can calculate how often words occur on their own, and how often words occur together with other words. We do this using the point-wise mutual information (PMI), a measure of association that measures exactly what we described in the previous sentence; it's the logarithm of the probability of finding two words together, normalized for the probability of finding each of the words alone. We use PMI to measure which words occur together more often than expected based on how often they occurred on their own. \" \\\n",
        "+ \"When PMI is high, the two words are associated with each other, likely to occur together. When PMI is low, the two words are not associated with each other, unlikely to occur together.\" \\\n",
        "+ \"Now that we have determined word embeddings for the dataset of CFPB complaints, let's explore them and talk about they are used in modeling. We have projected the sparse, high-dimensional set of word features into a more dense, 100-dimensional set of features.\" \\\n",
        "+ \"This function takes the tidy word embeddings as input, along with a word (or token, more strictly) as a string. It uses matrix multiplication to find which words are closer or farther to the input word, and returns a dataframe sorted by similarity.\"\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUSIlssHKken",
        "outputId": "cf4c81b9-180c-4712-94b7-e6b95d40f869"
      },
      "source": [
        "# Inicia Traductor\n",
        "translator = pipeline(\"translation\", model = \"Helsinki-NLP/opus-mt-en-es\")\n",
        "# Traducir Texto\n",
        "traduccion = translator(text)\n",
        "# Mostrar Traducción\n",
        "traduccion"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Ahora que podemos encontrar todas las ventanas de skipgram, podemos calcular con qué frecuencia las palabras ocurren por sí solas, y con qué frecuencia las palabras ocurren junto con otras palabras. Lo hacemos usando la información mutua puntual (PMI), una medida de asociación que mide exactamente lo que describimos en la frase anterior; es el logaritmo de la probabilidad de encontrar dos palabras juntas, normalizadas para la probabilidad de encontrar cada una de las palabras solas. Utilizamos PMI para medir qué palabras ocurren juntas más a menudo de lo esperado basado en la frecuencia con que ocurrieron por sí mismas. Cuando PMI es alto, las dos palabras se asocian entre sí, es probable que ocurran juntas. Cuando PMI es bajo, las dos palabras no se asocian entre sí, es poco probable que ocurran juntas.Ahora que hemos determinado la inserción de palabras para el conjunto de datos de las quejas de CFPB, exploremos y hablaremos sobre ellas se utilizan en el modelado. Hemos proyectado el conjunto de palabras escasas, de alta dimensión características en un conjunto de palabras más denso, 100 dimensiones en un conjunto de características.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "x2BFVxq1LBEn",
        "outputId": "3458c601-5a73-416c-83a6-512b50dbcaac"
      },
      "source": [
        "texto = traduccion[0]['translation_text']\n",
        "texto"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ahora que podemos encontrar todas las ventanas de skipgram, podemos calcular con qué frecuencia las palabras ocurren por sí solas, y con qué frecuencia las palabras ocurren junto con otras palabras. Lo hacemos usando la información mutua puntual (PMI), una medida de asociación que mide exactamente lo que describimos en la frase anterior; es el logaritmo de la probabilidad de encontrar dos palabras juntas, normalizadas para la probabilidad de encontrar cada una de las palabras solas. Utilizamos PMI para medir qué palabras ocurren juntas más a menudo de lo esperado basado en la frecuencia con que ocurrieron por sí mismas. Cuando PMI es alto, las dos palabras se asocian entre sí, es probable que ocurran juntas. Cuando PMI es bajo, las dos palabras no se asocian entre sí, es poco probable que ocurran juntas.Ahora que hemos determinado la inserción de palabras para el conjunto de datos de las quejas de CFPB, exploremos y hablaremos sobre ellas se utilizan en el modelado. Hemos proyectado el conjunto de palabras escasas, de alta dimensión características en un conjunto de palabras más denso, 100 dimensiones en un conjunto de características.'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}